{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# M√≥dulo 7: GANs e VAEs - Gera√ß√£o Sint√©tica de Imagens\n",
        "\n",
        "## üéØ Objetivos de Aprendizagem\n",
        "\n",
        "Ao final deste m√≥dulo, voc√™ ser√° capaz de:\n",
        "\n",
        "- ‚úÖ Compreender os fundamentos de Generative Adversarial Networks (GANs)\n",
        "- ‚úÖ Entender Variational Autoencoders (VAEs) para gera√ß√£o de imagens\n",
        "- ‚úÖ Implementar modelos de gera√ß√£o sint√©tica\n",
        "- ‚úÖ Analisar aplica√ß√µes pr√°ticas de gera√ß√£o de imagens\n",
        "- ‚úÖ Comparar diferentes abordagens de gera√ß√£o\n",
        "\n",
        "---\n",
        "\n",
        "## üé® 7.1 Introdu√ß√£o √† Gera√ß√£o Sint√©tica de Imagens\n",
        "\n",
        "### Conceito Fundamental\n",
        "\n",
        "**Gera√ß√£o Sint√©tica de Imagens** √© o processo de criar imagens artificialmente usando modelos de machine learning, permitindo criar conte√∫do visual novo e realista.\n",
        "\n",
        "![Introdu√ß√£o Gera√ß√£o Sint√©tica](https://cdn.jsdelivr.net/gh/rfapo/visao-computacional@main/images/modulo7/introducao_geracao_sintetica.png)\n",
        "\n",
        "### Defini√ß√£o e Caracter√≠sticas\n",
        "\n",
        "**Defini√ß√£o:**\n",
        "- **Gera√ß√£o**: Cria√ß√£o de novas imagens\n",
        "- **Sint√©tica**: Produzida artificialmente\n",
        "- **Realista**: Visualmente convincente\n",
        "- **Control√°vel**: Par√¢metros ajust√°veis\n",
        "\n",
        "**Caracter√≠sticas Principais:**\n",
        "- **Novidade**: Imagens nunca vistas antes\n",
        "- **Variedade**: Diversidade de conte√∫do\n",
        "- **Qualidade**: Alta fidelidade visual\n",
        "- **Controle**: Manipula√ß√£o de caracter√≠sticas\n",
        "\n",
        "### Aplica√ß√µes Pr√°ticas\n",
        "\n",
        "#### **1. Arte Digital**\n",
        "- **Cria√ß√£o art√≠stica**: Gera√ß√£o de obras de arte\n",
        "- **Estilos diversos**: Pinturas, fotografias, ilustra√ß√µes\n",
        "- **Personaliza√ß√£o**: Adapta√ß√£o a prefer√™ncias\n",
        "- **Colabora√ß√£o**: Ferramenta para artistas\n",
        "\n",
        "#### **2. Data Augmentation**\n",
        "- **Aumento de datasets**: Cria√ß√£o de dados sint√©ticos\n",
        "- **Balanceamento**: Corre√ß√£o de desbalanceamento\n",
        "- **Variedade**: Diversifica√ß√£o de exemplos\n",
        "- **Efici√™ncia**: Redu√ß√£o de coleta manual\n",
        "\n",
        "#### **3. Design e Prototipagem**\n",
        "- **Conceitos visuais**: Ideias r√°pidas\n",
        "- **Itera√ß√£o**: M√∫ltiplas vers√µes\n",
        "- **Personaliza√ß√£o**: Adapta√ß√£o a necessidades\n",
        "- **Efici√™ncia**: Redu√ß√£o de tempo de desenvolvimento\n",
        "\n",
        "#### **4. Entretenimento**\n",
        "- **Jogos**: Assets visuais\n",
        "- **Filmes**: Efeitos especiais\n",
        "- **Realidade virtual**: Ambientes sint√©ticos\n",
        "- **Conte√∫do**: Gera√ß√£o de m√≠dia\n",
        "\n",
        "### Evolu√ß√£o da Gera√ß√£o Sint√©tica\n",
        "\n",
        "![Evolu√ß√£o Gera√ß√£o Sint√©tica](https://cdn.jsdelivr.net/gh/rfapo/visao-computacional@main/images/modulo7/evolucao_geracao_sintetica.png)\n",
        "\n",
        "#### **Progress√£o Hist√≥rica:**\n",
        "\n",
        "| Ano | Marco | Contribui√ß√£o |\n",
        "|-----|-------|--------------|\n",
        "| **2014** | GANs | Generative Adversarial Networks |\n",
        "| **2015** | VAEs | Variational Autoencoders |\n",
        "| **2016** | DCGAN | Deep Convolutional GANs |\n",
        "| **2017** | Progressive GAN | Resolu√ß√£o crescente |\n",
        "| **2018** | StyleGAN | Controle de estilo |\n",
        "| **2020** | Diffusion Models | Revolu√ß√£o no campo |\n",
        "| **2022** | DALL-E 2 | Populariza√ß√£o |\n",
        "\n",
        "#### **Marcos Importantes:**\n",
        "- **2014**: Generative Adversarial Networks - Goodfellow et al.\n",
        "- **2015**: Auto-Encoding Variational Bayes - Kingma & Welling\n",
        "- **2016**: Deep Convolutional GANs - Radford et al.\n",
        "- **2017**: Progressive Growing of GANs - Karras et al.\n",
        "- **2019**: StyleGAN - Karras et al.\n",
        "- **2021**: DALL-E - Ramesh et al.\n",
        "\n",
        "---\n",
        "\n",
        "## ‚öîÔ∏è 7.2 Generative Adversarial Networks (GANs)\n",
        "\n",
        "### Conceito Fundamental\n",
        "\n",
        "**GANs** s√£o arquiteturas que consistem em dois modelos neurais competindo entre si: um **gerador** que cria imagens sint√©ticas e um **discriminador** que tenta distinguir entre imagens reais e sint√©ticas.\n",
        "\n",
        "![Arquitetura GANs](https://cdn.jsdelivr.net/gh/rfapo/visao-computacional@main/images/modulo7/arquitetura_gans.png)\n",
        "\n",
        "### Componentes Principais\n",
        "\n",
        "#### **1. Gerador (Generator)**\n",
        "\n",
        "**Fun√ß√£o:**\n",
        "- **Entrada**: Ru√≠do aleat√≥rio (latent vector)\n",
        "- **Sa√≠da**: Imagem sint√©tica\n",
        "- **Objetivo**: Enganar o discriminador\n",
        "- **Treinamento**: Minimizar perda do discriminador\n",
        "\n",
        "**Arquitetura:**\n",
        "```\n",
        "Ru√≠do ‚Üí FC ‚Üí Reshape ‚Üí Conv Transpose ‚Üí Imagem\n",
        "```\n",
        "\n",
        "**Caracter√≠sticas:**\n",
        "- **Upsampling**: Aumento de resolu√ß√£o\n",
        "- **Convolu√ß√µes transpostas**: Gera√ß√£o de features\n",
        "- **Normaliza√ß√£o**: Batch normalization\n",
        "- **Ativa√ß√£o**: Tanh para sa√≠da\n",
        "\n",
        "#### **2. Discriminador (Discriminator)**\n",
        "\n",
        "**Fun√ß√£o:**\n",
        "- **Entrada**: Imagem (real ou sint√©tica)\n",
        "- **Sa√≠da**: Probabilidade de ser real\n",
        "- **Objetivo**: Distinguir real de sint√©tico\n",
        "- **Treinamento**: Maximizar precis√£o\n",
        "\n",
        "**Arquitetura:**\n",
        "```\n",
        "Imagem ‚Üí Conv ‚Üí Pool ‚Üí Conv ‚Üí Pool ‚Üí FC ‚Üí Probabilidade\n",
        "```\n",
        "\n",
        "**Caracter√≠sticas:**\n",
        "- **Downsampling**: Redu√ß√£o de resolu√ß√£o\n",
        "- **Convolu√ß√µes**: Extra√ß√£o de features\n",
        "- **Pooling**: Redu√ß√£o de dimensionalidade\n",
        "- **Ativa√ß√£o**: Sigmoid para sa√≠da\n",
        "\n",
        "### Processo de Treinamento\n",
        "\n",
        "#### **1. Treinamento do Discriminador**\n",
        "```\n",
        "1. Imagens reais ‚Üí Discriminador ‚Üí Loss real\n",
        "2. Ru√≠do ‚Üí Gerador ‚Üí Imagens sint√©ticas\n",
        "3. Imagens sint√©ticas ‚Üí Discriminador ‚Üí Loss sint√©tico\n",
        "4. Loss total = Loss real + Loss sint√©tico\n",
        "5. Backpropagation no discriminador\n",
        "```\n",
        "\n",
        "#### **2. Treinamento do Gerador**\n",
        "```\n",
        "1. Ru√≠do ‚Üí Gerador ‚Üí Imagens sint√©ticas\n",
        "2. Imagens sint√©ticas ‚Üí Discriminador ‚Üí Probabilidade\n",
        "3. Loss = -log(probabilidade)\n",
        "4. Backpropagation no gerador\n",
        "```\n",
        "\n",
        "### Vantagens e Desvantagens\n",
        "\n",
        "#### **Vantagens:**\n",
        "- ‚úÖ **Qualidade alta**: Imagens muito realistas\n",
        "- ‚úÖ **Variedade**: Diversidade de conte√∫do\n",
        "- ‚úÖ **Flexibilidade**: M√∫ltiplas aplica√ß√µes\n",
        "- ‚úÖ **Inova√ß√£o**: Abordagem √∫nica\n",
        "\n",
        "#### **Desvantagens:**\n",
        "- ‚ùå **Treinamento inst√°vel**: Dif√≠cil converg√™ncia\n",
        "- ‚ùå **Mode collapse**: Falta de diversidade\n",
        "- ‚ùå **Computa√ß√£o intensiva**: Recursos elevados\n",
        "- ‚ùå **Controle limitado**: Dificuldade de manipula√ß√£o\n",
        "\n",
        "---\n",
        "\n",
        "## üîÑ 7.3 Variational Autoencoders (VAEs)\n",
        "\n",
        "### Conceito Fundamental\n",
        "\n",
        "**VAEs** s√£o modelos generativos que aprendem a representar dados em um espa√ßo latente de menor dimensionalidade, permitindo gera√ß√£o de novas amostras atrav√©s de amostragem do espa√ßo latente.\n",
        "\n",
        "![Arquitetura VAEs](https://cdn.jsdelivr.net/gh/rfapo/visao-computacional@main/images/modulo7/arquitetura_vaes.png)\n",
        "\n",
        "### Componentes Principais\n",
        "\n",
        "#### **1. Encoder**\n",
        "\n",
        "**Fun√ß√£o:**\n",
        "- **Entrada**: Imagem real\n",
        "- **Sa√≠da**: Par√¢metros da distribui√ß√£o latente (Œº, œÉ)\n",
        "- **Objetivo**: Comprimir informa√ß√£o\n",
        "- **Resultado**: Representa√ß√£o latente\n",
        "\n",
        "**Processo:**\n",
        "```\n",
        "Imagem ‚Üí Conv ‚Üí Pool ‚Üí Conv ‚Üí Pool ‚Üí FC ‚Üí Œº, œÉ\n",
        "```\n",
        "\n",
        "#### **2. Decoder**\n",
        "\n",
        "**Fun√ß√£o:**\n",
        "- **Entrada**: Amostra do espa√ßo latente\n",
        "- **Sa√≠da**: Imagem reconstru√≠da\n",
        "- **Objetivo**: Reconstruir imagem original\n",
        "- **Resultado**: Imagem sint√©tica\n",
        "\n",
        "**Processo:**\n",
        "```\n",
        "z ‚Üí FC ‚Üí Reshape ‚Üí Conv Transpose ‚Üí Imagem\n",
        "```\n",
        "\n",
        "### Espa√ßo Latente\n",
        "\n",
        "#### **Caracter√≠sticas:**\n",
        "- **Dimensionalidade**: Menor que dados originais\n",
        "- **Distribui√ß√£o**: Gaussiana multivariada\n",
        "- **Continuidade**: Espa√ßo cont√≠nuo\n",
        "- **Interpretabilidade**: Caracter√≠sticas sem√¢nticas\n",
        "\n",
        "#### **Amostragem:**\n",
        "```\n",
        "z = Œº + œÉ ‚äô Œµ\n",
        "onde Œµ ~ N(0, I)\n",
        "```\n",
        "\n",
        "### Fun√ß√£o de Perda\n",
        "\n",
        "#### **Loss Total:**\n",
        "```\n",
        "L = L_reconstruction + Œ≤ * L_KL\n",
        "```\n",
        "\n",
        "#### **1. Loss de Reconstru√ß√£o:**\n",
        "```\n",
        "L_reconstruction = ||x - x'||¬≤\n",
        "```\n",
        "\n",
        "#### **2. Loss KL Divergence:**\n",
        "```\n",
        "L_KL = KL(q(z|x) || p(z))\n",
        "```\n",
        "\n",
        "### Vantagens e Desvantagens\n",
        "\n",
        "#### **Vantagens:**\n",
        "- ‚úÖ **Treinamento est√°vel**: Converg√™ncia garantida\n",
        "- ‚úÖ **Controle**: Manipula√ß√£o do espa√ßo latente\n",
        "- ‚úÖ **Interpretabilidade**: Caracter√≠sticas sem√¢nticas\n",
        "- ‚úÖ **Efici√™ncia**: Treinamento mais r√°pido\n",
        "\n",
        "#### **Desvantagens:**\n",
        "- ‚ùå **Qualidade**: Imagens menos n√≠tidas\n",
        "- ‚ùå **Variedade**: Menos diversidade\n",
        "- ‚ùå **Blur**: Efeito de desfoque\n",
        "- ‚ùå **Complexidade**: Implementa√ß√£o mais complexa\n",
        "\n",
        "---\n",
        "\n",
        "## üîç 7.4 Demonstra√ß√£o Pr√°tica: GANs Simples\n",
        "\n",
        "Vamos implementar e visualizar um GAN simples para gera√ß√£o de imagens:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "class SimpleGAN:\n",
        "    \"\"\"Implementa√ß√£o de um GAN simples para demonstra√ß√£o\"\"\"\n",
        "    \n",
        "    def __init__(self, latent_dim=100, img_size=64):\n",
        "        self.latent_dim = latent_dim\n",
        "        self.img_size = img_size\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        \n",
        "        # Inicializar modelos\n",
        "        self.generator = self._build_generator()\n",
        "        self.discriminator = self._build_discriminator()\n",
        "        \n",
        "        # Otimizadores\n",
        "        self.g_optimizer = optim.Adam(self.generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "        self.d_optimizer = optim.Adam(self.discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "        \n",
        "        # Loss function\n",
        "        self.criterion = nn.BCELoss()\n",
        "        \n",
        "        # Hist√≥rico de treinamento\n",
        "        self.g_losses = []\n",
        "        self.d_losses = []\n",
        "        \n",
        "    def _build_generator(self):\n",
        "        \"\"\"Constr√≥i o gerador\"\"\"\n",
        "        \n",
        "        class Generator(nn.Module):\n",
        "            def __init__(self, latent_dim, img_size):\n",
        "                super(Generator, self).__init__()\n",
        "                \n",
        "                # Camadas fully connected\n",
        "                self.fc1 = nn.Linear(latent_dim, 256)\n",
        "                self.fc2 = nn.Linear(256, 512)\n",
        "                self.fc3 = nn.Linear(512, 1024)\n",
        "                self.fc4 = nn.Linear(1024, img_size * img_size * 3)\n",
        "                \n",
        "                # Dropout\n",
        "                self.dropout = nn.Dropout(0.3)\n",
        "                \n",
        "            def forward(self, x):\n",
        "                x = F.relu(self.fc1(x))\n",
        "                x = self.dropout(x)\n",
        "                x = F.relu(self.fc2(x))\n",
        "                x = self.dropout(x)\n",
        "                x = F.relu(self.fc3(x))\n",
        "                x = self.dropout(x)\n",
        "                x = torch.tanh(self.fc4(x))\n",
        "                \n",
        "                # Reshape para imagem\n",
        "                x = x.view(x.size(0), 3, self.img_size, self.img_size)\n",
        "                return x\n",
        "        \n",
        "        return Generator(self.latent_dim, self.img_size).to(self.device)\n",
        "    \n",
        "    def _build_discriminator(self):\n",
        "        \"\"\"Constr√≥i o discriminador\"\"\"\n",
        "        \n",
        "        class Discriminator(nn.Module):\n",
        "            def __init__(self, img_size):\n",
        "                super(Discriminator, self).__init__()\n",
        "                \n",
        "                # Camadas fully connected\n",
        "                self.fc1 = nn.Linear(img_size * img_size * 3, 1024)\n",
        "                self.fc2 = nn.Linear(1024, 512)\n",
        "                self.fc3 = nn.Linear(512, 256)\n",
        "                self.fc4 = nn.Linear(256, 1)\n",
        "                \n",
        "                # Dropout\n",
        "                self.dropout = nn.Dropout(0.3)\n",
        "                \n",
        "            def forward(self, x):\n",
        "                x = x.view(x.size(0), -1)\n",
        "                x = F.leaky_relu(self.fc1(x), 0.2)\n",
        "                x = self.dropout(x)\n",
        "                x = F.leaky_relu(self.fc2(x), 0.2)\n",
        "                x = self.dropout(x)\n",
        "                x = F.leaky_relu(self.fc3(x), 0.2)\n",
        "                x = self.dropout(x)\n",
        "                x = torch.sigmoid(self.fc4(x))\n",
        "                return x\n",
        "        \n",
        "        return Discriminator(self.img_size).to(self.device)\n",
        "    \n",
        "    def create_sample_data(self, num_samples=1000):\n",
        "        \"\"\"Cria dados de exemplo para demonstra√ß√£o\"\"\"\n",
        "        \n",
        "        # Criar imagens sint√©ticas simples\n",
        "        images = []\n",
        "        \n",
        "        for _ in range(num_samples):\n",
        "            # Criar imagem com padr√µes simples\n",
        "            img = np.random.rand(3, self.img_size, self.img_size) * 2 - 1  # Normalizar para [-1, 1]\n",
        "            \n",
        "            # Adicionar padr√µes\n",
        "            if np.random.random() > 0.5:\n",
        "                # Padr√£o circular\n",
        "                center_x, center_y = np.random.randint(20, self.img_size-20, 2)\n",
        "                radius = np.random.randint(10, 20)\n",
        "                \n",
        "                y, x = np.ogrid[:self.img_size, :self.img_size]\n",
        "                mask = (x - center_x)**2 + (y - center_y)**2 <= radius**2\n",
        "                \n",
        "                img[0, mask] = 1.0  # Red\n",
        "                img[1, mask] = 0.0  # Green\n",
        "                img[2, mask] = 0.0  # Blue\n",
        "            else:\n",
        "                # Padr√£o retangular\n",
        "                x1, y1 = np.random.randint(0, self.img_size-30, 2)\n",
        "                x2, y2 = x1 + np.random.randint(20, 40), y1 + np.random.randint(20, 40)\n",
        "                \n",
        "                img[0, y1:y2, x1:x2] = 0.0  # Red\n",
        "                img[1, y1:y2, x1:x2] = 1.0  # Green\n",
        "                img[2, y1:y2, x1:x2] = 0.0  # Blue\n",
        "            \n",
        "            images.append(img)\n",
        "        \n",
        "        return torch.FloatTensor(images)\n",
        "    \n",
        "    def train_step(self, real_images, batch_size):\n",
        "        \"\"\"Executa um passo de treinamento\"\"\"\n",
        "        \n",
        "        # Labels\n",
        "        real_labels = torch.ones(batch_size, 1).to(self.device)\n",
        "        fake_labels = torch.zeros(batch_size, 1).to(self.device)\n",
        "        \n",
        "        # Treinar Discriminador\n",
        "        self.d_optimizer.zero_grad()\n",
        "        \n",
        "        # Loss com imagens reais\n",
        "        real_output = self.discriminator(real_images)\n",
        "        d_loss_real = self.criterion(real_output, real_labels)\n",
        "        \n",
        "        # Loss com imagens sint√©ticas\n",
        "        noise = torch.randn(batch_size, self.latent_dim).to(self.device)\n",
        "        fake_images = self.generator(noise)\n",
        "        fake_output = self.discriminator(fake_images.detach())\n",
        "        d_loss_fake = self.criterion(fake_output, fake_labels)\n",
        "        \n",
        "        d_loss = d_loss_real + d_loss_fake\n",
        "        d_loss.backward()\n",
        "        self.d_optimizer.step()\n",
        "        \n",
        "        # Treinar Gerador\n",
        "        self.g_optimizer.zero_grad()\n",
        "        \n",
        "        noise = torch.randn(batch_size, self.latent_dim).to(self.device)\n",
        "        fake_images = self.generator(noise)\n",
        "        fake_output = self.discriminator(fake_images)\n",
        "        g_loss = self.criterion(fake_output, real_labels)\n",
        "        \n",
        "        g_loss.backward()\n",
        "        self.g_optimizer.step()\n",
        "        \n",
        "        return d_loss.item(), g_loss.item()\n",
        "    \n",
        "    def train(self, epochs=50, batch_size=32):\n",
        "        \"\"\"Treina o GAN\"\"\"\n",
        "        \n",
        "        # Criar dados\n",
        "        real_images = self.create_sample_data(1000)\n",
        "        dataset = TensorDataset(real_images)\n",
        "        dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "        \n",
        "        print(f\"Iniciando treinamento do GAN para {epochs} √©pocas...\")\n",
        "        \n",
        "        for epoch in range(epochs):\n",
        "            epoch_d_loss = 0\n",
        "            epoch_g_loss = 0\n",
        "            \n",
        "            for batch_idx, (real_batch,) in enumerate(dataloader):\n",
        "                real_batch = real_batch.to(self.device)\n",
        "                \n",
        "                d_loss, g_loss = self.train_step(real_batch, real_batch.size(0))\n",
        "                \n",
        "                epoch_d_loss += d_loss\n",
        "                epoch_g_loss += g_loss\n",
        "            \n",
        "            # M√©dias\n",
        "            avg_d_loss = epoch_d_loss / len(dataloader)\n",
        "            avg_g_loss = epoch_g_loss / len(dataloader)\n",
        "            \n",
        "            self.d_losses.append(avg_d_loss)\n",
        "            self.g_losses.append(avg_g_loss)\n",
        "            \n",
        "            if epoch % 10 == 0:\n",
        "                print(f\"√âpoca {epoch}/{epochs} - D Loss: {avg_d_loss:.4f}, G Loss: {avg_g_loss:.4f}\")\n",
        "        \n",
        "        print(\"Treinamento conclu√≠do!\")\n",
        "    \n",
        "    def generate_samples(self, num_samples=16):\n",
        "        \"\"\"Gera amostras sint√©ticas\"\"\"\n",
        "        \n",
        "        self.generator.eval()\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            noise = torch.randn(num_samples, self.latent_dim).to(self.device)\n",
        "            fake_images = self.generator(noise)\n",
        "            \n",
        "            # Converter para numpy\n",
        "            fake_images = fake_images.cpu().numpy()\n",
        "            \n",
        "            # Normalizar para [0, 1]\n",
        "            fake_images = (fake_images + 1) / 2\n",
        "            fake_images = np.clip(fake_images, 0, 1)\n",
        "            \n",
        "        return fake_images\n",
        "    \n",
        "    def visualize_results(self):\n",
        "        \"\"\"Visualiza resultados do treinamento\"\"\"\n",
        "        \n",
        "        fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "        \n",
        "        # Gr√°fico de perdas\n",
        "        axes[0, 0].plot(self.d_losses, label='Discriminador', color='red')\n",
        "        axes[0, 0].plot(self.g_losses, label='Gerador', color='blue')\n",
        "        axes[0, 0].set_title('Evolu√ß√£o das Perdas')\n",
        "        axes[0, 0].set_xlabel('√âpoca')\n",
        "        axes[0, 0].set_ylabel('Perda')\n",
        "        axes[0, 0].legend()\n",
        "        axes[0, 0].grid(True, alpha=0.3)\n",
        "        \n",
        "        # Amostras geradas\n",
        "        fake_images = self.generate_samples(16)\n",
        "        \n",
        "        # Criar grid de imagens\n",
        "        grid_img = np.zeros((4 * self.img_size, 4 * self.img_size, 3))\n",
        "        \n",
        "        for i in range(4):\n",
        "            for j in range(4):\n",
        "                idx = i * 4 + j\n",
        "                if idx < len(fake_images):\n",
        "                    img = fake_images[idx].transpose(1, 2, 0)\n",
        "                    grid_img[i*self.img_size:(i+1)*self.img_size, \n",
        "                           j*self.img_size:(j+1)*self.img_size] = img\n",
        "        \n",
        "        axes[0, 1].imshow(grid_img)\n",
        "        axes[0, 1].set_title('Amostras Geradas')\n",
        "        axes[0, 1].axis('off')\n",
        "        \n",
        "        # An√°lise de qualidade\n",
        "        fake_images = self.generate_samples(100)\n",
        "        \n",
        "        # Calcular estat√≠sticas\n",
        "        mean_values = np.mean(fake_images, axis=(2, 3))\n",
        "        std_values = np.std(fake_images, axis=(2, 3))\n",
        "        \n",
        "        axes[1, 0].scatter(mean_values[:, 0], mean_values[:, 1], alpha=0.6, label='Red vs Green')\n",
        "        axes[1, 0].set_title('Distribui√ß√£o de Cores (M√©dia)')\n",
        "        axes[1, 0].set_xlabel('Red')\n",
        "        axes[1, 0].set_ylabel('Green')\n",
        "        axes[1, 0].legend()\n",
        "        axes[1, 0].grid(True, alpha=0.3)\n",
        "        \n",
        "        axes[1, 1].scatter(std_values[:, 0], std_values[:, 1], alpha=0.6, label='Red vs Green')\n",
        "        axes[1, 1].set_title('Distribui√ß√£o de Cores (Desvio Padr√£o)')\n",
        "        axes[1, 1].set_xlabel('Red')\n",
        "        axes[1, 1].set_ylabel('Green')\n",
        "        axes[1, 1].legend()\n",
        "        axes[1, 1].grid(True, alpha=0.3)\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        \n",
        "        # An√°lise quantitativa\n",
        "        print(\"=== AN√ÅLISE QUANTITATIVA DO GAN ===\")\n",
        "        print(f\"\\nEstat√≠sticas de Treinamento:\")\n",
        "        print(f\"  - √âpocas: {len(self.d_losses)}\")\n",
        "        print(f\"  - Perda final do Discriminador: {self.d_losses[-1]:.4f}\")\n",
        "        print(f\"  - Perda final do Gerador: {self.g_losses[-1]:.4f}\")\n",
        "        print(f\"  - Diferen√ßa de perdas: {abs(self.d_losses[-1] - self.g_losses[-1]):.4f}\")\n",
        "        \n",
        "        print(f\"\\nEstat√≠sticas das Imagens Geradas:\")\n",
        "        print(f\"  - M√©dia Red: {np.mean(mean_values[:, 0]):.3f}\")\n",
        "        print(f\"  - M√©dia Green: {np.mean(mean_values[:, 1]):.3f}\")\n",
        "        print(f\"  - M√©dia Blue: {np.mean(mean_values[:, 2]):.3f}\")\n",
        "        print(f\"  - Desvio Red: {np.mean(std_values[:, 0]):.3f}\")\n",
        "        print(f\"  - Desvio Green: {np.mean(std_values[:, 1]):.3f}\")\n",
        "        print(f\"  - Desvio Blue: {np.mean(std_values[:, 2]):.3f}\")\n",
        "        \n",
        "        return fake_images\n",
        "\n",
        "# Executar demonstra√ß√£o\n",
        "print(\"=== DEMONSTRA√á√ÉO: GAN SIMPLES ===\")\n",
        "gan = SimpleGAN(latent_dim=100, img_size=32)\n",
        "gan.train(epochs=30, batch_size=16)\n",
        "generated_images = gan.visualize_results()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### An√°lise dos Resultados\n",
        "\n",
        "**Observa√ß√µes Importantes:**\n",
        "\n",
        "1. **Evolu√ß√£o das Perdas**:\n",
        "   - **Discriminador**: Deve diminuir gradualmente\n",
        "   - **Gerador**: Deve diminuir para enganar o discriminador\n",
        "   - **Equil√≠brio**: Perdas devem se estabilizar\n",
        "\n",
        "2. **Qualidade das Imagens**:\n",
        "   - **Diversidade**: Varia√ß√£o nas cores e padr√µes\n",
        "   - **Realismo**: Apar√™ncia convincente\n",
        "   - **Consist√™ncia**: Padr√µes reconhec√≠veis\n",
        "\n",
        "3. **Distribui√ß√£o de Cores**:\n",
        "   - **M√©dia**: Concentra√ß√£o em certas cores\n",
        "   - **Desvio**: Variabilidade das cores\n",
        "   - **Balanceamento**: Distribui√ß√£o equilibrada\n",
        "\n",
        "---\n",
        "\n",
        "## üîÑ 7.5 Demonstra√ß√£o Pr√°tica: VAEs Simples\n",
        "\n",
        "Vamos implementar e visualizar um VAE simples:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "class SimpleVAE:\n",
        "    \"\"\"Implementa√ß√£o de um VAE simples para demonstra√ß√£o\"\"\"\n",
        "    \n",
        "    def __init__(self, latent_dim=20, img_size=32):\n",
        "        self.latent_dim = latent_dim\n",
        "        self.img_size = img_size\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        \n",
        "        # Inicializar modelo\n",
        "        self.vae = self._build_vae()\n",
        "        \n",
        "        # Otimizador\n",
        "        self.optimizer = optim.Adam(self.vae.parameters(), lr=0.001)\n",
        "        \n",
        "        # Hist√≥rico de treinamento\n",
        "        self.reconstruction_losses = []\n",
        "        self.kl_losses = []\n",
        "        self.total_losses = []\n",
        "        \n",
        "    def _build_vae(self):\n",
        "        \"\"\"Constr√≥i o VAE\"\"\"\n",
        "        \n",
        "        class VAE(nn.Module):\n",
        "            def __init__(self, latent_dim, img_size):\n",
        "                super(VAE, self).__init__()\n",
        "                \n",
        "                self.latent_dim = latent_dim\n",
        "                self.img_size = img_size\n",
        "                \n",
        "                # Encoder\n",
        "                self.encoder = nn.Sequential(\n",
        "                    nn.Linear(img_size * img_size * 3, 512),\n",
        "                    nn.ReLU(),\n",
        "                    nn.Linear(512, 256),\n",
        "                    nn.ReLU(),\n",
        "                    nn.Linear(256, 128),\n",
        "                    nn.ReLU()\n",
        "                )\n",
        "                \n",
        "                # Latent space\n",
        "                self.fc_mu = nn.Linear(128, latent_dim)\n",
        "                self.fc_logvar = nn.Linear(128, latent_dim)\n",
        "                \n",
        "                # Decoder\n",
        "                self.decoder = nn.Sequential(\n",
        "                    nn.Linear(latent_dim, 128),\n",
        "                    nn.ReLU(),\n",
        "                    nn.Linear(128, 256),\n",
        "                    nn.ReLU(),\n",
        "                    nn.Linear(256, 512),\n",
        "                    nn.ReLU(),\n",
        "                    nn.Linear(512, img_size * img_size * 3),\n",
        "                    nn.Tanh()\n",
        "                )\n",
        "                \n",
        "            def encode(self, x):\n",
        "                h = self.encoder(x.view(x.size(0), -1))\n",
        "                mu = self.fc_mu(h)\n",
        "                logvar = self.fc_logvar(h)\n",
        "                return mu, logvar\n",
        "                \n",
        "            def reparameterize(self, mu, logvar):\n",
        "                std = torch.exp(0.5 * logvar)\n",
        "                eps = torch.randn_like(std)\n",
        "                return mu + eps * std\n",
        "                \n",
        "            def decode(self, z):\n",
        "                h = self.decoder(z)\n",
        "                return h.view(-1, 3, self.img_size, self.img_size)\n",
        "                \n",
        "            def forward(self, x):\n",
        "                mu, logvar = self.encode(x)\n",
        "                z = self.reparameterize(mu, logvar)\n",
        "                recon_x = self.decode(z)\n",
        "                return recon_x, mu, logvar\n",
        "        \n",
        "        return VAE(self.latent_dim, self.img_size).to(self.device)\n",
        "    \n",
        "    def create_sample_data(self, num_samples=1000):\n",
        "        \"\"\"Cria dados de exemplo para demonstra√ß√£o\"\"\"\n",
        "        \n",
        "        # Criar imagens sint√©ticas simples\n",
        "        images = []\n",
        "        \n",
        "        for _ in range(num_samples):\n",
        "            # Criar imagem com padr√µes simples\n",
        "            img = np.random.rand(3, self.img_size, self.img_size) * 2 - 1  # Normalizar para [-1, 1]\n",
        "            \n",
        "            # Adicionar padr√µes\n",
        "            if np.random.random() > 0.5:\n",
        "                # Padr√£o circular\n",
        "                center_x, center_y = np.random.randint(10, self.img_size-10, 2)\n",
        "                radius = np.random.randint(5, 15)\n",
        "                \n",
        "                y, x = np.ogrid[:self.img_size, :self.img_size]\n",
        "                mask = (x - center_x)**2 + (y - center_y)**2 <= radius**2\n",
        "                \n",
        "                img[0, mask] = 1.0  # Red\n",
        "                img[1, mask] = 0.0  # Green\n",
        "                img[2, mask] = 0.0  # Blue\n",
        "            else:\n",
        "                # Padr√£o retangular\n",
        "                x1, y1 = np.random.randint(0, self.img_size-20, 2)\n",
        "                x2, y2 = x1 + np.random.randint(10, 25), y1 + np.random.randint(10, 25)\n",
        "                \n",
        "                img[0, y1:y2, x1:x2] = 0.0  # Red\n",
        "                img[1, y1:y2, x1:x2] = 1.0  # Green\n",
        "                img[2, y1:y2, x1:x2] = 0.0  # Blue\n",
        "            \n",
        "            images.append(img)\n",
        "        \n",
        "        return torch.FloatTensor(images)\n",
        "    \n",
        "    def loss_function(self, recon_x, x, mu, logvar):\n",
        "        \"\"\"Calcula a fun√ß√£o de perda do VAE\"\"\"\n",
        "        \n",
        "        # Loss de reconstru√ß√£o (MSE)\n",
        "        recon_loss = F.mse_loss(recon_x, x, reduction='sum')\n",
        "        \n",
        "        # Loss KL divergence\n",
        "        kl_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "        \n",
        "        return recon_loss, kl_loss\n",
        "    \n",
        "    def train_step(self, batch):\n",
        "        \"\"\"Executa um passo de treinamento\"\"\"\n",
        "        \n",
        "        self.optimizer.zero_grad()\n",
        "        \n",
        "        # Forward pass\n",
        "        recon_batch, mu, logvar = self.vae(batch)\n",
        "        \n",
        "        # Calcular perdas\n",
        "        recon_loss, kl_loss = self.loss_function(recon_batch, batch, mu, logvar)\n",
        "        total_loss = recon_loss + kl_loss\n",
        "        \n",
        "        # Backward pass\n",
        "        total_loss.backward()\n",
        "        self.optimizer.step()\n",
        "        \n",
        "        return recon_loss.item(), kl_loss.item(), total_loss.item()\n",
        "    \n",
        "    def train(self, epochs=50, batch_size=32):\n",
        "        \"\"\"Treina o VAE\"\"\"\n",
        "        \n",
        "        # Criar dados\n",
        "        real_images = self.create_sample_data(1000)\n",
        "        dataset = TensorDataset(real_images)\n",
        "        dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "        \n",
        "        print(f\"Iniciando treinamento do VAE para {epochs} √©pocas...\")\n",
        "        \n",
        "        for epoch in range(epochs):\n",
        "            epoch_recon_loss = 0\n",
        "            epoch_kl_loss = 0\n",
        "            epoch_total_loss = 0\n",
        "            \n",
        "            for batch_idx, (batch,) in enumerate(dataloader):\n",
        "                batch = batch.to(self.device)\n",
        "                \n",
        "                recon_loss, kl_loss, total_loss = self.train_step(batch)\n",
        "                \n",
        "                epoch_recon_loss += recon_loss\n",
        "                epoch_kl_loss += kl_loss\n",
        "                epoch_total_loss += total_loss\n",
        "            \n",
        "            # M√©dias\n",
        "            avg_recon_loss = epoch_recon_loss / len(dataloader)\n",
        "            avg_kl_loss = epoch_kl_loss / len(dataloader)\n",
        "            avg_total_loss = epoch_total_loss / len(dataloader)\n",
        "            \n",
        "            self.reconstruction_losses.append(avg_recon_loss)\n",
        "            self.kl_losses.append(avg_kl_loss)\n",
        "            self.total_losses.append(avg_total_loss)\n",
        "            \n",
        "            if epoch % 10 == 0:\n",
        "                print(f\"√âpoca {epoch}/{epochs} - Recon Loss: {avg_recon_loss:.4f}, KL Loss: {avg_kl_loss:.4f}, Total Loss: {avg_total_loss:.4f}\")\n",
        "        \n",
        "        print(\"Treinamento conclu√≠do!\")\n",
        "    \n",
        "    def generate_samples(self, num_samples=16):\n",
        "        \"\"\"Gera amostras sint√©ticas\"\"\"\n",
        "        \n",
        "        self.vae.eval()\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            # Amostrar do espa√ßo latente\n",
        "            z = torch.randn(num_samples, self.latent_dim).to(self.device)\n",
        "            fake_images = self.vae.decode(z)\n",
        "            \n",
        "            # Converter para numpy\n",
        "            fake_images = fake_images.cpu().numpy()\n",
        "            \n",
        "            # Normalizar para [0, 1]\n",
        "            fake_images = (fake_images + 1) / 2\n",
        "            fake_images = np.clip(fake_images, 0, 1)\n",
        "            \n",
        "        return fake_images\n",
        "    \n",
        "    def reconstruct_samples(self, num_samples=16):\n",
        "        \"\"\"Reconstr√≥i amostras reais\"\"\"\n",
        "        \n",
        "        self.vae.eval()\n",
        "        \n",
        "        # Criar amostras reais\n",
        "        real_images = self.create_sample_data(num_samples)\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            real_images = real_images.to(self.device)\n",
        "            recon_images, _, _ = self.vae(real_images)\n",
        "            \n",
        "            # Converter para numpy\n",
        "            real_images = real_images.cpu().numpy()\n",
        "            recon_images = recon_images.cpu().numpy()\n",
        "            \n",
        "            # Normalizar para [0, 1]\n",
        "            real_images = (real_images + 1) / 2\n",
        "            recon_images = (recon_images + 1) / 2\n",
        "            real_images = np.clip(real_images, 0, 1)\n",
        "            recon_images = np.clip(recon_images, 0, 1)\n",
        "            \n",
        "        return real_images, recon_images\n",
        "    \n",
        "    def visualize_results(self):\n",
        "        \"\"\"Visualiza resultados do treinamento\"\"\"\n",
        "        \n",
        "        fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "        \n",
        "        # Gr√°fico de perdas\n",
        "        axes[0, 0].plot(self.reconstruction_losses, label='Reconstru√ß√£o', color='blue')\n",
        "        axes[0, 0].plot(self.kl_losses, label='KL Divergence', color='red')\n",
        "        axes[0, 0].plot(self.total_losses, label='Total', color='green')\n",
        "        axes[0, 0].set_title('Evolu√ß√£o das Perdas')\n",
        "        axes[0, 0].set_xlabel('√âpoca')\n",
        "        axes[0, 0].set_ylabel('Perda')\n",
        "        axes[0, 0].legend()\n",
        "        axes[0, 0].grid(True, alpha=0.3)\n",
        "        \n",
        "        # Amostras geradas\n",
        "        fake_images = self.generate_samples(16)\n",
        "        \n",
        "        # Criar grid de imagens\n",
        "        grid_img = np.zeros((4 * self.img_size, 4 * self.img_size, 3))\n",
        "        \n",
        "        for i in range(4):\n",
        "            for j in range(4):\n",
        "                idx = i * 4 + j\n",
        "                if idx < len(fake_images):\n",
        "                    img = fake_images[idx].transpose(1, 2, 0)\n",
        "                    grid_img[i*self.img_size:(i+1)*self.img_size, \n",
        "                           j*self.img_size:(j+1)*self.img_size] = img\n",
        "        \n",
        "        axes[0, 1].imshow(grid_img)\n",
        "        axes[0, 1].set_title('Amostras Geradas')\n",
        "        axes[0, 1].axis('off')\n",
        "        \n",
        "        # Reconstru√ß√µes\n",
        "        real_images, recon_images = self.reconstruct_samples(16)\n",
        "        \n",
        "        # Grid de imagens reais\n",
        "        real_grid = np.zeros((4 * self.img_size, 4 * self.img_size, 3))\n",
        "        for i in range(4):\n",
        "            for j in range(4):\n",
        "                idx = i * 4 + j\n",
        "                if idx < len(real_images):\n",
        "                    img = real_images[idx].transpose(1, 2, 0)\n",
        "                    real_grid[i*self.img_size:(i+1)*self.img_size, \n",
        "                            j*self.img_size:(j+1)*self.img_size] = img\n",
        "        \n",
        "        axes[0, 2].imshow(real_grid)\n",
        "        axes[0, 2].set_title('Imagens Reais')\n",
        "        axes[0, 2].axis('off')\n",
        "        \n",
        "        # Grid de reconstru√ß√µes\n",
        "        recon_grid = np.zeros((4 * self.img_size, 4 * self.img_size, 3))\n",
        "        for i in range(4):\n",
        "            for j in range(4):\n",
        "                idx = i * 4 + j\n",
        "                if idx < len(recon_images):\n",
        "                    img = recon_images[idx].transpose(1, 2, 0)\n",
        "                    recon_grid[i*self.img_size:(i+1)*self.img_size, \n",
        "                             j*self.img_size:(j+1)*self.img_size] = img\n",
        "        \n",
        "        axes[1, 0].imshow(recon_grid)\n",
        "        axes[1, 0].set_title('Reconstru√ß√µes')\n",
        "        axes[1, 0].axis('off')\n",
        "        \n",
        "        # An√°lise de qualidade\n",
        "        fake_images = self.generate_samples(100)\n",
        "        \n",
        "        # Calcular estat√≠sticas\n",
        "        mean_values = np.mean(fake_images, axis=(2, 3))\n",
        "        std_values = np.std(fake_images, axis=(2, 3))\n",
        "        \n",
        "        axes[1, 1].scatter(mean_values[:, 0], mean_values[:, 1], alpha=0.6, label='Red vs Green')\n",
        "        axes[1, 1].set_title('Distribui√ß√£o de Cores (M√©dia)')\n",
        "        axes[1, 1].set_xlabel('Red')\n",
        "        axes[1, 1].set_ylabel('Green')\n",
        "        axes[1, 1].legend()\n",
        "        axes[1, 1].grid(True, alpha=0.3)\n",
        "        \n",
        "        axes[1, 2].scatter(std_values[:, 0], std_values[:, 1], alpha=0.6, label='Red vs Green')\n",
        "        axes[1, 2].set_title('Distribui√ß√£o de Cores (Desvio Padr√£o)')\n",
        "        axes[1, 2].set_xlabel('Red')\n",
        "        axes[1, 2].set_ylabel('Green')\n",
        "        axes[1, 2].legend()\n",
        "        axes[1, 2].grid(True, alpha=0.3)\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        \n",
        "        # An√°lise quantitativa\n",
        "        print(\"=== AN√ÅLISE QUANTITATIVA DO VAE ===\")\n",
        "        print(f\"\\nEstat√≠sticas de Treinamento:\")\n",
        "        print(f\"  - √âpocas: {len(self.total_losses)}\")\n",
        "        print(f\"  - Perda final de Reconstru√ß√£o: {self.reconstruction_losses[-1]:.4f}\")\n",
        "        print(f\"  - Perda final KL: {self.kl_losses[-1]:.4f}\")\n",
        "        print(f\"  - Perda final Total: {self.total_losses[-1]:.4f}\")\n",
        "        \n",
        "        print(f\"\\nEstat√≠sticas das Imagens Geradas:\")\n",
        "        print(f\"  - M√©dia Red: {np.mean(mean_values[:, 0]):.3f}\")\n",
        "        print(f\"  - M√©dia Green: {np.mean(mean_values[:, 1]):.3f}\")\n",
        "        print(f\"  - M√©dia Blue: {np.mean(mean_values[:, 2]):.3f}\")\n",
        "        print(f\"  - Desvio Red: {np.mean(std_values[:, 0]):.3f}\")\n",
        "        print(f\"  - Desvio Green: {np.mean(std_values[:, 1]):.3f}\")\n",
        "        print(f\"  - Desvio Blue: {np.mean(std_values[:, 2]):.3f}\")\n",
        "        \n",
        "        return fake_images\n",
        "\n",
        "# Executar demonstra√ß√£o\n",
        "print(\"=== DEMONSTRA√á√ÉO: VAE SIMPLES ===\")\n",
        "vae = SimpleVAE(latent_dim=20, img_size=32)\n",
        "vae.train(epochs=30, batch_size=16)\n",
        "generated_images = vae.visualize_results()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### An√°lise dos Resultados\n",
        "\n",
        "**Observa√ß√µes Importantes:**\n",
        "\n",
        "1. **Evolu√ß√£o das Perdas**:\n",
        "   - **Reconstru√ß√£o**: Deve diminuir para melhor reconstru√ß√£o\n",
        "   - **KL Divergence**: Deve diminuir para espa√ßo latente regularizado\n",
        "   - **Total**: Soma das duas perdas\n",
        "\n",
        "2. **Qualidade das Reconstru√ß√µes**:\n",
        "   - **Fidelidade**: Similaridade com imagens originais\n",
        "   - **Blur**: Efeito de desfoque t√≠pico de VAEs\n",
        "   - **Consist√™ncia**: Padr√µes reconhec√≠veis\n",
        "\n",
        "3. **Gera√ß√£o de Novas Imagens**:\n",
        "   - **Diversidade**: Varia√ß√£o nas cores e padr√µes\n",
        "   - **Realismo**: Apar√™ncia convincente\n",
        "   - **Controle**: Manipula√ß√£o do espa√ßo latente\n",
        "\n",
        "---\n",
        "\n",
        "## üìä 7.6 Compara√ß√£o: GANs vs VAEs\n",
        "\n",
        "### An√°lise Comparativa\n",
        "\n",
        "![Compara√ß√£o GANs vs VAEs](https://cdn.jsdelivr.net/gh/rfapo/visao-computacional@main/images/modulo7/comparacao_gans_vaes.png)\n",
        "\n",
        "#### **Qualidade das Imagens**\n",
        "\n",
        "| Aspecto | GANs | VAEs |\n",
        "|---------|------|------|\n",
        "| **Nitidez** | Alta | M√©dia (blur) |\n",
        "| **Realismo** | Muito Alto | Alto |\n",
        "| **Diversidade** | Alta | M√©dia |\n",
        "| **Consist√™ncia** | Vari√°vel | Alta |\n",
        "\n",
        "#### **Treinamento**\n",
        "\n",
        "| Aspecto | GANs | VAEs |\n",
        "|---------|------|------|\n",
        "| **Estabilidade** | Baixa | Alta |\n",
        "| **Converg√™ncia** | Dif√≠cil | Garantida |\n",
        "| **Velocidade** | Lenta | R√°pida |\n",
        "| **Complexidade** | Alta | M√©dia |\n",
        "\n",
        "#### **Controle e Manipula√ß√£o**\n",
        "\n",
        "| Aspecto | GANs | VAEs |\n",
        "|---------|------|------|\n",
        "| **Espa√ßo Latente** | N√£o estruturado | Estruturado |\n",
        "| **Interpola√ß√£o** | Dif√≠cil | F√°cil |\n",
        "| **Manipula√ß√£o** | Limitada | Alta |\n",
        "| **Interpretabilidade** | Baixa | Alta |\n",
        "\n",
        "### Quando Usar Cada Um\n",
        "\n",
        "#### **Use GANs quando:**\n",
        "- ‚úÖ **Qualidade m√°xima** √© necess√°ria\n",
        "- ‚úÖ **Realismo** √© priorit√°rio\n",
        "- ‚úÖ **Diversidade** √© importante\n",
        "- ‚úÖ **Recursos computacionais** s√£o abundantes\n",
        "\n",
        "#### **Use VAEs quando:**\n",
        "- ‚úÖ **Treinamento est√°vel** √© necess√°rio\n",
        "- ‚úÖ **Controle** do espa√ßo latente √© importante\n",
        "- ‚úÖ **Interpretabilidade** √© priorit√°ria\n",
        "- ‚úÖ **Recursos limitados** est√£o dispon√≠veis\n",
        "\n",
        "---\n",
        "\n",
        "## üìù Resumo do M√≥dulo 7\n",
        "\n",
        "### Principais Conceitos Abordados\n",
        "\n",
        "1. **Fundamentos**: Gera√ß√£o sint√©tica de imagens\n",
        "2. **GANs**: Arquitetura adversarial\n",
        "3. **VAEs**: Autoencoders variacionais\n",
        "4. **Implementa√ß√£o**: Demonstra√ß√µes pr√°ticas\n",
        "5. **Compara√ß√£o**: An√°lise de vantagens e desvantagens\n",
        "\n",
        "### Demonstra√ß√µes Pr√°ticas\n",
        "\n",
        "**1. GAN Simples:**\n",
        "   - Implementa√ß√£o de gerador e discriminador\n",
        "   - Treinamento adversarial\n",
        "   - An√°lise de qualidade das imagens\n",
        "\n",
        "**2. VAE Simples:**\n",
        "   - Implementa√ß√£o de encoder e decoder\n",
        "   - Treinamento com perda de reconstru√ß√£o e KL\n",
        "   - An√°lise de reconstru√ß√µes e gera√ß√£o\n",
        "\n",
        "### Pr√≥ximos Passos\n",
        "\n",
        "No **M√≥dulo 8**, exploraremos **Vision Transformers e Mecanismos de Aten√ß√£o**, uma abordagem revolucion√°ria para vis√£o computacional.\n",
        "\n",
        "### Refer√™ncias Principais\n",
        "\n",
        "- [Generative Adversarial Networks - Goodfellow et al.](https://arxiv.org/abs/1406.2661)\n",
        "- [Auto-Encoding Variational Bayes - Kingma & Welling](https://arxiv.org/abs/1312.6114)\n",
        "\n",
        "---\n",
        "\n",
        "**Pr√≥ximo M√≥dulo**: Vision Transformers e Mecanismos de Aten√ß√£o"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéØ Conex√£o com o Pr√≥ximo M√≥dulo\n",
        "\n",
        "Agora que dominamos **GANs e VAEs** para gera√ß√£o sint√©tica, estamos preparados para explorar **Vision Transformers e Mecanismos de Aten√ß√£o**.\n",
        "\n",
        "No **M√≥dulo 8**, veremos como:\n",
        "\n",
        "### üîó **Conex√µes Diretas:**\n",
        "\n",
        "1. **Gera√ß√£o** ‚Üí **Aten√ß√£o**\n",
        "   - GANs geram imagens sint√©ticas\n",
        "   - Transformers usam aten√ß√£o para processar imagens\n",
        "\n",
        "2. **Espa√ßo Latente** ‚Üí **Espa√ßo de Aten√ß√£o**\n",
        "   - VAEs aprendem representa√ß√µes latentes\n",
        "   - Transformers aprendem representa√ß√µes de aten√ß√£o\n",
        "\n",
        "3. **Arquiteturas Complexas** ‚Üí **Arquiteturas de Aten√ß√£o**\n",
        "   - GANs e VAEs s√£o arquiteturas complexas\n",
        "   - Vision Transformers s√£o arquiteturas baseadas em aten√ß√£o\n",
        "\n",
        "4. **Aplica√ß√µes Pr√°ticas** ‚Üí **Aplica√ß√µes de Aten√ß√£o**\n",
        "   - Gera√ß√£o sint√©tica para cria√ß√£o\n",
        "   - Aten√ß√£o para an√°lise e classifica√ß√£o\n",
        "\n",
        "### üöÄ **Evolu√ß√£o Natural:**\n",
        "\n",
        "- **Gera√ß√£o** ‚Üí **An√°lise**\n",
        "- **Cria√ß√£o** ‚Üí **Compreens√£o**\n",
        "- **S√≠ntese** ‚Üí **Processamento**\n",
        "- **Arquiteturas Complexas** ‚Üí **Arquiteturas de Aten√ß√£o**\n",
        "\n",
        "Esta transi√ß√£o marca o in√≠cio da **era dos Vision Transformers** em vis√£o computacional!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üñºÔ∏è Imagens de Refer√™ncia - M√≥dulo 7\n\n",
        "![Arquitetura GAN](https://cdn.jsdelivr.net/gh/rfapo/visao-computacional@main/images/modulo7/arquitetura_gan.png)\n\n",
        "![Arquitetura VAE](https://cdn.jsdelivr.net/gh/rfapo/visao-computacional@main/images/modulo7/arquitetura_vae.png)\n\n",
        "![Conceito GANs](https://cdn.jsdelivr.net/gh/rfapo/visao-computacional@main/images/modulo7/gans_conceito.png)\n\n",
        "![Tipos de GANs](https://cdn.jsdelivr.net/gh/rfapo/visao-computacional@main/images/modulo7/tipos_gans.png)\n\n",
        "![Conceito VAEs](https://cdn.jsdelivr.net/gh/rfapo/visao-computacional@main/images/modulo7/vaes_conceito.png)\n\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}