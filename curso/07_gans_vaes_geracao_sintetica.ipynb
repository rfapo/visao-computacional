{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# M√≥dulo 7: GANs e VAEs - Gera√ß√£o Sint√©tica de Imagens## üéØ Objetivos de AprendizagemAo final deste m√≥dulo, voc√™ ser√° capaz de:- ‚úÖ Compreender os fundamentos de Generative Adversarial Networks (GANs)- ‚úÖ Entender Variational Autoencoders (VAEs) para gera√ß√£o de imagens- ‚úÖ Implementar modelos de gera√ß√£o sint√©tica- ‚úÖ Analisar aplica√ß√µes pr√°ticas de gera√ß√£o de imagens- ‚úÖ Comparar diferentes abordagens de gera√ß√£o---## üé® 7.1 Introdu√ß√£o √† Gera√ß√£o Sint√©tica de Imagens### Conceito Fundamental**Gera√ß√£o Sint√©tica de Imagens** √© o processo de criar imagens artificialmente usando modelos de machine learning, permitindo criar conte√∫do visual novo e realista.![Introdu√ß√£o Gera√ß√£o Sint√©tica](https://github.com/tensorflow/docs/blob/master/site/en/tutorials/generative/images/gan_diagram.png?raw=true)### Defini√ß√£o e Caracter√≠sticas**Defini√ß√£o:**- **Gera√ß√£o**: Cria√ß√£o de novas imagens- **Sint√©tica**: Produzida artificialmente- **Realista**: Visualmente convincente- **Control√°vel**: Par√¢metros ajust√°veis**Caracter√≠sticas Principais:**- **Novidade**: Imagens nunca vistas antes- **Variedade**: Diversidade de conte√∫do- **Qualidade**: Alta fidelidade visual- **Controle**: Manipula√ß√£o de caracter√≠sticas### Aplica√ß√µes Pr√°ticas#### **1. Arte Digital**- **Cria√ß√£o art√≠stica**: Gera√ß√£o de obras de arte- **Estilos diversos**: Pinturas, fotografias, ilustra√ß√µes- **Personaliza√ß√£o**: Adapta√ß√£o a prefer√™ncias- **Colabora√ß√£o**: Ferramenta para artistas#### **2. Data Augmentation**- **Aumento de datasets**: Cria√ß√£o de dados sint√©ticos- **Balanceamento**: Corre√ß√£o de desbalanceamento- **Variedade**: Diversifica√ß√£o de exemplos- **Efici√™ncia**: Redu√ß√£o de coleta manual#### **3. Design e Prototipagem**- **Conceitos visuais**: Ideias r√°pidas- **Itera√ß√£o**: M√∫ltiplas vers√µes- **Personaliza√ß√£o**: Adapta√ß√£o a necessidades- **Efici√™ncia**: Redu√ß√£o de tempo de desenvolvimento#### **4. Entretenimento**- **Jogos**: Assets visuais- **Filmes**: Efeitos especiais- **Realidade virtual**: Ambientes sint√©ticos- **Conte√∫do**: Gera√ß√£o de m√≠dia### Evolu√ß√£o da Gera√ß√£o Sint√©tica![Evolu√ß√£o Gera√ß√£o Sint√©tica](https://miro.medium.com/v2/resize:fit:1200/1*UdOybs9wOe3zW8vDAfj9VA@2x.png)#### **Progress√£o Hist√≥rica:**| Ano | Marco | Contribui√ß√£o ||-----|-------|--------------|| **2014** | GANs | Generative Adversarial Networks || **2015** | VAEs | Variational Autoencoders || **2016** | DCGAN | Deep Convolutional GANs || **2017** | Progressive GAN | Resolu√ß√£o crescente || **2018** | StyleGAN | Controle de estilo || **2020** | Diffusion Models | Revolu√ß√£o no campo || **2022** | DALL-E 2 | Populariza√ß√£o |#### **Marcos Importantes:**- **2014**: Generative Adversarial Networks - Goodfellow et al.- **2015**: Auto-Encoding Variational Bayes - Kingma & Welling- **2016**: Deep Convolutional GANs - Radford et al.- **2017**: Progressive Growing of GANs - Karras et al.- **2019**: StyleGAN - Karras et al.- **2021**: DALL-E - Ramesh et al.---## ‚öîÔ∏è 7.2 Generative Adversarial Networks (GANs)### Conceito Fundamental**GANs** s√£o arquiteturas que consistem em dois modelos neurais competindo entre si: um **gerador** que cria imagens sint√©ticas e um **discriminador** que tenta distinguir entre imagens reais e sint√©ticas.![Arquitetura GANs](https://developers.google.com/static/machine-learning/gan/images/gan_diagram.svg)### Componentes Principais#### **1. Gerador (Generator)****Fun√ß√£o:**- **Entrada**: Ru√≠do aleat√≥rio (latent vector)- **Sa√≠da**: Imagem sint√©tica- **Objetivo**: Enganar o discriminador- **Treinamento**: Minimizar perda do discriminador**Arquitetura:**```Ru√≠do ‚Üí FC ‚Üí Reshape ‚Üí Conv Transpose ‚Üí Imagem```**Caracter√≠sticas:**- **Upsampling**: Aumento de resolu√ß√£o- **Convolu√ß√µes transpostas**: Gera√ß√£o de features- **Normaliza√ß√£o**: Batch normalization- **Ativa√ß√£o**: Tanh para sa√≠da#### **2. Discriminador (Discriminator)****Fun√ß√£o:**- **Entrada**: Imagem (real ou sint√©tica)- **Sa√≠da**: Probabilidade de ser real- **Objetivo**: Distinguir real de sint√©tico- **Treinamento**: Maximizar precis√£o**Arquitetura:**```Imagem ‚Üí Conv ‚Üí Pool ‚Üí Conv ‚Üí Pool ‚Üí FC ‚Üí Probabilidade```**Caracter√≠sticas:**- **Downsampling**: Redu√ß√£o de resolu√ß√£o- **Convolu√ß√µes**: Extra√ß√£o de features- **Pooling**: Redu√ß√£o de dimensionalidade- **Ativa√ß√£o**: Sigmoid para sa√≠da### Processo de Treinamento#### **1. Treinamento do Discriminador**```1. Imagens reais ‚Üí Discriminador ‚Üí Loss real2. Ru√≠do ‚Üí Gerador ‚Üí Imagens sint√©ticas3. Imagens sint√©ticas ‚Üí Discriminador ‚Üí Loss sint√©tico4. Loss total = Loss real + Loss sint√©tico5. Backpropagation no discriminador```#### **2. Treinamento do Gerador**```1. Ru√≠do ‚Üí Gerador ‚Üí Imagens sint√©ticas2. Imagens sint√©ticas ‚Üí Discriminador ‚Üí Probabilidade3. Loss = -log(probabilidade)4. Backpropagation no gerador```### Vantagens e Desvantagens#### **Vantagens:**- ‚úÖ **Qualidade alta**: Imagens muito realistas- ‚úÖ **Variedade**: Diversidade de conte√∫do- ‚úÖ **Flexibilidade**: M√∫ltiplas aplica√ß√µes- ‚úÖ **Inova√ß√£o**: Abordagem √∫nica#### **Desvantagens:**- ‚ùå **Treinamento inst√°vel**: Dif√≠cil converg√™ncia- ‚ùå **Mode collapse**: Falta de diversidade- ‚ùå **Computa√ß√£o intensiva**: Recursos elevados- ‚ùå **Controle limitado**: Dificuldade de manipula√ß√£o---## üîÑ 7.3 Variational Autoencoders (VAEs)### Conceito Fundamental**VAEs** s√£o modelos generativos que aprendem a representar dados em um espa√ßo latente de menor dimensionalidade, permitindo gera√ß√£o de novas amostras atrav√©s de amostragem do espa√ßo latente.![Arquitetura VAEs](https://lilianweng.github.io/posts/2018-08-12-vae/vae-gaussian.png)### Componentes Principais#### **1. Encoder****Fun√ß√£o:**- **Entrada**: Imagem real- **Sa√≠da**: Par√¢metros da distribui√ß√£o latente (Œº, œÉ)- **Objetivo**: Comprimir informa√ß√£o- **Resultado**: Representa√ß√£o latente**Processo:**```Imagem ‚Üí Conv ‚Üí Pool ‚Üí Conv ‚Üí Pool ‚Üí FC ‚Üí Œº, œÉ```#### **2. Decoder****Fun√ß√£o:**- **Entrada**: Amostra do espa√ßo latente- **Sa√≠da**: Imagem reconstru√≠da- **Objetivo**: Reconstruir imagem original- **Resultado**: Imagem sint√©tica**Processo:**```z ‚Üí FC ‚Üí Reshape ‚Üí Conv Transpose ‚Üí Imagem```### Espa√ßo Latente#### **Caracter√≠sticas:**- **Dimensionalidade**: Menor que dados originais- **Distribui√ß√£o**: Gaussiana multivariada- **Continuidade**: Espa√ßo cont√≠nuo- **Interpretabilidade**: Caracter√≠sticas sem√¢nticas#### **Amostragem:**```z = Œº + œÉ ‚äô Œµonde Œµ ~ N(0, I)```### Fun√ß√£o de Perda#### **Loss Total:**```L = L_reconstruction + Œ≤ * L_KL```#### **1. Loss de Reconstru√ß√£o:**```L_reconstruction = ||x - x'||¬≤```#### **2. Loss KL Divergence:**```L_KL = KL(q(z|x) || p(z))```### Vantagens e Desvantagens#### **Vantagens:**- ‚úÖ **Treinamento est√°vel**: Converg√™ncia garantida- ‚úÖ **Controle**: Manipula√ß√£o do espa√ßo latente- ‚úÖ **Interpretabilidade**: Caracter√≠sticas sem√¢nticas- ‚úÖ **Efici√™ncia**: Treinamento mais r√°pido#### **Desvantagens:**- ‚ùå **Qualidade**: Imagens menos n√≠tidas- ‚ùå **Variedade**: Menos diversidade- ‚ùå **Blur**: Efeito de desfoque- ‚ùå **Complexidade**: Implementa√ß√£o mais complexa---## üîç 7.4 Demonstra√ß√£o Pr√°tica: GANs SimplesVamos implementar e visualizar um GAN simples para gera√ß√£o de imagens:"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "class SimpleGAN:\n",
    "    \"\"\"Implementa√ß√£o de um GAN simples para demonstra√ß√£o\"\"\"\n",
    "    \n",
    "    def __init__(self, latent_dim=100, img_size=64):\n",
    "        self.latent_dim = latent_dim\n",
    "        self.img_size = img_size\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        # Inicializar modelos\n",
    "        self.generator = self._build_generator()\n",
    "        self.discriminator = self._build_discriminator()\n",
    "        \n",
    "        # Otimizadores\n",
    "        self.g_optimizer = optim.Adam(self.generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "        self.d_optimizer = optim.Adam(self.discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "        \n",
    "        # Loss function\n",
    "        self.criterion = nn.BCELoss()\n",
    "        \n",
    "        # Hist√≥rico de treinamento\n",
    "        self.g_losses = []\n",
    "        self.d_losses = []\n",
    "        \n",
    "    def _build_generator(self):\n",
    "        \"\"\"Constr√≥i o gerador\"\"\"\n",
    "        \n",
    "        class Generator(nn.Module):\n",
    "            def __init__(self, latent_dim, img_size):\n",
    "                super(Generator, self).__init__()\n",
    "                \n",
    "                # Camadas fully connected\n",
    "                self.fc1 = nn.Linear(latent_dim, 256)\n",
    "                self.fc2 = nn.Linear(256, 512)\n",
    "                self.fc3 = nn.Linear(512, 1024)\n",
    "                self.fc4 = nn.Linear(1024, img_size * img_size * 3)\n",
    "                \n",
    "                # Dropout\n",
    "                self.dropout = nn.Dropout(0.3)\n",
    "                \n",
    "            def forward(self, x):\n",
    "                x = F.relu(self.fc1(x))\n",
    "                x = self.dropout(x)\n",
    "                x = F.relu(self.fc2(x))\n",
    "                x = self.dropout(x)\n",
    "                x = F.relu(self.fc3(x))\n",
    "                x = self.dropout(x)\n",
    "                x = torch.tanh(self.fc4(x))\n",
    "                \n",
    "                # Reshape para imagem\n",
    "                x = x.view(x.size(0), 3, self.img_size, self.img_size)\n",
    "                return x\n",
    "        \n",
    "        return Generator(self.latent_dim, self.img_size).to(self.device)\n",
    "    \n",
    "    def _build_discriminator(self):\n",
    "        \"\"\"Constr√≥i o discriminador\"\"\"\n",
    "        \n",
    "        class Discriminator(nn.Module):\n",
    "            def __init__(self, img_size):\n",
    "                super(Discriminator, self).__init__()\n",
    "                \n",
    "                # Camadas fully connected\n",
    "                self.fc1 = nn.Linear(img_size * img_size * 3, 1024)\n",
    "                self.fc2 = nn.Linear(1024, 512)\n",
    "                self.fc3 = nn.Linear(512, 256)\n",
    "                self.fc4 = nn.Linear(256, 1)\n",
    "                \n",
    "                # Dropout\n",
    "                self.dropout = nn.Dropout(0.3)\n",
    "                \n",
    "            def forward(self, x):\n",
    "                x = x.view(x.size(0), -1)\n",
    "                x = F.leaky_relu(self.fc1(x), 0.2)\n",
    "                x = self.dropout(x)\n",
    "                x = F.leaky_relu(self.fc2(x), 0.2)\n",
    "                x = self.dropout(x)\n",
    "                x = F.leaky_relu(self.fc3(x), 0.2)\n",
    "                x = self.dropout(x)\n",
    "                x = torch.sigmoid(self.fc4(x))\n",
    "                return x\n",
    "        \n",
    "        return Discriminator(self.img_size).to(self.device)\n",
    "    \n",
    "    def create_sample_data(self, num_samples=1000):\n",
    "        \"\"\"Cria dados de exemplo para demonstra√ß√£o\"\"\"\n",
    "        \n",
    "        # Criar imagens sint√©ticas simples\n",
    "        images = []\n",
    "        \n",
    "        for _ in range(num_samples):\n",
    "            # Criar imagem com padr√µes simples\n",
    "            img = np.random.rand(3, self.img_size, self.img_size) * 2 - 1  # Normalizar para [-1, 1]\n",
    "            \n",
    "            # Adicionar padr√µes\n",
    "            if np.random.random() > 0.5:\n",
    "                # Padr√£o circular\n",
    "                center_x, center_y = np.random.randint(20, self.img_size-20, 2)\n",
    "                radius = np.random.randint(10, 20)\n",
    "                \n",
    "                y, x = np.ogrid[:self.img_size, :self.img_size]\n",
    "                mask = (x - center_x)**2 + (y - center_y)**2 <= radius**2\n",
    "                \n",
    "                img[0, mask] = 1.0  # Red\n",
    "                img[1, mask] = 0.0  # Green\n",
    "                img[2, mask] = 0.0  # Blue\n",
    "            else:\n",
    "                # Padr√£o retangular\n",
    "                x1, y1 = np.random.randint(0, self.img_size-30, 2)\n",
    "                x2, y2 = x1 + np.random.randint(20, 40), y1 + np.random.randint(20, 40)\n",
    "                \n",
    "                img[0, y1:y2, x1:x2] = 0.0  # Red\n",
    "                img[1, y1:y2, x1:x2] = 1.0  # Green\n",
    "                img[2, y1:y2, x1:x2] = 0.0  # Blue\n",
    "            \n",
    "            images.append(img)\n",
    "        \n",
    "        return torch.FloatTensor(images)\n",
    "    \n",
    "    def train_step(self, real_images, batch_size):\n",
    "        \"\"\"Executa um passo de treinamento\"\"\"\n",
    "        \n",
    "        # Labels\n",
    "        real_labels = torch.ones(batch_size, 1).to(self.device)\n",
    "        fake_labels = torch.zeros(batch_size, 1).to(self.device)\n",
    "        \n",
    "        # Treinar Discriminador\n",
    "        self.d_optimizer.zero_grad()\n",
    "        \n",
    "        # Loss com imagens reais\n",
    "        real_output = self.discriminator(real_images)\n",
    "        d_loss_real = self.criterion(real_output, real_labels)\n",
    "        \n",
    "        # Loss com imagens sint√©ticas\n",
    "        noise = torch.randn(batch_size, self.latent_dim).to(self.device)\n",
    "        fake_images = self.generator(noise)\n",
    "        fake_output = self.discriminator(fake_images.detach())\n",
    "        d_loss_fake = self.criterion(fake_output, fake_labels)\n",
    "        \n",
    "        d_loss = d_loss_real + d_loss_fake\n",
    "        d_loss.backward()\n",
    "        self.d_optimizer.step()\n",
    "        \n",
    "        # Treinar Gerador\n",
    "        self.g_optimizer.zero_grad()\n",
    "        \n",
    "        noise = torch.randn(batch_size, self.latent_dim).to(self.device)\n",
    "        fake_images = self.generator(noise)\n",
    "        fake_output = self.discriminator(fake_images)\n",
    "        g_loss = self.criterion(fake_output, real_labels)\n",
    "        \n",
    "        g_loss.backward()\n",
    "        self.g_optimizer.step()\n",
    "        \n",
    "        return d_loss.item(), g_loss.item()\n",
    "    \n",
    "    def train(self, epochs=50, batch_size=32):\n",
    "        \"\"\"Treina o GAN\"\"\"\n",
    "        \n",
    "        # Criar dados\n",
    "        real_images = self.create_sample_data(1000)\n",
    "        dataset = TensorDataset(real_images)\n",
    "        dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "        \n",
    "        print(f\"Iniciando treinamento do GAN para {epochs} √©pocas...\")\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            epoch_d_loss = 0\n",
    "            epoch_g_loss = 0\n",
    "            \n",
    "            for batch_idx, (real_batch,) in enumerate(dataloader):\n",
    "                real_batch = real_batch.to(self.device)\n",
    "                \n",
    "                d_loss, g_loss = self.train_step(real_batch, real_batch.size(0))\n",
    "                \n",
    "                epoch_d_loss += d_loss\n",
    "                epoch_g_loss += g_loss\n",
    "            \n",
    "            # M√©dias\n",
    "            avg_d_loss = epoch_d_loss / len(dataloader)\n",
    "            avg_g_loss = epoch_g_loss / len(dataloader)\n",
    "            \n",
    "            self.d_losses.append(avg_d_loss)\n",
    "            self.g_losses.append(avg_g_loss)\n",
    "            \n",
    "            if epoch % 10 == 0:\n",
    "                print(f\"√âpoca {epoch}/{epochs} - D Loss: {avg_d_loss:.4f}, G Loss: {avg_g_loss:.4f}\")\n",
    "        \n",
    "        print(\"Treinamento conclu√≠do!\")\n",
    "    \n",
    "    def generate_samples(self, num_samples=16):\n",
    "        \"\"\"Gera amostras sint√©ticas\"\"\"\n",
    "        \n",
    "        self.generator.eval()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            noise = torch.randn(num_samples, self.latent_dim).to(self.device)\n",
    "            fake_images = self.generator(noise)\n",
    "            \n",
    "            # Converter para numpy\n",
    "            fake_images = fake_images.cpu().numpy()\n",
    "            \n",
    "            # Normalizar para [0, 1]\n",
    "            fake_images = (fake_images + 1) / 2\n",
    "            fake_images = np.clip(fake_images, 0, 1)\n",
    "            \n",
    "        return fake_images\n",
    "    \n",
    "    def visualize_results(self):\n",
    "        \"\"\"Visualiza resultados do treinamento\"\"\"\n",
    "        \n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "        \n",
    "        # Gr√°fico de perdas\n",
    "        axes[0, 0].plot(self.d_losses, label='Discriminador', color='red')\n",
    "        axes[0, 0].plot(self.g_losses, label='Gerador', color='blue')\n",
    "        axes[0, 0].set_title('Evolu√ß√£o das Perdas')\n",
    "        axes[0, 0].set_xlabel('√âpoca')\n",
    "        axes[0, 0].set_ylabel('Perda')\n",
    "        axes[0, 0].legend()\n",
    "        axes[0, 0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Amostras geradas\n",
    "        fake_images = self.generate_samples(16)\n",
    "        \n",
    "        # Criar grid de imagens\n",
    "        grid_img = np.zeros((4 * self.img_size, 4 * self.img_size, 3))\n",
    "        \n",
    "        for i in range(4):\n",
    "            for j in range(4):\n",
    "                idx = i * 4 + j\n",
    "                if idx < len(fake_images):\n",
    "                    img = fake_images[idx].transpose(1, 2, 0)\n",
    "                    grid_img[i*self.img_size:(i+1)*self.img_size, \n",
    "                           j*self.img_size:(j+1)*self.img_size] = img\n",
    "        \n",
    "        axes[0, 1].imshow(grid_img)\n",
    "        axes[0, 1].set_title('Amostras Geradas')\n",
    "        axes[0, 1].axis('off')\n",
    "        \n",
    "        # An√°lise de qualidade\n",
    "        fake_images = self.generate_samples(100)\n",
    "        \n",
    "        # Calcular estat√≠sticas\n",
    "        mean_values = np.mean(fake_images, axis=(2, 3))\n",
    "        std_values = np.std(fake_images, axis=(2, 3))\n",
    "        \n",
    "        axes[1, 0].scatter(mean_values[:, 0], mean_values[:, 1], alpha=0.6, label='Red vs Green')\n",
    "        axes[1, 0].set_title('Distribui√ß√£o de Cores (M√©dia)')\n",
    "        axes[1, 0].set_xlabel('Red')\n",
    "        axes[1, 0].set_ylabel('Green')\n",
    "        axes[1, 0].legend()\n",
    "        axes[1, 0].grid(True, alpha=0.3)\n",
    "        \n",
    "        axes[1, 1].scatter(std_values[:, 0], std_values[:, 1], alpha=0.6, label='Red vs Green')\n",
    "        axes[1, 1].set_title('Distribui√ß√£o de Cores (Desvio Padr√£o)')\n",
    "        axes[1, 1].set_xlabel('Red')\n",
    "        axes[1, 1].set_ylabel('Green')\n",
    "        axes[1, 1].legend()\n",
    "        axes[1, 1].grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # An√°lise quantitativa\n",
    "        print(\"=== AN√ÅLISE QUANTITATIVA DO GAN ===\")\n",
    "        print(f\"\\nEstat√≠sticas de Treinamento:\")\n",
    "        print(f\"  - √âpocas: {len(self.d_losses)}\")\n",
    "        print(f\"  - Perda final do Discriminador: {self.d_losses[-1]:.4f}\")\n",
    "        print(f\"  - Perda final do Gerador: {self.g_losses[-1]:.4f}\")\n",
    "        print(f\"  - Diferen√ßa de perdas: {abs(self.d_losses[-1] - self.g_losses[-1]):.4f}\")\n",
    "        \n",
    "        print(f\"\\nEstat√≠sticas das Imagens Geradas:\")\n",
    "        print(f\"  - M√©dia Red: {np.mean(mean_values[:, 0]):.3f}\")\n",
    "        print(f\"  - M√©dia Green: {np.mean(mean_values[:, 1]):.3f}\")\n",
    "        print(f\"  - M√©dia Blue: {np.mean(mean_values[:, 2]):.3f}\")\n",
    "        print(f\"  - Desvio Red: {np.mean(std_values[:, 0]):.3f}\")\n",
    "        print(f\"  - Desvio Green: {np.mean(std_values[:, 1]):.3f}\")\n",
    "        print(f\"  - Desvio Blue: {np.mean(std_values[:, 2]):.3f}\")\n",
    "        \n",
    "        return fake_images\n",
    "\n",
    "# Executar demonstra√ß√£o\n",
    "print(\"=== DEMONSTRA√á√ÉO: GAN SIMPLES ===\")\n",
    "gan = SimpleGAN(latent_dim=100, img_size=32)\n",
    "gan.train(epochs=30, batch_size=16)\n",
    "generated_images = gan.visualize_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An√°lise dos Resultados\n",
    "\n",
    "**Observa√ß√µes Importantes:**\n",
    "\n",
    "1. **Evolu√ß√£o das Perdas**:\n",
    "   - **Discriminador**: Deve diminuir gradualmente\n",
    "   - **Gerador**: Deve diminuir para enganar o discriminador\n",
    "   - **Equil√≠brio**: Perdas devem se estabilizar\n",
    "\n",
    "2. **Qualidade das Imagens**:\n",
    "   - **Diversidade**: Varia√ß√£o nas cores e padr√µes\n",
    "   - **Realismo**: Apar√™ncia convincente\n",
    "   - **Consist√™ncia**: Padr√µes reconhec√≠veis\n",
    "\n",
    "3. **Distribui√ß√£o de Cores**:\n",
    "   - **M√©dia**: Concentra√ß√£o em certas cores\n",
    "   - **Desvio**: Variabilidade das cores\n",
    "   - **Balanceamento**: Distribui√ß√£o equilibrada\n",
    "\n",
    "---\n",
    "\n",
    "## üîÑ 7.5 Demonstra√ß√£o Pr√°tica: VAEs Simples\n",
    "\n",
    "Vamos implementar e visualizar um VAE simples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "class SimpleVAE:\n",
    "    \"\"\"Implementa√ß√£o de um VAE simples para demonstra√ß√£o\"\"\"\n",
    "    \n",
    "    def __init__(self, latent_dim=20, img_size=32):\n",
    "        self.latent_dim = latent_dim\n",
    "        self.img_size = img_size\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        # Inicializar modelo\n",
    "        self.vae = self._build_vae()\n",
    "        \n",
    "        # Otimizador\n",
    "        self.optimizer = optim.Adam(self.vae.parameters(), lr=0.001)\n",
    "        \n",
    "        # Hist√≥rico de treinamento\n",
    "        self.reconstruction_losses = []\n",
    "        self.kl_losses = []\n",
    "        self.total_losses = []\n",
    "        \n",
    "    def _build_vae(self):\n",
    "        \"\"\"Constr√≥i o VAE\"\"\"\n",
    "        \n",
    "        class VAE(nn.Module):\n",
    "            def __init__(self, latent_dim, img_size):\n",
    "                super(VAE, self).__init__()\n",
    "                \n",
    "                self.latent_dim = latent_dim\n",
    "                self.img_size = img_size\n",
    "                \n",
    "                # Encoder\n",
    "                self.encoder = nn.Sequential(\n",
    "                    nn.Linear(img_size * img_size * 3, 512),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(512, 256),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(256, 128),\n",
    "                    nn.ReLU()\n",
    "                )\n",
    "                \n",
    "                # Latent space\n",
    "                self.fc_mu = nn.Linear(128, latent_dim)\n",
    "                self.fc_logvar = nn.Linear(128, latent_dim)\n",
    "                \n",
    "                # Decoder\n",
    "                self.decoder = nn.Sequential(\n",
    "                    nn.Linear(latent_dim, 128),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(128, 256),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(256, 512),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(512, img_size * img_size * 3),\n",
    "                    nn.Tanh()\n",
    "                )\n",
    "                \n",
    "            def encode(self, x):\n",
    "                h = self.encoder(x.view(x.size(0), -1))\n",
    "                mu = self.fc_mu(h)\n",
    "                logvar = self.fc_logvar(h)\n",
    "                return mu, logvar\n",
    "                \n",
    "            def reparameterize(self, mu, logvar):\n",
    "                std = torch.exp(0.5 * logvar)\n",
    "                eps = torch.randn_like(std)\n",
    "                return mu + eps * std\n",
    "                \n",
    "            def decode(self, z):\n",
    "                h = self.decoder(z)\n",
    "                return h.view(-1, 3, self.img_size, self.img_size)\n",
    "                \n",
    "            def forward(self, x):\n",
    "                mu, logvar = self.encode(x)\n",
    "                z = self.reparameterize(mu, logvar)\n",
    "                recon_x = self.decode(z)\n",
    "                return recon_x, mu, logvar\n",
    "        \n",
    "        return VAE(self.latent_dim, self.img_size).to(self.device)\n",
    "    \n",
    "    def create_sample_data(self, num_samples=1000):\n",
    "        \"\"\"Cria dados de exemplo para demonstra√ß√£o\"\"\"\n",
    "        \n",
    "        # Criar imagens sint√©ticas simples\n",
    "        images = []\n",
    "        \n",
    "        for _ in range(num_samples):\n",
    "            # Criar imagem com padr√µes simples\n",
    "            img = np.random.rand(3, self.img_size, self.img_size) * 2 - 1  # Normalizar para [-1, 1]\n",
    "            \n",
    "            # Adicionar padr√µes\n",
    "            if np.random.random() > 0.5:\n",
    "                # Padr√£o circular\n",
    "                center_x, center_y = np.random.randint(10, self.img_size-10, 2)\n",
    "                radius = np.random.randint(5, 15)\n",
    "                \n",
    "                y, x = np.ogrid[:self.img_size, :self.img_size]\n",
    "                mask = (x - center_x)**2 + (y - center_y)**2 <= radius**2\n",
    "                \n",
    "                img[0, mask] = 1.0  # Red\n",
    "                img[1, mask] = 0.0  # Green\n",
    "                img[2, mask] = 0.0  # Blue\n",
    "            else:\n",
    "                # Padr√£o retangular\n",
    "                x1, y1 = np.random.randint(0, self.img_size-20, 2)\n",
    "                x2, y2 = x1 + np.random.randint(10, 25), y1 + np.random.randint(10, 25)\n",
    "                \n",
    "                img[0, y1:y2, x1:x2] = 0.0  # Red\n",
    "                img[1, y1:y2, x1:x2] = 1.0  # Green\n",
    "                img[2, y1:y2, x1:x2] = 0.0  # Blue\n",
    "            \n",
    "            images.append(img)\n",
    "        \n",
    "        return torch.FloatTensor(images)\n",
    "    \n",
    "    def loss_function(self, recon_x, x, mu, logvar):\n",
    "        \"\"\"Calcula a fun√ß√£o de perda do VAE\"\"\"\n",
    "        \n",
    "        # Loss de reconstru√ß√£o (MSE)\n",
    "        recon_loss = F.mse_loss(recon_x, x, reduction='sum')\n",
    "        \n",
    "        # Loss KL divergence\n",
    "        kl_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "        \n",
    "        return recon_loss, kl_loss\n",
    "    \n",
    "    def train_step(self, batch):\n",
    "        \"\"\"Executa um passo de treinamento\"\"\"\n",
    "        \n",
    "        self.optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        recon_batch, mu, logvar = self.vae(batch)\n",
    "        \n",
    "        # Calcular perdas\n",
    "        recon_loss, kl_loss = self.loss_function(recon_batch, batch, mu, logvar)\n",
    "        total_loss = recon_loss + kl_loss\n",
    "        \n",
    "        # Backward pass\n",
    "        total_loss.backward()\n",
    "        self.optimizer.step()\n",
    "        \n",
    "        return recon_loss.item(), kl_loss.item(), total_loss.item()\n",
    "    \n",
    "    def train(self, epochs=50, batch_size=32):\n",
    "        \"\"\"Treina o VAE\"\"\"\n",
    "        \n",
    "        # Criar dados\n",
    "        real_images = self.create_sample_data(1000)\n",
    "        dataset = TensorDataset(real_images)\n",
    "        dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "        \n",
    "        print(f\"Iniciando treinamento do VAE para {epochs} √©pocas...\")\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            epoch_recon_loss = 0\n",
    "            epoch_kl_loss = 0\n",
    "            epoch_total_loss = 0\n",
    "            \n",
    "            for batch_idx, (batch,) in enumerate(dataloader):\n",
    "                batch = batch.to(self.device)\n",
    "                \n",
    "                recon_loss, kl_loss, total_loss = self.train_step(batch)\n",
    "                \n",
    "                epoch_recon_loss += recon_loss\n",
    "                epoch_kl_loss += kl_loss\n",
    "                epoch_total_loss += total_loss\n",
    "            \n",
    "            # M√©dias\n",
    "            avg_recon_loss = epoch_recon_loss / len(dataloader)\n",
    "            avg_kl_loss = epoch_kl_loss / len(dataloader)\n",
    "            avg_total_loss = epoch_total_loss / len(dataloader)\n",
    "            \n",
    "            self.reconstruction_losses.append(avg_recon_loss)\n",
    "            self.kl_losses.append(avg_kl_loss)\n",
    "            self.total_losses.append(avg_total_loss)\n",
    "            \n",
    "            if epoch % 10 == 0:\n",
    "                print(f\"√âpoca {epoch}/{epochs} - Recon Loss: {avg_recon_loss:.4f}, KL Loss: {avg_kl_loss:.4f}, Total Loss: {avg_total_loss:.4f}\")\n",
    "        \n",
    "        print(\"Treinamento conclu√≠do!\")\n",
    "    \n",
    "    def generate_samples(self, num_samples=16):\n",
    "        \"\"\"Gera amostras sint√©ticas\"\"\"\n",
    "        \n",
    "        self.vae.eval()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # Amostrar do espa√ßo latente\n",
    "            z = torch.randn(num_samples, self.latent_dim).to(self.device)\n",
    "            fake_images = self.vae.decode(z)\n",
    "            \n",
    "            # Converter para numpy\n",
    "            fake_images = fake_images.cpu().numpy()\n",
    "            \n",
    "            # Normalizar para [0, 1]\n",
    "            fake_images = (fake_images + 1) / 2\n",
    "            fake_images = np.clip(fake_images, 0, 1)\n",
    "            \n",
    "        return fake_images\n",
    "    \n",
    "    def reconstruct_samples(self, num_samples=16):\n",
    "        \"\"\"Reconstr√≥i amostras reais\"\"\"\n",
    "        \n",
    "        self.vae.eval()\n",
    "        \n",
    "        # Criar amostras reais\n",
    "        real_images = self.create_sample_data(num_samples)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            real_images = real_images.to(self.device)\n",
    "            recon_images, _, _ = self.vae(real_images)\n",
    "            \n",
    "            # Converter para numpy\n",
    "            real_images = real_images.cpu().numpy()\n",
    "            recon_images = recon_images.cpu().numpy()\n",
    "            \n",
    "            # Normalizar para [0, 1]\n",
    "            real_images = (real_images + 1) / 2\n",
    "            recon_images = (recon_images + 1) / 2\n",
    "            real_images = np.clip(real_images, 0, 1)\n",
    "            recon_images = np.clip(recon_images, 0, 1)\n",
    "            \n",
    "        return real_images, recon_images\n",
    "    \n",
    "    def visualize_results(self):\n",
    "        \"\"\"Visualiza resultados do treinamento\"\"\"\n",
    "        \n",
    "        fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "        \n",
    "        # Gr√°fico de perdas\n",
    "        axes[0, 0].plot(self.reconstruction_losses, label='Reconstru√ß√£o', color='blue')\n",
    "        axes[0, 0].plot(self.kl_losses, label='KL Divergence', color='red')\n",
    "        axes[0, 0].plot(self.total_losses, label='Total', color='green')\n",
    "        axes[0, 0].set_title('Evolu√ß√£o das Perdas')\n",
    "        axes[0, 0].set_xlabel('√âpoca')\n",
    "        axes[0, 0].set_ylabel('Perda')\n",
    "        axes[0, 0].legend()\n",
    "        axes[0, 0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Amostras geradas\n",
    "        fake_images = self.generate_samples(16)\n",
    "        \n",
    "        # Criar grid de imagens\n",
    "        grid_img = np.zeros((4 * self.img_size, 4 * self.img_size, 3))\n",
    "        \n",
    "        for i in range(4):\n",
    "            for j in range(4):\n",
    "                idx = i * 4 + j\n",
    "                if idx < len(fake_images):\n",
    "                    img = fake_images[idx].transpose(1, 2, 0)\n",
    "                    grid_img[i*self.img_size:(i+1)*self.img_size, \n",
    "                           j*self.img_size:(j+1)*self.img_size] = img\n",
    "        \n",
    "        axes[0, 1].imshow(grid_img)\n",
    "        axes[0, 1].set_title('Amostras Geradas')\n",
    "        axes[0, 1].axis('off')\n",
    "        \n",
    "        # Reconstru√ß√µes\n",
    "        real_images, recon_images = self.reconstruct_samples(16)\n",
    "        \n",
    "        # Grid de imagens reais\n",
    "        real_grid = np.zeros((4 * self.img_size, 4 * self.img_size, 3))\n",
    "        for i in range(4):\n",
    "            for j in range(4):\n",
    "                idx = i * 4 + j\n",
    "                if idx < len(real_images):\n",
    "                    img = real_images[idx].transpose(1, 2, 0)\n",
    "                    real_grid[i*self.img_size:(i+1)*self.img_size, \n",
    "                            j*self.img_size:(j+1)*self.img_size] = img\n",
    "        \n",
    "        axes[0, 2].imshow(real_grid)\n",
    "        axes[0, 2].set_title('Imagens Reais')\n",
    "        axes[0, 2].axis('off')\n",
    "        \n",
    "        # Grid de reconstru√ß√µes\n",
    "        recon_grid = np.zeros((4 * self.img_size, 4 * self.img_size, 3))\n",
    "        for i in range(4):\n",
    "            for j in range(4):\n",
    "                idx = i * 4 + j\n",
    "                if idx < len(recon_images):\n",
    "                    img = recon_images[idx].transpose(1, 2, 0)\n",
    "                    recon_grid[i*self.img_size:(i+1)*self.img_size, \n",
    "                             j*self.img_size:(j+1)*self.img_size] = img\n",
    "        \n",
    "        axes[1, 0].imshow(recon_grid)\n",
    "        axes[1, 0].set_title('Reconstru√ß√µes')\n",
    "        axes[1, 0].axis('off')\n",
    "        \n",
    "        # An√°lise de qualidade\n",
    "        fake_images = self.generate_samples(100)\n",
    "        \n",
    "        # Calcular estat√≠sticas\n",
    "        mean_values = np.mean(fake_images, axis=(2, 3))\n",
    "        std_values = np.std(fake_images, axis=(2, 3))\n",
    "        \n",
    "        axes[1, 1].scatter(mean_values[:, 0], mean_values[:, 1], alpha=0.6, label='Red vs Green')\n",
    "        axes[1, 1].set_title('Distribui√ß√£o de Cores (M√©dia)')\n",
    "        axes[1, 1].set_xlabel('Red')\n",
    "        axes[1, 1].set_ylabel('Green')\n",
    "        axes[1, 1].legend()\n",
    "        axes[1, 1].grid(True, alpha=0.3)\n",
    "        \n",
    "        axes[1, 2].scatter(std_values[:, 0], std_values[:, 1], alpha=0.6, label='Red vs Green')\n",
    "        axes[1, 2].set_title('Distribui√ß√£o de Cores (Desvio Padr√£o)')\n",
    "        axes[1, 2].set_xlabel('Red')\n",
    "        axes[1, 2].set_ylabel('Green')\n",
    "        axes[1, 2].legend()\n",
    "        axes[1, 2].grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # An√°lise quantitativa\n",
    "        print(\"=== AN√ÅLISE QUANTITATIVA DO VAE ===\")\n",
    "        print(f\"\\nEstat√≠sticas de Treinamento:\")\n",
    "        print(f\"  - √âpocas: {len(self.total_losses)}\")\n",
    "        print(f\"  - Perda final de Reconstru√ß√£o: {self.reconstruction_losses[-1]:.4f}\")\n",
    "        print(f\"  - Perda final KL: {self.kl_losses[-1]:.4f}\")\n",
    "        print(f\"  - Perda final Total: {self.total_losses[-1]:.4f}\")\n",
    "        \n",
    "        print(f\"\\nEstat√≠sticas das Imagens Geradas:\")\n",
    "        print(f\"  - M√©dia Red: {np.mean(mean_values[:, 0]):.3f}\")\n",
    "        print(f\"  - M√©dia Green: {np.mean(mean_values[:, 1]):.3f}\")\n",
    "        print(f\"  - M√©dia Blue: {np.mean(mean_values[:, 2]):.3f}\")\n",
    "        print(f\"  - Desvio Red: {np.mean(std_values[:, 0]):.3f}\")\n",
    "        print(f\"  - Desvio Green: {np.mean(std_values[:, 1]):.3f}\")\n",
    "        print(f\"  - Desvio Blue: {np.mean(std_values[:, 2]):.3f}\")\n",
    "        \n",
    "        return fake_images\n",
    "\n",
    "# Executar demonstra√ß√£o\n",
    "print(\"=== DEMONSTRA√á√ÉO: VAE SIMPLES ===\")\n",
    "vae = SimpleVAE(latent_dim=20, img_size=32)\n",
    "vae.train(epochs=30, batch_size=16)\n",
    "generated_images = vae.visualize_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### An√°lise dos Resultados**Observa√ß√µes Importantes:**1. **Evolu√ß√£o das Perdas**:   - **Reconstru√ß√£o**: Deve diminuir para melhor reconstru√ß√£o   - **KL Divergence**: Deve diminuir para espa√ßo latente regularizado   - **Total**: Soma das duas perdas2. **Qualidade das Reconstru√ß√µes**:   - **Fidelidade**: Similaridade com imagens originais   - **Blur**: Efeito de desfoque t√≠pico de VAEs   - **Consist√™ncia**: Padr√µes reconhec√≠veis3. **Gera√ß√£o de Novas Imagens**:   - **Diversidade**: Varia√ß√£o nas cores e padr√µes   - **Realismo**: Apar√™ncia convincente   - **Controle**: Manipula√ß√£o do espa√ßo latente---## üìä 7.6 Compara√ß√£o: GANs vs VAEs### An√°lise Comparativa![Compara√ß√£o GANs vs VAEs](https://lilianweng.github.io/posts/2018-08-12-vae/vae-gaussian.png)#### **Qualidade das Imagens**| Aspecto | GANs | VAEs ||---------|------|------|| **Nitidez** | Alta | M√©dia (blur) || **Realismo** | Muito Alto | Alto || **Diversidade** | Alta | M√©dia || **Consist√™ncia** | Vari√°vel | Alta |#### **Treinamento**| Aspecto | GANs | VAEs ||---------|------|------|| **Estabilidade** | Baixa | Alta || **Converg√™ncia** | Dif√≠cil | Garantida || **Velocidade** | Lenta | R√°pida || **Complexidade** | Alta | M√©dia |#### **Controle e Manipula√ß√£o**| Aspecto | GANs | VAEs ||---------|------|------|| **Espa√ßo Latente** | N√£o estruturado | Estruturado || **Interpola√ß√£o** | Dif√≠cil | F√°cil || **Manipula√ß√£o** | Limitada | Alta || **Interpretabilidade** | Baixa | Alta |### Quando Usar Cada Um#### **Use GANs quando:**- ‚úÖ **Qualidade m√°xima** √© necess√°ria- ‚úÖ **Realismo** √© priorit√°rio- ‚úÖ **Diversidade** √© importante- ‚úÖ **Recursos computacionais** s√£o abundantes#### **Use VAEs quando:**- ‚úÖ **Treinamento est√°vel** √© necess√°rio- ‚úÖ **Controle** do espa√ßo latente √© importante- ‚úÖ **Interpretabilidade** √© priorit√°ria- ‚úÖ **Recursos limitados** est√£o dispon√≠veis---## üìù Resumo do M√≥dulo 7### Principais Conceitos Abordados1. **Fundamentos**: Gera√ß√£o sint√©tica de imagens2. **GANs**: Arquitetura adversarial3. **VAEs**: Autoencoders variacionais4. **Implementa√ß√£o**: Demonstra√ß√µes pr√°ticas5. **Compara√ß√£o**: An√°lise de vantagens e desvantagens### Demonstra√ß√µes Pr√°ticas**1. GAN Simples:**   - Implementa√ß√£o de gerador e discriminador   - Treinamento adversarial   - An√°lise de qualidade das imagens**2. VAE Simples:**   - Implementa√ß√£o de encoder e decoder   - Treinamento com perda de reconstru√ß√£o e KL   - An√°lise de reconstru√ß√µes e gera√ß√£o### Pr√≥ximos PassosNo **M√≥dulo 8**, exploraremos **Vision Transformers e Mecanismos de Aten√ß√£o**, uma abordagem revolucion√°ria para vis√£o computacional.### Refer√™ncias Principais- [Generative Adversarial Networks - Goodfellow et al.](https://arxiv.org/abs/1406.2661)- [Auto-Encoding Variational Bayes - Kingma & Welling](https://arxiv.org/abs/1312.6114)---**Pr√≥ximo M√≥dulo**: Vision Transformers e Mecanismos de Aten√ß√£o"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Conex√£o com o Pr√≥ximo M√≥dulo\n",
    "\n",
    "Agora que dominamos **GANs e VAEs** para gera√ß√£o sint√©tica, estamos preparados para explorar **Vision Transformers e Mecanismos de Aten√ß√£o**.\n",
    "\n",
    "No **M√≥dulo 8**, veremos como:\n",
    "\n",
    "### üîó **Conex√µes Diretas:**\n",
    "\n",
    "1. **Gera√ß√£o** ‚Üí **Aten√ß√£o**\n",
    "   - GANs geram imagens sint√©ticas\n",
    "   - Transformers usam aten√ß√£o para processar imagens\n",
    "\n",
    "2. **Espa√ßo Latente** ‚Üí **Espa√ßo de Aten√ß√£o**\n",
    "   - VAEs aprendem representa√ß√µes latentes\n",
    "   - Transformers aprendem representa√ß√µes de aten√ß√£o\n",
    "\n",
    "3. **Arquiteturas Complexas** ‚Üí **Arquiteturas de Aten√ß√£o**\n",
    "   - GANs e VAEs s√£o arquiteturas complexas\n",
    "   - Vision Transformers s√£o arquiteturas baseadas em aten√ß√£o\n",
    "\n",
    "4. **Aplica√ß√µes Pr√°ticas** ‚Üí **Aplica√ß√µes de Aten√ß√£o**\n",
    "   - Gera√ß√£o sint√©tica para cria√ß√£o\n",
    "   - Aten√ß√£o para an√°lise e classifica√ß√£o\n",
    "\n",
    "### üöÄ **Evolu√ß√£o Natural:**\n",
    "\n",
    "- **Gera√ß√£o** ‚Üí **An√°lise**\n",
    "- **Cria√ß√£o** ‚Üí **Compreens√£o**\n",
    "- **S√≠ntese** ‚Üí **Processamento**\n",
    "- **Arquiteturas Complexas** ‚Üí **Arquiteturas de Aten√ß√£o**\n",
    "\n",
    "Esta transi√ß√£o marca o in√≠cio da **era dos Vision Transformers** em vis√£o computacional!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## üñºÔ∏è Imagens de Refer√™ncia - M√≥dulo 7![Arquitetura GAN](https://developers.google.com/static/machine-learning/gan/images/gan_diagram.svg)![Arquitetura VAE](https://lilianweng.github.io/posts/2018-08-12-vae/vae-gaussian.png)![Conceito GANs](https://sthalles.github.io/assets/dcgan/GANs.png)![Tipos de GANs](https://developers.google.com/static/machine-learning/gan/images/gan_diagram.svg)![Conceito VAEs](https://lilianweng.github.io/posts/2018-08-12-vae/autoencoder-architecture.png)"
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}