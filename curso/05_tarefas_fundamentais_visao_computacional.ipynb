{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# M√≥dulo 5: Tarefas Fundamentais em Vis√£o Computacional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Objetivos de AprendizagemAo final deste m√≥dulo, voc√™ ser√° capaz de:- ‚úÖ Dominar as principais tarefas de vis√£o computacional- ‚úÖ Compreender diferen√ßas entre classifica√ß√£o, detec√ß√£o e segmenta√ß√£o- ‚úÖ Conhecer arquiteturas espec√≠ficas para cada tarefa- ‚úÖ Implementar solu√ß√µes pr√°ticas com PyTorch- ‚úÖ Analisar m√©tricas de avalia√ß√£o espec√≠ficas---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üè∑Ô∏è 5.1 Classifica√ß√£o de Imagens#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conceito Fundamental**Classifica√ß√£o de Imagens** √© a tarefa de atribuir uma ou mais labels (etiquetas) a uma imagem completa, determinando a categoria ou classe √† qual ela pertence.![Classifica√ß√£o de Imagens](https://cdn.jsdelivr.net/gh/rfapo/visao-computacional@main/images/modulo5/classificacao_imagens.png)#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defini√ß√£o e Caracter√≠sticas**Defini√ß√£o:**- **Entrada**: Uma imagem completa- **Sa√≠da**: Uma ou mais classes/categorias- **Objetivo**: Determinar \"o que\" est√° na imagem- **Granularidade**: N√≠vel de imagem inteira#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìö **Refer√™ncia Pr√°tica: TensorFlow Classification Tutorial**O [tutorial oficial do TensorFlow](https://www.tensorflow.org/tutorials/images/classification) demonstra classifica√ß√£o de imagens de flores usando `tf.keras.Sequential` e carregamento eficiente de dados com `tf.keras.utils.image_dataset_from_directory`. O tutorial aborda:- **Carregamento eficiente** de datasets do disco- **Identifica√ß√£o de overfitting** e t√©cnicas de mitiga√ß√£o- **Data augmentation** e dropout- **Workflow completo** de machine learning- **Convers√£o para TensorFlow Lite** para dispositivos m√≥veisEste tutorial √© essencial para entender a implementa√ß√£o pr√°tica de classifica√ß√£o de imagens.**Caracter√≠sticas Principais:**- **Uma imagem = Uma classe**: Cada imagem recebe uma label principal- **Classes mutuamente exclusivas**: Geralmente uma classe por imagem- **Classifica√ß√£o multi-label**: Poss√≠vel em alguns casos- **Hier√°rquica**: Classes podem ter subclasses#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tipos de Classifica√ß√£o##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Classifica√ß√£o Bin√°ria**- **Duas classes**: Sim/N√£o, Positivo/Negativo- **Aplica√ß√µes**: Detec√ß√£o de spam, diagn√≥stico m√©dico- **M√©tricas**: Accuracy, Precision, Recall, F1-Score##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Classifica√ß√£o Multiclasse**- **M√∫ltiplas classes**: C√£o, Gato, P√°ssaro, etc.- **Aplica√ß√µes**: Reconhecimento de objetos, categoriza√ß√£o- **M√©tricas**: Accuracy, Confusion Matrix##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. Classifica√ß√£o Multilabel**- **M√∫ltiplas labels**: Uma imagem pode ter v√°rias classes- **Aplica√ß√µes**: An√°lise de conte√∫do, tags- **M√©tricas**: Hamming Loss, Jaccard Index#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arquiteturas Espec√≠ficas![Arquiteturas de Classifica√ß√£o](https://cdn.jsdelivr.net/gh/rfapo/visao-computacional@main/images/modulo5/classificacao_imagens.png)##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Modelos Cl√°ssicos:**| Arquitetura | Caracter√≠sticas | Aplica√ß√£o ||-------------|-----------------|----------|| **VGG** | Kernels 3√ó3 uniformes | Classifica√ß√£o geral || **ResNet** | Skip connections | Classifica√ß√£o profunda || **EfficientNet** | Otimiza√ß√£o de efici√™ncia | Classifica√ß√£o eficiente || **DenseNet** | Conex√µes densas | Classifica√ß√£o compacta |##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Componentes Essenciais:**- **Camadas convolucionais**: Extra√ß√£o de caracter√≠sticas- **Pooling**: Redu√ß√£o de dimensionalidade- **Fully connected**: Classifica√ß√£o final- **Softmax**: Probabilidades normalizadas---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç 5.2 Detec√ß√£o de Objetos#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conceito Fundamental**Detec√ß√£o de Objetos** √© a tarefa de localizar e classificar m√∫ltiplos objetos em uma imagem, fornecendo bounding boxes e classes para cada objeto detectado.![Detec√ß√£o de Objetos](https://cdn.jsdelivr.net/gh/rfapo/visao-computacional@main/images/modulo5/deteccao_objetos.png)#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defini√ß√£o e Caracter√≠sticas**Defini√ß√£o:**- **Entrada**: Uma imagem completa- **Sa√≠da**: Bounding boxes + classes para cada objeto- **Objetivo**: Determinar \"o que\" e \"onde\" est√£o os objetos- **Granularidade**: N√≠vel de objeto individual**Caracter√≠sticas Principais:**- **M√∫ltiplos objetos**: Uma imagem pode conter v√°rios objetos- **Localiza√ß√£o precisa**: Coordenadas dos bounding boxes- **Classifica√ß√£o simult√¢nea**: Classe de cada objeto detectado- **Tamanhos variados**: Objetos de diferentes escalas#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arquiteturas Espec√≠ficas##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. R-CNN Family****R-CNN (2014):**- **Regi√£o proposta**: Selective Search- **Classifica√ß√£o**: CNN para cada regi√£o- **Desvantagem**: Muito lento**Fast R-CNN (2015):**- **Melhoria**: ROI Pooling- **Velocidade**: Mais r√°pido que R-CNN- **Ainda lento**: Selective Search**Faster R-CNN (2016):**- **Inova√ß√£o**: RPN (Region Proposal Network)- **Velocidade**: Muito mais r√°pido- **Precis√£o**: Alta precis√£o##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. YOLO Family****YOLO (2016):**- **Abordagem**: Detec√ß√£o em uma passada- **Velocidade**: Muito r√°pido- **Precis√£o**: Boa para objetos grandes**YOLOv2 (2017):**- **Melhorias**: Batch normalization, anchor boxes- **Precis√£o**: Melhor que YOLO original**YOLOv3 (2018):**- **Inova√ß√µes**: Multi-scale, feature pyramid- **Performance**: Boa precis√£o e velocidade**YOLOv4+ (2020+):**- **Otimiza√ß√µes**: CSP, PAN, SAM- **Performance**: Estado da arte##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. SSD (Single Shot Detector)****Caracter√≠sticas:**- **Detec√ß√£o em uma passada**: Como YOLO- **Multi-scale**: Diferentes escalas- **Velocidade**: R√°pido- **Precis√£o**: Boa para objetos m√©dios#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## M√©tricas de Avalia√ß√£o##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **mAP (mean Average Precision)**- **Defini√ß√£o**: M√©dia das APs para cada classe- **C√°lculo**: AP = √Årea sob curva Precision-Recall- **Interpreta√ß√£o**: Maior mAP = Melhor performance##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **IoU (Intersection over Union)**- **Defini√ß√£o**: Sobreposi√ß√£o entre predi√ß√£o e ground truth- **C√°lculo**: IoU = Intersec√ß√£o / Uni√£o- **Threshold**: Geralmente 0.5 para detec√ß√£o---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üé® 5.3 Segmenta√ß√£o de Imagens#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conceito Fundamental**Segmenta√ß√£o de Imagens** √© a tarefa de dividir uma imagem em regi√µes significativas, atribuindo cada pixel a uma classe espec√≠fica.![Segmenta√ß√£o de Imagens](https://cdn.jsdelivr.net/gh/rfapo/visao-computacional@main/images/modulo5/segmentacao_imagens.png)#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìö **Refer√™ncia Pr√°tica: Ultralytics YOLO Instance Segmentation**A [documenta√ß√£o oficial do Ultralytics YOLO](https://docs.ultralytics.com/tasks/segment/#export) define **instance segmentation** como uma t√©cnica que vai al√©m da detec√ß√£o de objetos, envolvendo a identifica√ß√£o de objetos individuais na imagem e sua segmenta√ß√£o do resto da imagem.**Caracter√≠sticas da Instance Segmentation:**- **Sa√≠da**: Conjunto de m√°scaras ou contornos que delineiam cada objeto- **Informa√ß√µes**: Labels de classe e scores de confian√ßa para cada objeto- **Utilidade**: Conhecer n√£o apenas onde est√£o os objetos, mas tamb√©m sua forma exata- **Modelos YOLO11-seg**: Pr√©-treinados no dataset COCO com sufixo `-seg`Esta refer√™ncia √© fundamental para entender a implementa√ß√£o pr√°tica de segmenta√ß√£o de inst√¢ncias.#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tipos de Segmenta√ß√£o##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Segmenta√ß√£o Sem√¢ntica**- **Objetivo**: Classificar cada pixel- **Sa√≠da**: Mapa de classes por pixel- **Aplica√ß√µes**: An√°lise de cenas, medicina- **Exemplo**: Todos os pixels de \"carro\" t√™m a mesma classe##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Segmenta√ß√£o de Inst√¢ncia**- **Objetivo**: Separar inst√¢ncias individuais- **Sa√≠da**: Mapa de inst√¢ncias por pixel- **Aplica√ß√µes**: Contagem de objetos, an√°lise de tr√°fego- **Exemplo**: Cada carro tem uma inst√¢ncia diferente##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. Segmenta√ß√£o Pan√≥ptica**- **Objetivo**: Combina√ß√£o de sem√¢ntica e inst√¢ncia- **Sa√≠da**: Classes + inst√¢ncias por pixel- **Aplica√ß√µes**: An√°lise completa de cenas- **Exemplo**: Classes para coisas + inst√¢ncias para objetos#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arquiteturas Espec√≠ficas##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. U-Net****Caracter√≠sticas:**- **Arquitetura em U**: Encoder-Decoder- **Skip connections**: Conex√µes diretas- **Aplica√ß√£o**: Segmenta√ß√£o m√©dica- **Vantagem**: Funciona bem com poucos dados**Estrutura:**```Encoder: Conv ‚Üí Pool ‚Üí Conv ‚Üí Pool ‚Üí ...Decoder: Upsample ‚Üí Conv ‚Üí Upsample ‚Üí Conv ‚Üí ...Skip: Conex√µes diretas entre encoder e decoder```##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. FCN (Fully Convolutional Networks)****Caracter√≠sticas:**- **Sem camadas FC**: Apenas convolu√ß√µes- **Upsampling**: Deconvolution para aumentar resolu√ß√£o- **Aplica√ß√£o**: Segmenta√ß√£o geral- **Vantagem**: Arquitetura simples##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. DeepLab****Caracter√≠sticas:**- **Atrous Convolution**: Dilated convolutions- **ASPP**: Atrous Spatial Pyramid Pooling- **Aplica√ß√£o**: Segmenta√ß√£o de alta resolu√ß√£o- **Vantagem**: Boa precis√£o em bordas#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## M√©tricas de Avalia√ß√£o##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Pixel Accuracy**- **Defini√ß√£o**: Porcentagem de pixels corretos- **C√°lculo**: Pixels corretos / Total de pixels- **Limita√ß√£o**: N√£o considera desbalanceamento de classes##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Mean IoU**- **Defini√ß√£o**: M√©dia dos IoUs para cada classe- **C√°lculo**: IoU = Intersec√ß√£o / Uni√£o por classe- **Vantagem**: Considera todas as classes igualmente##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Dice Coefficient**- **Defini√ß√£o**: Sobreposi√ß√£o entre predi√ß√£o e ground truth- **C√°lculo**: Dice = 2 * Intersec√ß√£o / (Predi√ß√£o + Ground Truth)- **Aplica√ß√£o**: Especialmente √∫til para segmenta√ß√£o m√©dica---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç 5.4 Demonstra√ß√£o Pr√°tica: Classifica√ß√£o de ImagensVamos implementar e visualizar diferentes aspectos da classifica√ß√£o:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "class ImageClassificationDemo:\n",
    "    \"\"\"Demonstra√ß√£o de classifica√ß√£o de imagens\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "    def create_sample_images(self):\n",
    "        \"\"\"Cria imagens de exemplo para demonstra√ß√£o\"\"\"\n",
    "        \n",
    "        # Criar imagens sint√©ticas representando diferentes classes\n",
    "        images = {}\n",
    "        \n",
    "        # Classe 1: C√≠rculos\n",
    "        img_circle = np.zeros((224, 224, 3), dtype=np.uint8)\n",
    "        cv2.circle(img_circle, (112, 112), 50, (255, 0, 0), -1)\n",
    "        cv2.circle(img_circle, (112, 112), 30, (0, 255, 0), -1)\n",
    "        images['circle'] = img_circle\n",
    "        \n",
    "        # Classe 2: Ret√¢ngulos\n",
    "        img_rect = np.zeros((224, 224, 3), dtype=np.uint8)\n",
    "        cv2.rectangle(img_rect, (50, 50), (174, 174), (0, 0, 255), -1)\n",
    "        cv2.rectangle(img_rect, (80, 80), (144, 144), (255, 255, 0), -1)\n",
    "        images['rectangle'] = img_rect\n",
    "        \n",
    "        # Classe 3: Tri√¢ngulos\n",
    "        img_triangle = np.zeros((224, 224, 3), dtype=np.uint8)\n",
    "        pts = np.array([[112, 50], [50, 174], [174, 174]], np.int32)\n",
    "        cv2.fillPoly(img_triangle, [pts], (255, 0, 255))\n",
    "        images['triangle'] = img_triangle\n",
    "        \n",
    "        # Classe 4: Linhas\n",
    "        img_lines = np.zeros((224, 224, 3), dtype=np.uint8)\n",
    "        cv2.line(img_lines, (50, 50), (174, 174), (0, 255, 255), 5)\n",
    "        cv2.line(img_lines, (174, 50), (50, 174), (255, 255, 0), 5)\n",
    "        images['lines'] = img_lines\n",
    "        \n",
    "        # Classe 5: Ru√≠do\n",
    "        img_noise = np.random.randint(0, 256, (224, 224, 3), dtype=np.uint8)\n",
    "        images['noise'] = img_noise\n",
    "        \n",
    "        return images\n",
    "    \n",
    "    def create_simple_classifier(self, num_classes=5):\n",
    "        \"\"\"Cria um classificador simples\"\"\"\n",
    "        \n",
    "        class SimpleClassifier(nn.Module):\n",
    "            def __init__(self, num_classes):\n",
    "                super(SimpleClassifier, self).__init__()\n",
    "                \n",
    "                # Camadas convolucionais\n",
    "                self.conv1 = nn.Conv2d(3, 32, kernel_size=5, stride=2, padding=2)\n",
    "                self.conv2 = nn.Conv2d(32, 64, kernel_size=5, stride=2, padding=2)\n",
    "                self.conv3 = nn.Conv2d(64, 128, kernel_size=5, stride=2, padding=2)\n",
    "                \n",
    "                # Pooling\n",
    "                self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "                \n",
    "                # Fully connected\n",
    "                self.fc1 = nn.Linear(128 * 3 * 3, 256)\n",
    "                self.fc2 = nn.Linear(256, num_classes)\n",
    "                \n",
    "                # Dropout\n",
    "                self.dropout = nn.Dropout(0.5)\n",
    "                \n",
    "            def forward(self, x):\n",
    "                # Camadas convolucionais\n",
    "                x = F.relu(self.conv1(x))\n",
    "                x = self.pool(x)\n",
    "                x = F.relu(self.conv2(x))\n",
    "                x = self.pool(x)\n",
    "                x = F.relu(self.conv3(x))\n",
    "                x = self.pool(x)\n",
    "                \n",
    "                # Flatten\n",
    "                x = x.view(-1, 128 * 3 * 3)\n",
    "                \n",
    "                # Fully connected\n",
    "                x = F.relu(self.fc1(x))\n",
    "                x = self.dropout(x)\n",
    "                x = self.fc2(x)\n",
    "                \n",
    "                return x\n",
    "        \n",
    "        return SimpleClassifier(num_classes)\n",
    "    \n",
    "    def simulate_classification(self, images, model):\n",
    "        \"\"\"Simula classifica√ß√£o das imagens\"\"\"\n",
    "        \n",
    "        model.eval()\n",
    "        results = {}\n",
    "        \n",
    "        # Definir classes\n",
    "        classes = ['circle', 'rectangle', 'triangle', 'lines', 'noise']\n",
    "        \n",
    "        for class_name, img in images.items():\n",
    "            # Converter para tensor\n",
    "            img_tensor = torch.FloatTensor(img).permute(2, 0, 1).unsqueeze(0) / 255.0\n",
    "            \n",
    "            # Simular predi√ß√£o\n",
    "            with torch.no_grad():\n",
    "                # Criar predi√ß√£o simulada baseada na classe real\n",
    "                if class_name == 'circle':\n",
    "                    pred = torch.tensor([[0.8, 0.1, 0.05, 0.03, 0.02]])\n",
    "                elif class_name == 'rectangle':\n",
    "                    pred = torch.tensor([[0.1, 0.8, 0.05, 0.03, 0.02]])\n",
    "                elif class_name == 'triangle':\n",
    "                    pred = torch.tensor([[0.05, 0.1, 0.8, 0.03, 0.02]])\n",
    "                elif class_name == 'lines':\n",
    "                    pred = torch.tensor([[0.03, 0.05, 0.1, 0.8, 0.02]])\n",
    "                else:  # noise\n",
    "                    pred = torch.tensor([[0.02, 0.03, 0.05, 0.1, 0.8]])\n",
    "                \n",
    "                # Aplicar softmax\n",
    "                pred = F.softmax(pred, dim=1)\n",
    "                \n",
    "                # Obter classe predita\n",
    "                predicted_class = torch.argmax(pred, dim=1).item()\n",
    "                confidence = pred[0, predicted_class].item()\n",
    "                \n",
    "                results[class_name] = {\n",
    "                    'image': img,\n",
    "                    'true_class': class_name,\n",
    "                    'predicted_class': classes[predicted_class],\n",
    "                    'confidence': confidence,\n",
    "                    'probabilities': pred[0].numpy()\n",
    "                }\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def visualize_classification_results(self, results):\n",
    "        \"\"\"Visualiza resultados da classifica√ß√£o\"\"\"\n",
    "        \n",
    "        fig, axes = plt.subplots(2, 5, figsize=(20, 8))\n",
    "        \n",
    "        classes = ['circle', 'rectangle', 'triangle', 'lines', 'noise']\n",
    "        \n",
    "        for i, class_name in enumerate(classes):\n",
    "            result = results[class_name]\n",
    "            \n",
    "            # Imagem original\n",
    "            axes[0, i].imshow(cv2.cvtColor(result['image'], cv2.COLOR_BGR2RGB))\n",
    "            axes[0, i].set_title(f'Classe Real: {result[\"true_class\"]}\\nPredi√ß√£o: {result[\"predicted_class\"]}\\nConfian√ßa: {result[\"confidence\"]:.3f}')\n",
    "            axes[0, i].axis('off')\n",
    "            \n",
    "            # Probabilidades\n",
    "            axes[1, i].bar(classes, result['probabilities'], color=['red', 'blue', 'green', 'orange', 'purple'])\n",
    "            axes[1, i].set_title('Probabilidades por Classe')\n",
    "            axes[1, i].set_ylabel('Probabilidade')\n",
    "            axes[1, i].tick_params(axis='x', rotation=45)\n",
    "            axes[1, i].set_ylim(0, 1)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # An√°lise quantitativa\n",
    "        print(\"=== AN√ÅLISE QUANTITATIVA DA CLASSIFICA√á√ÉO ===\")\n",
    "        \n",
    "        correct_predictions = 0\n",
    "        total_predictions = len(results)\n",
    "        \n",
    "        for class_name, result in results.items():\n",
    "            is_correct = result['true_class'] == result['predicted_class']\n",
    "            if is_correct:\n",
    "                correct_predictions += 1\n",
    "            \n",
    "            print(f\"\\n{class_name.upper()}:\")\n",
    "            print(f\"  - Classe real: {result['true_class']}\")\n",
    "            print(f\"  - Classe predita: {result['predicted_class']}\")\n",
    "            print(f\"  - Confian√ßa: {result['confidence']:.3f}\")\n",
    "            print(f\"  - Correto: {'Sim' if is_correct else 'N√£o'}\")\n",
    "        \n",
    "        accuracy = correct_predictions / total_predictions\n",
    "        print(f\"\\nACUR√ÅCIA GERAL: {accuracy:.3f} ({correct_predictions}/{total_predictions})\")\n",
    "        \n",
    "        return results\n",
    "\n",
    "# Executar demonstra√ß√£o\n",
    "print(\"=== DEMONSTRA√á√ÉO: CLASSIFICA√á√ÉO DE IMAGENS ===\")\n",
    "demo = ImageClassificationDemo()\n",
    "images = demo.create_sample_images()\n",
    "model = demo.create_simple_classifier()\n",
    "results = demo.simulate_classification(images, model)\n",
    "demo.visualize_classification_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "class ObjectDetectionDemo:\n",
    "    \"\"\"Demonstra√ß√£o de detec√ß√£o de objetos\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "    def create_sample_scene(self):\n",
    "        \"\"\"Cria uma cena de exemplo com m√∫ltiplos objetos\"\"\"\n",
    "        \n",
    "        # Criar imagem de fundo\n",
    "        img = np.ones((400, 600, 3), dtype=np.uint8) * 255\n",
    "        \n",
    "        # Adicionar objetos\n",
    "        objects = []\n",
    "        \n",
    "        # Objeto 1: C√≠rculo (classe 0)\n",
    "        cv2.circle(img, (150, 100), 40, (255, 0, 0), -1)\n",
    "        objects.append({'class': 0, 'bbox': [110, 60, 190, 140], 'name': 'circle'})\n",
    "        \n",
    "        # Objeto 2: Ret√¢ngulo (classe 1)\n",
    "        cv2.rectangle(img, (300, 80), (450, 180), (0, 255, 0), -1)\n",
    "        objects.append({'class': 1, 'bbox': [300, 80, 450, 180], 'name': 'rectangle'})\n",
    "        \n",
    "        # Objeto 3: Tri√¢ngulo (classe 2)\n",
    "        pts = np.array([[500, 50], [450, 150], [550, 150]], np.int32)\n",
    "        cv2.fillPoly(img, [pts], (0, 0, 255))\n",
    "        objects.append({'class': 2, 'bbox': [450, 50, 550, 150], 'name': 'triangle'})\n",
    "        \n",
    "        # Objeto 4: C√≠rculo pequeno (classe 0)\n",
    "        cv2.circle(img, (200, 300), 25, (255, 255, 0), -1)\n",
    "        objects.append({'class': 0, 'bbox': [175, 275, 225, 325], 'name': 'circle'})\n",
    "        \n",
    "        # Objeto 5: Ret√¢ngulo pequeno (classe 1)\n",
    "        cv2.rectangle(img, (400, 280), (500, 320), (255, 0, 255), -1)\n",
    "        objects.append({'class': 1, 'bbox': [400, 280, 500, 320], 'name': 'rectangle'})\n",
    "        \n",
    "        return img, objects\n",
    "    \n",
    "    def simulate_object_detection(self, img, objects):\n",
    "        \"\"\"Simula detec√ß√£o de objetos\"\"\"\n",
    "        \n",
    "        # Simular detec√ß√µes com algumas imprecis√µes\n",
    "        detections = []\n",
    "        \n",
    "        for obj in objects:\n",
    "            # Adicionar ru√≠do √†s coordenadas\n",
    "            noise_x = np.random.randint(-10, 11)\n",
    "            noise_y = np.random.randint(-10, 11)\n",
    "            noise_w = np.random.randint(-5, 6)\n",
    "            noise_h = np.random.randint(-5, 6)\n",
    "            \n",
    "            # Coordenadas com ru√≠do\n",
    "            x1 = max(0, obj['bbox'][0] + noise_x)\n",
    "            y1 = max(0, obj['bbox'][1] + noise_y)\n",
    "            x2 = min(img.shape[1], obj['bbox'][2] + noise_w)\n",
    "            y2 = min(img.shape[0], obj['bbox'][3] + noise_h)\n",
    "            \n",
    "            # Simular confian√ßa\n",
    "            confidence = np.random.uniform(0.7, 0.95)\n",
    "            \n",
    "            detections.append({\n",
    "                'class': obj['class'],\n",
    "                'bbox': [x1, y1, x2, y2],\n",
    "                'confidence': confidence,\n",
    "                'name': obj['name']\n",
    "            })\n",
    "        \n",
    "        # Adicionar falsos positivos\n",
    "        false_positives = 2\n",
    "        for _ in range(false_positives):\n",
    "            x1 = np.random.randint(0, img.shape[1] - 50)\n",
    "            y1 = np.random.randint(0, img.shape[0] - 50)\n",
    "            x2 = x1 + np.random.randint(20, 80)\n",
    "            y2 = y1 + np.random.randint(20, 80)\n",
    "            \n",
    "            detections.append({\n",
    "                'class': np.random.randint(0, 3),\n",
    "                'bbox': [x1, y1, x2, y2],\n",
    "                'confidence': np.random.uniform(0.3, 0.6),\n",
    "                'name': 'false_positive'\n",
    "            })\n",
    "        \n",
    "        return detections\n",
    "    \n",
    "    def calculate_iou(self, box1, box2):\n",
    "        \"\"\"Calcula IoU entre duas caixas\"\"\"\n",
    "        \n",
    "        # Coordenadas das caixas\n",
    "        x1_1, y1_1, x2_1, y2_1 = box1\n",
    "        x1_2, y1_2, x2_2, y2_2 = box2\n",
    "        \n",
    "        # Calcular interse√ß√£o\n",
    "        x1_i = max(x1_1, x1_2)\n",
    "        y1_i = max(y1_1, y1_2)\n",
    "        x2_i = min(x2_1, x2_2)\n",
    "        y2_i = min(y2_1, y2_2)\n",
    "        \n",
    "        if x2_i <= x1_i or y2_i <= y1_i:\n",
    "            return 0.0\n",
    "        \n",
    "        intersection = (x2_i - x1_i) * (y2_i - y1_i)\n",
    "        \n",
    "        # Calcular uni√£o\n",
    "        area1 = (x2_1 - x1_1) * (y2_1 - y1_1)\n",
    "        area2 = (x2_2 - x1_2) * (y2_2 - y1_2)\n",
    "        union = area1 + area2 - intersection\n",
    "        \n",
    "        return intersection / union if union > 0 else 0.0\n",
    "    \n",
    "    def visualize_detection_results(self, img, objects, detections):\n",
    "        \"\"\"Visualiza resultados da detec√ß√£o\"\"\"\n",
    "        \n",
    "        fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "        \n",
    "        # Imagem original\n",
    "        axes[0].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "        axes[0].set_title('Imagem Original')\n",
    "        axes[0].axis('off')\n",
    "        \n",
    "        # Ground truth\n",
    "        axes[1].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "        colors = ['red', 'blue', 'green']\n",
    "        for obj in objects:\n",
    "            x1, y1, x2, y2 = obj['bbox']\n",
    "            rect = Rectangle((x1, y1), x2-x1, y2-y1, linewidth=2, edgecolor=colors[obj['class']], facecolor='none')\n",
    "            axes[1].add_patch(rect)\n",
    "            axes[1].text(x1, y1-5, f'{obj[\"name\"]}', fontsize=10, color=colors[obj['class']])\n",
    "        axes[1].set_title('Ground Truth')\n",
    "        axes[1].axis('off')\n",
    "        \n",
    "        # Detec√ß√µes\n",
    "        axes[2].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "        for det in detections:\n",
    "            x1, y1, x2, y2 = det['bbox']\n",
    "            color = colors[det['class']] if det['name'] != 'false_positive' else 'orange'\n",
    "            rect = Rectangle((x1, y1), x2-x1, y2-y1, linewidth=2, edgecolor=color, facecolor='none')\n",
    "            axes[2].add_patch(rect)\n",
    "            axes[2].text(x1, y1-5, f'{det[\"name\"]} ({det[\"confidence\"]:.2f})', fontsize=10, color=color)\n",
    "        axes[2].set_title('Detec√ß√µes')\n",
    "        axes[2].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # An√°lise quantitativa\n",
    "        print(\"=== AN√ÅLISE QUANTITATIVA DA DETEC√á√ÉO ===\")\n",
    "        \n",
    "        # Calcular m√©tricas\n",
    "        true_positives = 0\n",
    "        false_positives = 0\n",
    "        false_negatives = 0\n",
    "        \n",
    "        # Para cada detec√ß√£o\n",
    "        for det in detections:\n",
    "            if det['name'] == 'false_positive':\n",
    "                false_positives += 1\n",
    "            else:\n",
    "                # Verificar se h√° overlap com ground truth\n",
    "                max_iou = 0\n",
    "                for obj in objects:\n",
    "                    if obj['class'] == det['class']:\n",
    "                        iou = self.calculate_iou(det['bbox'], obj['bbox'])\n",
    "                        max_iou = max(max_iou, iou)\n",
    "                \n",
    "                if max_iou > 0.5:  # Threshold para considerar TP\n",
    "                    true_positives += 1\n",
    "                else:\n",
    "                    false_positives += 1\n",
    "        \n",
    "        # Calcular false negatives\n",
    "        for obj in objects:\n",
    "            max_iou = 0\n",
    "            for det in detections:\n",
    "                if det['name'] != 'false_positive' and det['class'] == obj['class']:\n",
    "                    iou = self.calculate_iou(det['bbox'], obj['bbox'])\n",
    "                    max_iou = max(max_iou, iou)\n",
    "            \n",
    "            if max_iou < 0.5:\n",
    "                false_negatives += 1\n",
    "        \n",
    "        # Calcular m√©tricas\n",
    "        precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0\n",
    "        recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0\n",
    "        f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        \n",
    "        print(f\"\\nM√©tricas de Detec√ß√£o:\")\n",
    "        print(f\"  - True Positives: {true_positives}\")\n",
    "        print(f\"  - False Positives: {false_positives}\")\n",
    "        print(f\"  - False Negatives: {false_negatives}\")\n",
    "        print(f\"  - Precision: {precision:.3f}\")\n",
    "        print(f\"  - Recall: {recall:.3f}\")\n",
    "        print(f\"  - F1-Score: {f1_score:.3f}\")\n",
    "        \n",
    "        return {\n",
    "            'true_positives': true_positives,\n",
    "            'false_positives': false_positives,\n",
    "            'false_negatives': false_negatives,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1_score': f1_score\n",
    "        }\n",
    "\n",
    "# Executar demonstra√ß√£o\n",
    "print(\"=== DEMONSTRA√á√ÉO: DETEC√á√ÉO DE OBJETOS ===\")\n",
    "detection_demo = ObjectDetectionDemo()\n",
    "img, objects = detection_demo.create_sample_scene()\n",
    "detections = detection_demo.simulate_object_detection(img, objects)\n",
    "metrics = detection_demo.visualize_detection_results(img, objects, detections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "class ImageSegmentationDemo:\n",
    "    \"\"\"Demonstra√ß√£o de segmenta√ß√£o de imagens\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "    def create_sample_scene(self):\n",
    "        \"\"\"Cria uma cena de exemplo para segmenta√ß√£o\"\"\"\n",
    "        \n",
    "        # Criar imagem de fundo\n",
    "        img = np.ones((300, 400, 3), dtype=np.uint8) * 128  # Fundo cinza\n",
    "        \n",
    "        # Adicionar objetos com diferentes classes\n",
    "        \n",
    "        # Classe 1: C√≠rculo azul (c√©u)\n",
    "        cv2.circle(img, (200, 80), 60, (255, 200, 100), -1)\n",
    "        \n",
    "        # Classe 2: Ret√¢ngulo verde (grama)\n",
    "        cv2.rectangle(img, (50, 200), (350, 300), (100, 255, 100), -1)\n",
    "        \n",
    "        # Classe 3: Tri√¢ngulo marrom (montanha)\n",
    "        pts = np.array([[100, 150], [50, 200], [150, 200]], np.int32)\n",
    "        cv2.fillPoly(img, [pts], (150, 100, 50))\n",
    "        \n",
    "        # Classe 4: Ret√¢ngulo azul (√°gua)\n",
    "        cv2.rectangle(img, (200, 220), (350, 280), (100, 150, 255), -1)\n",
    "        \n",
    "        # Classe 5: C√≠rculo pequeno amarelo (sol)\n",
    "        cv2.circle(img, (320, 60), 25, (255, 255, 100), -1)\n",
    "        \n",
    "        return img\n",
    "    \n",
    "    def create_ground_truth_mask(self, img):\n",
    "        \"\"\"Cria m√°scara de ground truth para segmenta√ß√£o\"\"\"\n",
    "        \n",
    "        # Criar m√°scara baseada na imagem\n",
    "        mask = np.zeros((img.shape[0], img.shape[1]), dtype=np.uint8)\n",
    "        \n",
    "        # Classe 0: Fundo\n",
    "        mask[:] = 0\n",
    "        \n",
    "        # Classe 1: C√©u (c√≠rculo azul)\n",
    "        cv2.circle(mask, (200, 80), 60, 1, -1)\n",
    "        \n",
    "        # Classe 2: Grama (ret√¢ngulo verde)\n",
    "        cv2.rectangle(mask, (50, 200), (350, 300), 2, -1)\n",
    "        \n",
    "        # Classe 3: Montanha (tri√¢ngulo marrom)\n",
    "        pts = np.array([[100, 150], [50, 200], [150, 200]], np.int32)\n",
    "        cv2.fillPoly(mask, [pts], 3)\n",
    "        \n",
    "        # Classe 4: √Ågua (ret√¢ngulo azul)\n",
    "        cv2.rectangle(mask, (200, 220), (350, 280), 4, -1)\n",
    "        \n",
    "        # Classe 5: Sol (c√≠rculo amarelo)\n",
    "        cv2.circle(mask, (320, 60), 25, 5, -1)\n",
    "        \n",
    "        return mask\n",
    "    \n",
    "    def simulate_segmentation(self, img, ground_truth):\n",
    "        \"\"\"Simula segmenta√ß√£o com algumas imprecis√µes\"\"\"\n",
    "        \n",
    "        # Criar predi√ß√£o simulada\n",
    "        prediction = ground_truth.copy()\n",
    "        \n",
    "        # Adicionar ru√≠do\n",
    "        noise = np.random.randint(0, 6, prediction.shape)\n",
    "        \n",
    "        # Aplicar ru√≠do em algumas regi√µes\n",
    "        for i in range(prediction.shape[0]):\n",
    "            for j in range(prediction.shape[1]):\n",
    "                if np.random.random() < 0.1:  # 10% de chance de erro\n",
    "                    prediction[i, j] = noise[i, j]\n",
    "        \n",
    "        # Suavizar bordas\n",
    "        prediction = cv2.medianBlur(prediction, 3)\n",
    "        \n",
    "        return prediction\n",
    "    \n",
    "    def calculate_segmentation_metrics(self, ground_truth, prediction):\n",
    "        \"\"\"Calcula m√©tricas de segmenta√ß√£o\"\"\"\n",
    "        \n",
    "        # Pixel Accuracy\n",
    "        pixel_accuracy = np.mean(ground_truth == prediction)\n",
    "        \n",
    "        # Mean IoU\n",
    "        num_classes = 6  # 0-5\n",
    "        ious = []\n",
    "        \n",
    "        for class_id in range(num_classes):\n",
    "            gt_mask = (ground_truth == class_id)\n",
    "            pred_mask = (prediction == class_id)\n",
    "            \n",
    "            intersection = np.sum(gt_mask & pred_mask)\n",
    "            union = np.sum(gt_mask | pred_mask)\n",
    "            \n",
    "            if union > 0:\n",
    "                iou = intersection / union\n",
    "                ious.append(iou)\n",
    "            else:\n",
    "                ious.append(0.0)\n",
    "        \n",
    "        mean_iou = np.mean(ious)\n",
    "        \n",
    "        # Dice Coefficient\n",
    "        dice_coeffs = []\n",
    "        \n",
    "        for class_id in range(num_classes):\n",
    "            gt_mask = (ground_truth == class_id)\n",
    "            pred_mask = (prediction == class_id)\n",
    "            \n",
    "            intersection = np.sum(gt_mask & pred_mask)\n",
    "            total = np.sum(gt_mask) + np.sum(pred_mask)\n",
    "            \n",
    "            if total > 0:\n",
    "                dice = 2 * intersection / total\n",
    "                dice_coeffs.append(dice)\n",
    "            else:\n",
    "                dice_coeffs.append(0.0)\n",
    "        \n",
    "        mean_dice = np.mean(dice_coeffs)\n",
    "        \n",
    "        return {\n",
    "            'pixel_accuracy': pixel_accuracy,\n",
    "            'mean_iou': mean_iou,\n",
    "            'mean_dice': mean_dice,\n",
    "            'class_ious': ious,\n",
    "            'class_dices': dice_coeffs\n",
    "        }\n",
    "    \n",
    "    def visualize_segmentation_results(self, img, ground_truth, prediction, metrics):\n",
    "        \"\"\"Visualiza resultados da segmenta√ß√£o\"\"\"\n",
    "        \n",
    "        fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "        \n",
    "        # Imagem original\n",
    "        axes[0, 0].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "        axes[0, 0].set_title('Imagem Original')\n",
    "        axes[0, 0].axis('off')\n",
    "        \n",
    "        # Ground truth\n",
    "        colors = ['black', 'lightblue', 'green', 'brown', 'blue', 'yellow']\n",
    "        cmap = ListedColormap(colors)\n",
    "        axes[0, 1].imshow(ground_truth, cmap=cmap, vmin=0, vmax=5)\n",
    "        axes[0, 1].set_title('Ground Truth')\n",
    "        axes[0, 1].axis('off')\n",
    "        \n",
    "        # Predi√ß√£o\n",
    "        axes[0, 2].imshow(prediction, cmap=cmap, vmin=0, vmax=5)\n",
    "        axes[0, 2].set_title('Predi√ß√£o')\n",
    "        axes[0, 2].axis('off')\n",
    "        \n",
    "        # Diferen√ßas\n",
    "        diff = np.abs(ground_truth.astype(float) - prediction.astype(float))\n",
    "        axes[1, 0].imshow(diff, cmap='hot')\n",
    "        axes[1, 0].set_title('Diferen√ßas (Ground Truth vs Predi√ß√£o)')\n",
    "        axes[1, 0].axis('off')\n",
    "        \n",
    "        # M√©tricas por classe\n",
    "        class_names = ['Fundo', 'C√©u', 'Grama', 'Montanha', '√Ågua', 'Sol']\n",
    "        x = np.arange(len(class_names))\n",
    "        \n",
    "        axes[1, 1].bar(x, metrics['class_ious'], color=colors, alpha=0.7)\n",
    "        axes[1, 1].set_title('IoU por Classe')\n",
    "        axes[1, 1].set_xlabel('Classe')\n",
    "        axes[1, 1].set_ylabel('IoU')\n",
    "        axes[1, 1].set_xticks(x)\n",
    "        axes[1, 1].set_xticklabels(class_names, rotation=45)\n",
    "        axes[1, 1].set_ylim(0, 1)\n",
    "        \n",
    "        # M√©tricas gerais\n",
    "        metric_names = ['Pixel\\nAccuracy', 'Mean\\nIoU', 'Mean\\nDice']\n",
    "        metric_values = [metrics['pixel_accuracy'], metrics['mean_iou'], metrics['mean_dice']]\n",
    "        \n",
    "        axes[1, 2].bar(metric_names, metric_values, color=['blue', 'green', 'red'], alpha=0.7)\n",
    "        axes[1, 2].set_title('M√©tricas Gerais')\n",
    "        axes[1, 2].set_ylabel('Valor')\n",
    "        axes[1, 2].set_ylim(0, 1)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # An√°lise quantitativa\n",
    "        print(\"=== AN√ÅLISE QUANTITATIVA DA SEGMENTA√á√ÉO ===\")\n",
    "        \n",
    "        print(f\"\\nM√©tricas Gerais:\")\n",
    "        print(f\"  - Pixel Accuracy: {metrics['pixel_accuracy']:.3f}\")\n",
    "        print(f\"  - Mean IoU: {metrics['mean_iou']:.3f}\")\n",
    "        print(f\"  - Mean Dice: {metrics['mean_dice']:.3f}\")\n",
    "        \n",
    "        print(f\"\\nM√©tricas por Classe:\")\n",
    "        for i, class_name in enumerate(class_names):\n",
    "            print(f\"  - {class_name}: IoU={metrics['class_ious'][i]:.3f}, Dice={metrics['class_dices'][i]:.3f}\")\n",
    "        \n",
    "        return metrics\n",
    "\n",
    "# Executar demonstra√ß√£o\n",
    "print(\"=== DEMONSTRA√á√ÉO: SEGMENTA√á√ÉO DE IMAGENS ===\")\n",
    "segmentation_demo = ImageSegmentationDemo()\n",
    "img = segmentation_demo.create_sample_scene()\n",
    "ground_truth = segmentation_demo.create_ground_truth_mask(img)\n",
    "prediction = segmentation_demo.simulate_segmentation(img, ground_truth)\n",
    "metrics = segmentation_demo.calculate_segmentation_metrics(ground_truth, prediction)\n",
    "segmentation_demo.visualize_segmentation_results(img, ground_truth, prediction, metrics)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}