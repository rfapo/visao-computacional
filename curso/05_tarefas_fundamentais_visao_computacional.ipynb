{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# M√≥dulo 5: Tarefas Fundamentais em Vis√£o Computacional\n",
    "\n",
    "## üéØ Objetivos de Aprendizagem\n",
    "\n",
    "Ao final deste m√≥dulo, voc√™ ser√° capaz de:\n",
    "\n",
    "- ‚úÖ Dominar as principais tarefas de vis√£o computacional\n",
    "- ‚úÖ Compreender diferen√ßas entre classifica√ß√£o, detec√ß√£o e segmenta√ß√£o\n",
    "- ‚úÖ Conhecer arquiteturas espec√≠ficas para cada tarefa\n",
    "- ‚úÖ Implementar solu√ß√µes pr√°ticas com PyTorch\n",
    "- ‚úÖ Analisar m√©tricas de avalia√ß√£o espec√≠ficas\n",
    "\n",
    "---\n",
    "\n",
    "## üè∑Ô∏è 5.1 Classifica√ß√£o de Imagens\n",
    "\n",
    "### Conceito Fundamental\n",
    "\n",
    "**Classifica√ß√£o de Imagens** √© a tarefa de atribuir uma ou mais labels (etiquetas) a uma imagem completa, determinando a categoria ou classe √† qual ela pertence.\n",
    "\n",
    "![Classifica√ß√£o de Imagens](https://cdn.jsdelivr.net/gh/rfapo/visao-computacional@main/images/modulo5/classificacao_imagens.png)\n",
    "\n",
    "### Defini√ß√£o e Caracter√≠sticas\n",
    "\n",
    "**Defini√ß√£o:**\n",
    "- **Entrada**: Uma imagem completa\n",
    "- **Sa√≠da**: Uma ou mais classes/categorias\n",
    "- **Objetivo**: Determinar \"o que\" est√° na imagem\n",
    "- **Granularidade**: N√≠vel de imagem inteira\n",
    "\n",
    "### üìö **Refer√™ncia Pr√°tica: TensorFlow Classification Tutorial**\n",
    "\n",
    "O [tutorial oficial do TensorFlow](https://www.tensorflow.org/tutorials/images/classification) demonstra classifica√ß√£o de imagens de flores usando `tf.keras.Sequential` e carregamento eficiente de dados com `tf.keras.utils.image_dataset_from_directory`. O tutorial aborda:\n",
    "\n",
    "- **Carregamento eficiente** de datasets do disco\n",
    "- **Identifica√ß√£o de overfitting** e t√©cnicas de mitiga√ß√£o\n",
    "- **Data augmentation** e dropout\n",
    "- **Workflow completo** de machine learning\n",
    "- **Convers√£o para TensorFlow Lite** para dispositivos m√≥veis\n",
    "\n",
    "Este tutorial √© essencial para entender a implementa√ß√£o pr√°tica de classifica√ß√£o de imagens.\n",
    "\n",
    "### Tipos de Classifica√ß√£o\n",
    "\n",
    "#### **1. Classifica√ß√£o Bin√°ria**\n",
    "- **Duas classes**: Sim/N√£o, Positivo/Negativo\n",
    "- **Aplica√ß√µes**: Detec√ß√£o de spam, diagn√≥stico m√©dico\n",
    "- **M√©tricas**: Accuracy, Precision, Recall, F1-Score\n",
    "\n",
    "#### **2. Classifica√ß√£o Multiclasse**\n",
    "- **M√∫ltiplas classes**: C√£o, Gato, P√°ssaro, etc.\n",
    "- **Aplica√ß√µes**: Reconhecimento de objetos, categoriza√ß√£o\n",
    "- **M√©tricas**: Accuracy, Confusion Matrix\n",
    "\n",
    "#### **3. Classifica√ß√£o Multilabel**\n",
    "- **M√∫ltiplas labels**: Uma imagem pode ter v√°rias classes\n",
    "- **Aplica√ß√µes**: An√°lise de conte√∫do, tags\n",
    "- **M√©tricas**: Hamming Loss, Jaccard Index\n",
    "\n",
    "### Arquiteturas Espec√≠ficas\n",
    "\n",
    "![Arquiteturas de Classifica√ß√£o](https://cdn.jsdelivr.net/gh/rfapo/visao-computacional@main/images/modulo5/arquiteturas_classificacao.png)\n",
    "\n",
    "#### **Modelos Cl√°ssicos:**\n",
    "\n",
    "| Arquitetura | Caracter√≠sticas | Aplica√ß√£o |\n",
    "|-------------|-----------------|----------|\n",
    "| **VGG** | Kernels 3√ó3 uniformes | Classifica√ß√£o geral |\n",
    "| **ResNet** | Skip connections | Classifica√ß√£o profunda |\n",
    "| **EfficientNet** | Otimiza√ß√£o de efici√™ncia | Classifica√ß√£o eficiente |\n",
    "| **DenseNet** | Conex√µes densas | Classifica√ß√£o compacta |\n",
    "\n",
    "#### **Componentes Essenciais:**\n",
    "- **Camadas convolucionais**: Extra√ß√£o de caracter√≠sticas\n",
    "- **Pooling**: Redu√ß√£o de dimensionalidade\n",
    "- **Fully connected**: Classifica√ß√£o final\n",
    "- **Softmax**: Probabilidades normalizadas\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ 5.2 Detec√ß√£o de Objetos\n",
    "\n",
    "### Conceito Fundamental\n",
    "\n",
    "**Detec√ß√£o de Objetos** √© a tarefa de localizar e classificar m√∫ltiplos objetos em uma imagem, fornecendo bounding boxes e classes para cada objeto detectado.\n",
    "\n",
    "![Detec√ß√£o de Objetos](https://cdn.jsdelivr.net/gh/rfapo/visao-computacional@main/images/modulo5/deteccao_objetos.png)\n",
    "\n",
    "### Defini√ß√£o e Caracter√≠sticas\n",
    "\n",
    "**Defini√ß√£o:**\n",
    "- **Entrada**: Uma imagem completa\n",
    "- **Sa√≠da**: Bounding boxes + classes para cada objeto\n",
    "- **Objetivo**: Determinar \"o que\" e \"onde\" est√£o os objetos\n",
    "- **Granularidade**: N√≠vel de objeto individual\n",
    "\n",
    "### üìö **Datasets Pr√°ticos para Detec√ß√£o de Objetos**\n",
    "\n",
    "#### **1. Coke Can Detection Dataset**\n",
    "\n",
    "O [dataset de detec√ß√£o de latas de Coca-Cola](https://universe.roboflow.com/antony-p68kw/coke-can-detection-ttylj/dataset/1) √© um exemplo pr√°tico de detec√ß√£o de objetos espec√≠ficos:\n",
    "\n",
    "- **Objetivo**: Detectar latas de Coca-Cola em imagens\n",
    "- **Aplica√ß√£o**: Sistemas de venda autom√°tica, contagem de produtos\n",
    "- **Formato**: Anota√ß√µes em formato YOLO\n",
    "- **Tamanho**: Dataset p√∫blico dispon√≠vel no Roboflow Universe\n",
    "\n",
    "#### **2. Can, Bottle and Pack Detection Dataset**\n",
    "\n",
    "O [dataset de detec√ß√£o de latas, garrafas e embalagens](https://universe.roboflow.com/recyclorobloai-intern/can-bottle-and-pack-detection/dataset/1) √© ideal para aplica√ß√µes de reciclagem:\n",
    "\n",
    "- **Objetivo**: Detectar diferentes tipos de embalagens recicl√°veis\n",
    "- **Classes**: Latas, garrafas, embalagens\n",
    "- **Aplica√ß√£o**: Sistemas de triagem autom√°tica de res√≠duos\n",
    "- **Impacto**: Sustentabilidade e economia circular\n",
    "\n",
    "Estes datasets s√£o excelentes para pr√°tica e demonstra√ß√£o de t√©cnicas de detec√ß√£o de objetos.\n",
    "\n",
    "### Arquiteturas Espec√≠ficas\n",
    "\n",
    "![Arquiteturas de Detec√ß√£o](https://cdn.jsdelivr.net/gh/rfapo/visao-computacional@main/images/modulo5/arquiteturas_deteccao.png)\n",
    "\n",
    "#### **1. R-CNN Family**\n",
    "\n",
    "**R-CNN (2014):**\n",
    "- **Regi√£o proposta**: Selective Search\n",
    "- **Classifica√ß√£o**: CNN para cada regi√£o\n",
    "- **Desvantagem**: Muito lento\n",
    "\n",
    "**Fast R-CNN (2015):**\n",
    "- **Melhoria**: ROI Pooling\n",
    "- **Velocidade**: Mais r√°pido que R-CNN\n",
    "- **Ainda lento**: Selective Search\n",
    "\n",
    "**Faster R-CNN (2016):**\n",
    "- **Inova√ß√£o**: RPN (Region Proposal Network)\n",
    "- **Velocidade**: Muito mais r√°pido\n",
    "- **Precis√£o**: Alta precis√£o\n",
    "\n",
    "#### **2. YOLO Family**\n",
    "\n",
    "**YOLO (2016):**\n",
    "- **Abordagem**: Detec√ß√£o em uma passada\n",
    "- **Velocidade**: Muito r√°pido\n",
    "- **Precis√£o**: Boa para objetos grandes\n",
    "\n",
    "**YOLOv2 (2017):**\n",
    "- **Melhorias**: Batch normalization, anchor boxes\n",
    "- **Precis√£o**: Melhor que YOLO original\n",
    "\n",
    "**YOLOv3 (2018):**\n",
    "- **Inova√ß√µes**: Multi-scale, feature pyramid\n",
    "- **Performance**: Boa precis√£o e velocidade\n",
    "\n",
    "**YOLOv4+ (2020+):**\n",
    "- **Otimiza√ß√µes**: CSP, PAN, SAM\n",
    "- **Performance**: Estado da arte\n",
    "\n",
    "#### **3. SSD (Single Shot Detector)**\n",
    "\n",
    "**Caracter√≠sticas:**\n",
    "- **Detec√ß√£o em uma passada**: Como YOLO\n",
    "- **Multi-scale**: Diferentes escalas\n",
    "- **Velocidade**: R√°pido\n",
    "- **Precis√£o**: Boa para objetos m√©dios\n",
    "\n",
    "### M√©tricas de Avalia√ß√£o\n",
    "\n",
    "![M√©tricas de Detec√ß√£o](https://cdn.jsdelivr.net/gh/rfapo/visao-computacional@main/images/modulo5/metricas_deteccao.png)\n",
    "\n",
    "#### **mAP (mean Average Precision)**\n",
    "- **Defini√ß√£o**: M√©dia das APs para cada classe\n",
    "- **C√°lculo**: AP = √Årea sob curva Precision-Recall\n",
    "- **Interpreta√ß√£o**: Maior mAP = Melhor performance\n",
    "\n",
    "#### **IoU (Intersection over Union)**\n",
    "- **Defini√ß√£o**: Sobreposi√ß√£o entre predi√ß√£o e ground truth\n",
    "- **C√°lculo**: IoU = Intersec√ß√£o / Uni√£o\n",
    "- **Threshold**: Geralmente 0.5 para detec√ß√£o\n",
    "\n",
    "---\n",
    "\n",
    "## üé® 5.3 Segmenta√ß√£o de Imagens\n",
    "\n",
    "### Conceito Fundamental\n",
    "\n",
    "**Segmenta√ß√£o de Imagens** √© a tarefa de dividir uma imagem em regi√µes significativas, atribuindo cada pixel a uma classe espec√≠fica.\n",
    "\n",
    "![Segmenta√ß√£o de Imagens](https://cdn.jsdelivr.net/gh/rfapo/visao-computacional@main/images/modulo5/segmentacao_imagens.png)\n",
    "\n",
    "### üìö **Refer√™ncia Pr√°tica: Ultralytics YOLO Instance Segmentation**\n",
    "\n",
    "A [documenta√ß√£o oficial do Ultralytics YOLO](https://docs.ultralytics.com/tasks/segment/#export) define **instance segmentation** como uma t√©cnica que vai al√©m da detec√ß√£o de objetos, envolvendo a identifica√ß√£o de objetos individuais na imagem e sua segmenta√ß√£o do resto da imagem.\n",
    "\n",
    "**Caracter√≠sticas da Instance Segmentation:**\n",
    "- **Sa√≠da**: Conjunto de m√°scaras ou contornos que delineiam cada objeto\n",
    "- **Informa√ß√µes**: Labels de classe e scores de confian√ßa para cada objeto\n",
    "- **Utilidade**: Conhecer n√£o apenas onde est√£o os objetos, mas tamb√©m sua forma exata\n",
    "- **Modelos YOLO11-seg**: Pr√©-treinados no dataset COCO com sufixo `-seg`\n",
    "\n",
    "Esta refer√™ncia √© fundamental para entender a implementa√ß√£o pr√°tica de segmenta√ß√£o de inst√¢ncias.\n",
    "\n",
    "### Tipos de Segmenta√ß√£o\n",
    "\n",
    "#### **1. Segmenta√ß√£o Sem√¢ntica**\n",
    "- **Objetivo**: Classificar cada pixel\n",
    "- **Sa√≠da**: Mapa de classes por pixel\n",
    "- **Aplica√ß√µes**: An√°lise de cenas, medicina\n",
    "- **Exemplo**: Todos os pixels de \"carro\" t√™m a mesma classe\n",
    "\n",
    "#### **2. Segmenta√ß√£o de Inst√¢ncia**\n",
    "- **Objetivo**: Separar inst√¢ncias individuais\n",
    "- **Sa√≠da**: Mapa de inst√¢ncias por pixel\n",
    "- **Aplica√ß√µes**: Contagem de objetos, an√°lise de tr√°fego\n",
    "- **Exemplo**: Cada carro tem uma inst√¢ncia diferente\n",
    "\n",
    "#### **3. Segmenta√ß√£o Pan√≥ptica**\n",
    "- **Objetivo**: Combina√ß√£o de sem√¢ntica e inst√¢ncia\n",
    "- **Sa√≠da**: Classes + inst√¢ncias por pixel\n",
    "- **Aplica√ß√µes**: An√°lise completa de cenas\n",
    "- **Exemplo**: Classes para coisas + inst√¢ncias para objetos\n",
    "\n",
    "### Arquiteturas Espec√≠ficas\n",
    "\n",
    "![Arquiteturas de Segmenta√ß√£o](https://cdn.jsdelivr.net/gh/rfapo/visao-computacional@main/images/modulo5/arquiteturas_segmentacao.png)\n",
    "\n",
    "#### **1. U-Net**\n",
    "\n",
    "**Caracter√≠sticas:**\n",
    "- **Arquitetura em U**: Encoder-Decoder\n",
    "- **Skip connections**: Conex√µes diretas\n",
    "- **Aplica√ß√£o**: Segmenta√ß√£o m√©dica\n",
    "- **Vantagem**: Funciona bem com poucos dados\n",
    "\n",
    "**Estrutura:**\n",
    "```\n",
    "Encoder: Conv ‚Üí Pool ‚Üí Conv ‚Üí Pool ‚Üí ...\n",
    "Decoder: Upsample ‚Üí Conv ‚Üí Upsample ‚Üí Conv ‚Üí ...\n",
    "Skip: Conex√µes diretas entre encoder e decoder\n",
    "```\n",
    "\n",
    "#### **2. FCN (Fully Convolutional Networks)**\n",
    "\n",
    "**Caracter√≠sticas:**\n",
    "- **Sem camadas FC**: Apenas convolu√ß√µes\n",
    "- **Upsampling**: Deconvolution para aumentar resolu√ß√£o\n",
    "- **Aplica√ß√£o**: Segmenta√ß√£o geral\n",
    "- **Vantagem**: Arquitetura simples\n",
    "\n",
    "#### **3. DeepLab**\n",
    "\n",
    "**Caracter√≠sticas:**\n",
    "- **Atrous Convolution**: Dilated convolutions\n",
    "- **ASPP**: Atrous Spatial Pyramid Pooling\n",
    "- **Aplica√ß√£o**: Segmenta√ß√£o de alta resolu√ß√£o\n",
    "- **Vantagem**: Boa precis√£o em bordas\n",
    "\n",
    "### M√©tricas de Avalia√ß√£o\n",
    "\n",
    "![M√©tricas de Segmenta√ß√£o](https://cdn.jsdelivr.net/gh/rfapo/visao-computacional@main/images/modulo5/metricas_segmentacao.png)\n",
    "\n",
    "#### **Pixel Accuracy**\n",
    "- **Defini√ß√£o**: Porcentagem de pixels corretos\n",
    "- **C√°lculo**: Pixels corretos / Total de pixels\n",
    "- **Limita√ß√£o**: N√£o considera desbalanceamento de classes\n",
    "\n",
    "#### **Mean IoU**\n",
    "- **Defini√ß√£o**: M√©dia dos IoUs para cada classe\n",
    "- **C√°lculo**: IoU = Intersec√ß√£o / Uni√£o por classe\n",
    "- **Vantagem**: Considera todas as classes igualmente\n",
    "\n",
    "#### **Dice Coefficient**\n",
    "- **Defini√ß√£o**: Sobreposi√ß√£o entre predi√ß√£o e ground truth\n",
    "- **C√°lculo**: Dice = 2 * Intersec√ß√£o / (Predi√ß√£o + Ground Truth)\n",
    "- **Aplica√ß√£o**: Especialmente √∫til para segmenta√ß√£o m√©dica\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Atividade de Fixa√ß√£o: Classifica√ß√£o de Documentos com RVL-CDIP\n",
    "\n",
    "### üìã **Dataset RVL-CDIP (Ryerson Vision Lab Complex Document Information Processing)**\n",
    "\n",
    "O **RVL-CDIP** √© um dataset especializado em classifica√ß√£o de documentos complexos, ideal para aplicar os conceitos de **classifica√ß√£o de imagens** aprendidos neste m√≥dulo.\n",
    "\n",
    "#### **üìä Caracter√≠sticas do Dataset:**\n",
    "\n",
    "- **400.000 imagens** em escala de cinza\n",
    "- **16 classes** de documentos diferentes\n",
    "- **25.000 imagens** por classe\n",
    "- **Divis√£o**: 320.000 treino, 40.000 valida√ß√£o, 40.000 teste\n",
    "- **Resolu√ß√£o**: M√°ximo 1000 pixels na maior dimens√£o\n",
    "\n",
    "#### **üìÅ Classes de Documentos (0-15):**\n",
    "\n",
    "| ID | Classe | Descri√ß√£o |\n",
    "|----|--------|-----------|\n",
    "| 0 | **letter** | Cartas |\n",
    "| 1 | **form** | Formul√°rios |\n",
    "| 2 | **email** | E-mails |\n",
    "| 3 | **handwritten** | Documentos manuscritos |\n",
    "| 4 | **advertisement** | An√∫ncios |\n",
    "| 5 | **scientific report** | Relat√≥rios cient√≠ficos |\n",
    "| 6 | **scientific publication** | Publica√ß√µes cient√≠ficas |\n",
    "| 7 | **specification** | Especifica√ß√µes t√©cnicas |\n",
    "| 8 | **file folder** | Pastas de arquivo |\n",
    "| 9 | **news article** | Artigos de not√≠cia |\n",
    "| 10 | **budget** | Or√ßamentos |\n",
    "| 11 | **invoice** | Faturas |\n",
    "| 12 | **presentation** | Apresenta√ß√µes |\n",
    "| 13 | **questionnaire** | Question√°rios |\n",
    "| 14 | **resume** | Curr√≠culos |\n",
    "| 15 | **memo** | Memorandos |\n",
    "\n",
    "### üöÄ **Exerc√≠cio Pr√°tico:**\n",
    "\n",
    "#### **Objetivo:**\n",
    "Implementar um sistema de classifica√ß√£o de documentos usando **Deep Learning** e aplicar as **m√©tricas de avalia√ß√£o** estudadas neste m√≥dulo.\n",
    "\n",
    "#### **Tarefas:**\n",
    "\n",
    "1. **üì• Download do Dataset:**\n",
    "   ```python\n",
    "   # Dataset dispon√≠vel em:\n",
    "   # https://www.kaggle.com/datasets/pdavpoojan/the-rvlcdip-dataset-test\n",
    "   ```\n",
    "\n",
    "2. **üîß Implementa√ß√£o:**\n",
    "   - Carregar e pr√©-processar as imagens\n",
    "   - Implementar uma **CNN** para classifica√ß√£o\n",
    "   - Aplicar **data augmentation**\n",
    "   - Treinar o modelo\n",
    "\n",
    "3. **üìä Avalia√ß√£o:**\n",
    "   - Calcular **accuracy**, **precision**, **recall**, **F1-score**\n",
    "   - Gerar **matriz de confus√£o**\n",
    "   - Analisar **classes mais dif√≠ceis** de classificar\n",
    "\n",
    "4. **üéØ Desafios Espec√≠ficos:**\n",
    "   - **Documentos manuscritos** vs **impressos**\n",
    "   - **Formul√°rios** vs **question√°rios**\n",
    "   - **Relat√≥rios** vs **publica√ß√µes cient√≠ficas**\n",
    "\n",
    "#### **üí° Dicas de Implementa√ß√£o:**\n",
    "\n",
    "```python\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# 1. Carregar dataset\n",
    "# 2. Definir transforma√ß√µes\n",
    "# 3. Criar DataLoader\n",
    "# 4. Implementar CNN\n",
    "# 5. Treinar modelo\n",
    "# 6. Avaliar performance\n",
    "```\n",
    "\n",
    "#### **üìà M√©tricas Esperadas:**\n",
    "\n",
    "- **Accuracy**: > 85% (baseline)\n",
    "- **F1-Score**: > 0.80 (m√©dia)\n",
    "- **Classes problem√°ticas**: Identificar e analisar\n",
    "\n",
    "#### **üîó Refer√™ncias:**\n",
    "\n",
    "- **Harley, A. W., Ufkes, A., Derpanis, K. G.** (2015). \"Evaluation of Deep Convolutional Nets for Document Image Classification and Retrieval.\" *ICDAR*.\n",
    "- **Lewis, D., et al.** (2006). \"Building a test collection for complex document information processing.\" *SIGIR*.\n",
    "- **Legacy Tobacco Document Library** (LTDL), UCSF, 2007.\n",
    "\n",
    "### üéì **Aplica√ß√£o dos Conceitos:**\n",
    "\n",
    "Esta atividade permite aplicar **todos os conceitos** estudados no M√≥dulo 5:\n",
    "\n",
    "- ‚úÖ **Classifica√ß√£o de Imagens** (tarefa principal)\n",
    "- ‚úÖ **CNNs** (arquitetura de rede)\n",
    "- ‚úÖ **M√©tricas de Avalia√ß√£o** (accuracy, precision, recall, F1)\n",
    "- ‚úÖ **Matriz de Confus√£o** (an√°lise detalhada)\n",
    "- ‚úÖ **Data Augmentation** (melhoria de performance)\n",
    "- ‚úÖ **Transfer Learning** (opcional, usando modelos pr√©-treinados)\n",
    "\n",
    "### üöÄ **Pr√≥ximos Passos:**\n",
    "\n",
    "Ap√≥s completar esta atividade, voc√™ estar√° preparado para:\n",
    "- **M√≥dulo 6**: OCR e Reconhecimento de Texto\n",
    "- **M√≥dulo 7**: GANs e VAEs para Gera√ß√£o Sint√©tica\n",
    "- **M√≥dulo 8**: Vision Transformers\n",
    "\n",
    "**Esta atividade consolida todos os conceitos fundamentais de vis√£o computacional!** üéØ\n",
    "\n",
    "---\n",
    "\n",
    "## üìù Resumo do M√≥dulo 5\n",
    "\n",
    "### Principais Conceitos Abordados\n",
    "\n",
    "1. **Classifica√ß√£o**: Tarefa de atribuir labels a imagens\n",
    "2. **Detec√ß√£o**: Localiza√ß√£o e classifica√ß√£o de objetos\n",
    "3. **Segmenta√ß√£o**: Divis√£o de imagens em regi√µes\n",
    "4. **Arquiteturas**: Espec√≠ficas para cada tarefa\n",
    "5. **M√©tricas**: Avalia√ß√£o de performance\n",
    "6. **Aplica√ß√£o**: Dataset RVL-CDIP para pr√°tica\n",
    "\n",
    "### Pr√≥ximos Passos\n",
    "\n",
    "No **M√≥dulo 6**, aplicaremos essas t√©cnicas em **OCR e Reconhecimento de Texto**, uma aplica√ß√£o pr√°tica importante.\n",
    "\n",
    "### Refer√™ncias Principais\n",
    "\n",
    "- [Computer Vision: Algorithms and Applications - Szeliski](https://szeliski.org/Book/)\n",
    "- [Deep Learning for Computer Vision - Goodfellow et al.](https://www.deeplearningbook.org/)\n",
    "\n",
    "---\n",
    "\n",
    "**Pr√≥ximo M√≥dulo**: OCR e Reconhecimento de Texto"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}