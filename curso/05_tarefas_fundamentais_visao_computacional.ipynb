{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# M√≥dulo 5: Tarefas Fundamentais em Vis√£o Computacional\n",
        "\n",
        "## üéØ Objetivos de Aprendizagem\n",
        "\n",
        "Ao final deste m√≥dulo, voc√™ ser√° capaz de:\n",
        "\n",
        "- ‚úÖ Dominar as principais tarefas de vis√£o computacional\n",
        "- ‚úÖ Compreender diferen√ßas entre classifica√ß√£o, detec√ß√£o e segmenta√ß√£o\n",
        "- ‚úÖ Conhecer arquiteturas espec√≠ficas para cada tarefa\n",
        "- ‚úÖ Implementar solu√ß√µes pr√°ticas com PyTorch\n",
        "- ‚úÖ Analisar m√©tricas de avalia√ß√£o espec√≠ficas\n",
        "\n",
        "---\n",
        "\n",
        "## üè∑Ô∏è 5.1 Classifica√ß√£o de Imagens\n",
        "\n",
        "### Conceito Fundamental\n",
        "\n",
        "**Classifica√ß√£o de Imagens** √© a tarefa de atribuir uma ou mais labels (etiquetas) a uma imagem completa, determinando a categoria ou classe √† qual ela pertence.\n",
        "\n",
        "![Classifica√ß√£o de Imagens](https://cdn.jsdelivr.net/gh/rfapo/visao-computacional@main/images/modulo5/classificacao_imagens.png)\n",
        "\n",
        "### Defini√ß√£o e Caracter√≠sticas\n",
        "\n",
        "**Defini√ß√£o:**\n",
        "- **Entrada**: Uma imagem completa\n",
        "- **Sa√≠da**: Uma ou mais classes/categorias\n",
        "- **Objetivo**: Determinar \"o que\" est√° na imagem\n",
        "- **Granularidade**: N√≠vel de imagem inteira\n",
        "\n",
        "**Caracter√≠sticas Principais:**\n",
        "- **Uma imagem = Uma classe**: Cada imagem recebe uma label principal\n",
        "- **Classes mutuamente exclusivas**: Geralmente uma classe por imagem\n",
        "- **Classifica√ß√£o multi-label**: Poss√≠vel em alguns casos\n",
        "- **Hier√°rquica**: Classes podem ter subclasses\n",
        "\n",
        "### Tipos de Classifica√ß√£o\n",
        "\n",
        "#### **1. Classifica√ß√£o Bin√°ria**\n",
        "- **Duas classes**: Sim/N√£o, Positivo/Negativo\n",
        "- **Aplica√ß√µes**: Detec√ß√£o de spam, diagn√≥stico m√©dico\n",
        "- **M√©tricas**: Accuracy, Precision, Recall, F1-Score\n",
        "\n",
        "#### **2. Classifica√ß√£o Multiclasse**\n",
        "- **M√∫ltiplas classes**: C√£o, Gato, P√°ssaro, etc.\n",
        "- **Aplica√ß√µes**: Reconhecimento de objetos, categoriza√ß√£o\n",
        "- **M√©tricas**: Accuracy, Confusion Matrix\n",
        "\n",
        "#### **3. Classifica√ß√£o Multilabel**\n",
        "- **M√∫ltiplas labels**: Uma imagem pode ter v√°rias classes\n",
        "- **Aplica√ß√µes**: An√°lise de conte√∫do, tags\n",
        "- **M√©tricas**: Hamming Loss, Jaccard Index\n",
        "\n",
        "### Arquiteturas Espec√≠ficas\n",
        "\n",
        "![Arquiteturas de Classifica√ß√£o](https://cdn.jsdelivr.net/gh/rfapo/visao-computacional@main/images/modulo5/classificacao_imagens.png)\n",
        "\n",
        "#### **Modelos Cl√°ssicos:**\n",
        "\n",
        "| Arquitetura | Caracter√≠sticas | Aplica√ß√£o |\n",
        "|-------------|-----------------|----------|\n",
        "| **VGG** | Kernels 3√ó3 uniformes | Classifica√ß√£o geral |\n",
        "| **ResNet** | Skip connections | Classifica√ß√£o profunda |\n",
        "| **EfficientNet** | Otimiza√ß√£o de efici√™ncia | Classifica√ß√£o eficiente |\n",
        "| **DenseNet** | Conex√µes densas | Classifica√ß√£o compacta |\n",
        "\n",
        "#### **Componentes Essenciais:**\n",
        "- **Camadas convolucionais**: Extra√ß√£o de caracter√≠sticas\n",
        "- **Pooling**: Redu√ß√£o de dimensionalidade\n",
        "- **Fully connected**: Classifica√ß√£o final\n",
        "- **Softmax**: Probabilidades normalizadas\n",
        "\n",
        "---\n",
        "\n",
        "## üîç 5.2 Detec√ß√£o de Objetos\n",
        "\n",
        "### Conceito Fundamental\n",
        "\n",
        "**Detec√ß√£o de Objetos** √© a tarefa de localizar e classificar m√∫ltiplos objetos em uma imagem, fornecendo bounding boxes e classes para cada objeto detectado.\n",
        "\n",
        "![Detec√ß√£o de Objetos](https://cdn.jsdelivr.net/gh/rfapo/visao-computacional@main/images/modulo5/deteccao_objetos.png)\n",
        "\n",
        "### Defini√ß√£o e Caracter√≠sticas\n",
        "\n",
        "**Defini√ß√£o:**\n",
        "- **Entrada**: Uma imagem completa\n",
        "- **Sa√≠da**: Bounding boxes + classes para cada objeto\n",
        "- **Objetivo**: Determinar \"o que\" e \"onde\" est√£o os objetos\n",
        "- **Granularidade**: N√≠vel de objeto individual\n",
        "\n",
        "**Caracter√≠sticas Principais:**\n",
        "- **M√∫ltiplos objetos**: Uma imagem pode conter v√°rios objetos\n",
        "- **Localiza√ß√£o precisa**: Coordenadas dos bounding boxes\n",
        "- **Classifica√ß√£o simult√¢nea**: Classe de cada objeto detectado\n",
        "- **Tamanhos variados**: Objetos de diferentes escalas\n",
        "\n",
        "### Arquiteturas Espec√≠ficas\n",
        "\n",
        "#### **1. R-CNN Family**\n",
        "\n",
        "**R-CNN (2014):**\n",
        "- **Regi√£o proposta**: Selective Search\n",
        "- **Classifica√ß√£o**: CNN para cada regi√£o\n",
        "- **Desvantagem**: Muito lento\n",
        "\n",
        "**Fast R-CNN (2015):**\n",
        "- **Melhoria**: ROI Pooling\n",
        "- **Velocidade**: Mais r√°pido que R-CNN\n",
        "- **Ainda lento**: Selective Search\n",
        "\n",
        "**Faster R-CNN (2016):**\n",
        "- **Inova√ß√£o**: RPN (Region Proposal Network)\n",
        "- **Velocidade**: Muito mais r√°pido\n",
        "- **Precis√£o**: Alta precis√£o\n",
        "\n",
        "#### **2. YOLO Family**\n",
        "\n",
        "**YOLO (2016):**\n",
        "- **Abordagem**: Detec√ß√£o em uma passada\n",
        "- **Velocidade**: Muito r√°pido\n",
        "- **Precis√£o**: Boa para objetos grandes\n",
        "\n",
        "**YOLOv2 (2017):**\n",
        "- **Melhorias**: Batch normalization, anchor boxes\n",
        "- **Precis√£o**: Melhor que YOLO original\n",
        "\n",
        "**YOLOv3 (2018):**\n",
        "- **Inova√ß√µes**: Multi-scale, feature pyramid\n",
        "- **Performance**: Boa precis√£o e velocidade\n",
        "\n",
        "**YOLOv4+ (2020+):**\n",
        "- **Otimiza√ß√µes**: CSP, PAN, SAM\n",
        "- **Performance**: Estado da arte\n",
        "\n",
        "#### **3. SSD (Single Shot Detector)**\n",
        "\n",
        "**Caracter√≠sticas:**\n",
        "- **Detec√ß√£o em uma passada**: Como YOLO\n",
        "- **Multi-scale**: Diferentes escalas\n",
        "- **Velocidade**: R√°pido\n",
        "- **Precis√£o**: Boa para objetos m√©dios\n",
        "\n",
        "### M√©tricas de Avalia√ß√£o\n",
        "\n",
        "#### **mAP (mean Average Precision)**\n",
        "- **Defini√ß√£o**: M√©dia das APs para cada classe\n",
        "- **C√°lculo**: AP = √Årea sob curva Precision-Recall\n",
        "- **Interpreta√ß√£o**: Maior mAP = Melhor performance\n",
        "\n",
        "#### **IoU (Intersection over Union)**\n",
        "- **Defini√ß√£o**: Sobreposi√ß√£o entre predi√ß√£o e ground truth\n",
        "- **C√°lculo**: IoU = Intersec√ß√£o / Uni√£o\n",
        "- **Threshold**: Geralmente 0.5 para detec√ß√£o\n",
        "\n",
        "---\n",
        "\n",
        "## üé® 5.3 Segmenta√ß√£o de Imagens\n",
        "\n",
        "### Conceito Fundamental\n",
        "\n",
        "**Segmenta√ß√£o de Imagens** √© a tarefa de dividir uma imagem em regi√µes significativas, atribuindo cada pixel a uma classe espec√≠fica.\n",
        "\n",
        "![Segmenta√ß√£o de Imagens](https://cdn.jsdelivr.net/gh/rfapo/visao-computacional@main/images/modulo5/segmentacao_imagens.png)\n",
        "\n",
        "### Tipos de Segmenta√ß√£o\n",
        "\n",
        "#### **1. Segmenta√ß√£o Sem√¢ntica**\n",
        "- **Objetivo**: Classificar cada pixel\n",
        "- **Sa√≠da**: Mapa de classes por pixel\n",
        "- **Aplica√ß√µes**: An√°lise de cenas, medicina\n",
        "- **Exemplo**: Todos os pixels de \"carro\" t√™m a mesma classe\n",
        "\n",
        "#### **2. Segmenta√ß√£o de Inst√¢ncia**\n",
        "- **Objetivo**: Separar inst√¢ncias individuais\n",
        "- **Sa√≠da**: Mapa de inst√¢ncias por pixel\n",
        "- **Aplica√ß√µes**: Contagem de objetos, an√°lise de tr√°fego\n",
        "- **Exemplo**: Cada carro tem uma inst√¢ncia diferente\n",
        "\n",
        "#### **3. Segmenta√ß√£o Pan√≥ptica**\n",
        "- **Objetivo**: Combina√ß√£o de sem√¢ntica e inst√¢ncia\n",
        "- **Sa√≠da**: Classes + inst√¢ncias por pixel\n",
        "- **Aplica√ß√µes**: An√°lise completa de cenas\n",
        "- **Exemplo**: Classes para coisas + inst√¢ncias para objetos\n",
        "\n",
        "### Arquiteturas Espec√≠ficas\n",
        "\n",
        "#### **1. U-Net**\n",
        "\n",
        "**Caracter√≠sticas:**\n",
        "- **Arquitetura em U**: Encoder-Decoder\n",
        "- **Skip connections**: Conex√µes diretas\n",
        "- **Aplica√ß√£o**: Segmenta√ß√£o m√©dica\n",
        "- **Vantagem**: Funciona bem com poucos dados\n",
        "\n",
        "**Estrutura:**\n",
        "```\n",
        "Encoder: Conv ‚Üí Pool ‚Üí Conv ‚Üí Pool ‚Üí ...\n",
        "Decoder: Upsample ‚Üí Conv ‚Üí Upsample ‚Üí Conv ‚Üí ...\n",
        "Skip: Conex√µes diretas entre encoder e decoder\n",
        "```\n",
        "\n",
        "#### **2. FCN (Fully Convolutional Networks)**\n",
        "\n",
        "**Caracter√≠sticas:**\n",
        "- **Sem camadas FC**: Apenas convolu√ß√µes\n",
        "- **Upsampling**: Deconvolution para aumentar resolu√ß√£o\n",
        "- **Aplica√ß√£o**: Segmenta√ß√£o geral\n",
        "- **Vantagem**: Arquitetura simples\n",
        "\n",
        "#### **3. DeepLab**\n",
        "\n",
        "**Caracter√≠sticas:**\n",
        "- **Atrous Convolution**: Dilated convolutions\n",
        "- **ASPP**: Atrous Spatial Pyramid Pooling\n",
        "- **Aplica√ß√£o**: Segmenta√ß√£o de alta resolu√ß√£o\n",
        "- **Vantagem**: Boa precis√£o em bordas\n",
        "\n",
        "### M√©tricas de Avalia√ß√£o\n",
        "\n",
        "#### **Pixel Accuracy**\n",
        "- **Defini√ß√£o**: Porcentagem de pixels corretos\n",
        "- **C√°lculo**: Pixels corretos / Total de pixels\n",
        "- **Limita√ß√£o**: N√£o considera desbalanceamento de classes\n",
        "\n",
        "#### **Mean IoU**\n",
        "- **Defini√ß√£o**: M√©dia dos IoUs para cada classe\n",
        "- **C√°lculo**: IoU = Intersec√ß√£o / Uni√£o por classe\n",
        "- **Vantagem**: Considera todas as classes igualmente\n",
        "\n",
        "#### **Dice Coefficient**\n",
        "- **Defini√ß√£o**: Sobreposi√ß√£o entre predi√ß√£o e ground truth\n",
        "- **C√°lculo**: Dice = 2 * Intersec√ß√£o / (Predi√ß√£o + Ground Truth)\n",
        "- **Aplica√ß√£o**: Especialmente √∫til para segmenta√ß√£o m√©dica\n",
        "\n",
        "---\n",
        "\n",
        "## üîç 5.4 Demonstra√ß√£o Pr√°tica: Classifica√ß√£o de Imagens\n",
        "\n",
        "Vamos implementar e visualizar diferentes aspectos da classifica√ß√£o:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import models\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "from PIL import Image\n",
        "\n",
        "class ImageClassificationDemo:\n",
        "    \"\"\"Demonstra√ß√£o de classifica√ß√£o de imagens\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        \n",
        "    def create_sample_images(self):\n",
        "        \"\"\"Cria imagens de exemplo para demonstra√ß√£o\"\"\"\n",
        "        \n",
        "        # Criar imagens sint√©ticas representando diferentes classes\n",
        "        images = {}\n",
        "        \n",
        "        # Classe 1: C√≠rculos\n",
        "        img_circle = np.zeros((224, 224, 3), dtype=np.uint8)\n",
        "        cv2.circle(img_circle, (112, 112), 50, (255, 0, 0), -1)\n",
        "        cv2.circle(img_circle, (112, 112), 30, (0, 255, 0), -1)\n",
        "        images['circle'] = img_circle\n",
        "        \n",
        "        # Classe 2: Ret√¢ngulos\n",
        "        img_rect = np.zeros((224, 224, 3), dtype=np.uint8)\n",
        "        cv2.rectangle(img_rect, (50, 50), (174, 174), (0, 0, 255), -1)\n",
        "        cv2.rectangle(img_rect, (80, 80), (144, 144), (255, 255, 0), -1)\n",
        "        images['rectangle'] = img_rect\n",
        "        \n",
        "        # Classe 3: Tri√¢ngulos\n",
        "        img_triangle = np.zeros((224, 224, 3), dtype=np.uint8)\n",
        "        pts = np.array([[112, 50], [50, 174], [174, 174]], np.int32)\n",
        "        cv2.fillPoly(img_triangle, [pts], (255, 0, 255))\n",
        "        images['triangle'] = img_triangle\n",
        "        \n",
        "        # Classe 4: Linhas\n",
        "        img_lines = np.zeros((224, 224, 3), dtype=np.uint8)\n",
        "        cv2.line(img_lines, (50, 50), (174, 174), (0, 255, 255), 5)\n",
        "        cv2.line(img_lines, (174, 50), (50, 174), (255, 255, 0), 5)\n",
        "        images['lines'] = img_lines\n",
        "        \n",
        "        # Classe 5: Ru√≠do\n",
        "        img_noise = np.random.randint(0, 256, (224, 224, 3), dtype=np.uint8)\n",
        "        images['noise'] = img_noise\n",
        "        \n",
        "        return images\n",
        "    \n",
        "    def create_simple_classifier(self, num_classes=5):\n",
        "        \"\"\"Cria um classificador simples\"\"\"\n",
        "        \n",
        "        class SimpleClassifier(nn.Module):\n",
        "            def __init__(self, num_classes):\n",
        "                super(SimpleClassifier, self).__init__()\n",
        "                \n",
        "                # Camadas convolucionais\n",
        "                self.conv1 = nn.Conv2d(3, 32, kernel_size=5, stride=2, padding=2)\n",
        "                self.conv2 = nn.Conv2d(32, 64, kernel_size=5, stride=2, padding=2)\n",
        "                self.conv3 = nn.Conv2d(64, 128, kernel_size=5, stride=2, padding=2)\n",
        "                \n",
        "                # Pooling\n",
        "                self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "                \n",
        "                # Fully connected\n",
        "                self.fc1 = nn.Linear(128 * 3 * 3, 256)\n",
        "                self.fc2 = nn.Linear(256, num_classes)\n",
        "                \n",
        "                # Dropout\n",
        "                self.dropout = nn.Dropout(0.5)\n",
        "                \n",
        "            def forward(self, x):\n",
        "                # Camadas convolucionais\n",
        "                x = F.relu(self.conv1(x))\n",
        "                x = self.pool(x)\n",
        "                x = F.relu(self.conv2(x))\n",
        "                x = self.pool(x)\n",
        "                x = F.relu(self.conv3(x))\n",
        "                x = self.pool(x)\n",
        "                \n",
        "                # Flatten\n",
        "                x = x.view(-1, 128 * 3 * 3)\n",
        "                \n",
        "                # Fully connected\n",
        "                x = F.relu(self.fc1(x))\n",
        "                x = self.dropout(x)\n",
        "                x = self.fc2(x)\n",
        "                \n",
        "                return x\n",
        "        \n",
        "        return SimpleClassifier(num_classes)\n",
        "    \n",
        "    def simulate_classification(self, images, model):\n",
        "        \"\"\"Simula classifica√ß√£o das imagens\"\"\"\n",
        "        \n",
        "        model.eval()\n",
        "        results = {}\n",
        "        \n",
        "        # Definir classes\n",
        "        classes = ['circle', 'rectangle', 'triangle', 'lines', 'noise']\n",
        "        \n",
        "        for class_name, img in images.items():\n",
        "            # Converter para tensor\n",
        "            img_tensor = torch.FloatTensor(img).permute(2, 0, 1).unsqueeze(0) / 255.0\n",
        "            \n",
        "            # Simular predi√ß√£o\n",
        "            with torch.no_grad():\n",
        "                # Criar predi√ß√£o simulada baseada na classe real\n",
        "                if class_name == 'circle':\n",
        "                    pred = torch.tensor([[0.8, 0.1, 0.05, 0.03, 0.02]])\n",
        "                elif class_name == 'rectangle':\n",
        "                    pred = torch.tensor([[0.1, 0.8, 0.05, 0.03, 0.02]])\n",
        "                elif class_name == 'triangle':\n",
        "                    pred = torch.tensor([[0.05, 0.1, 0.8, 0.03, 0.02]])\n",
        "                elif class_name == 'lines':\n",
        "                    pred = torch.tensor([[0.03, 0.05, 0.1, 0.8, 0.02]])\n",
        "                else:  # noise\n",
        "                    pred = torch.tensor([[0.02, 0.03, 0.05, 0.1, 0.8]])\n",
        "                \n",
        "                # Aplicar softmax\n",
        "                pred = F.softmax(pred, dim=1)\n",
        "                \n",
        "                # Obter classe predita\n",
        "                predicted_class = torch.argmax(pred, dim=1).item()\n",
        "                confidence = pred[0, predicted_class].item()\n",
        "                \n",
        "                results[class_name] = {\n",
        "                    'image': img,\n",
        "                    'true_class': class_name,\n",
        "                    'predicted_class': classes[predicted_class],\n",
        "                    'confidence': confidence,\n",
        "                    'probabilities': pred[0].numpy()\n",
        "                }\n",
        "        \n",
        "        return results\n",
        "    \n",
        "    def visualize_classification_results(self, results):\n",
        "        \"\"\"Visualiza resultados da classifica√ß√£o\"\"\"\n",
        "        \n",
        "        fig, axes = plt.subplots(2, 5, figsize=(20, 8))\n",
        "        \n",
        "        classes = ['circle', 'rectangle', 'triangle', 'lines', 'noise']\n",
        "        \n",
        "        for i, class_name in enumerate(classes):\n",
        "            result = results[class_name]\n",
        "            \n",
        "            # Imagem original\n",
        "            axes[0, i].imshow(cv2.cvtColor(result['image'], cv2.COLOR_BGR2RGB))\n",
        "            axes[0, i].set_title(f'Classe Real: {result[\"true_class\"]}\\nPredi√ß√£o: {result[\"predicted_class\"]}\\nConfian√ßa: {result[\"confidence\"]:.3f}')\n",
        "            axes[0, i].axis('off')\n",
        "            \n",
        "            # Probabilidades\n",
        "            axes[1, i].bar(classes, result['probabilities'], color=['red', 'blue', 'green', 'orange', 'purple'])\n",
        "            axes[1, i].set_title('Probabilidades por Classe')\n",
        "            axes[1, i].set_ylabel('Probabilidade')\n",
        "            axes[1, i].tick_params(axis='x', rotation=45)\n",
        "            axes[1, i].set_ylim(0, 1)\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        \n",
        "        # An√°lise quantitativa\n",
        "        print(\"=== AN√ÅLISE QUANTITATIVA DA CLASSIFICA√á√ÉO ===\")\n",
        "        \n",
        "        correct_predictions = 0\n",
        "        total_predictions = len(results)\n",
        "        \n",
        "        for class_name, result in results.items():\n",
        "            is_correct = result['true_class'] == result['predicted_class']\n",
        "            if is_correct:\n",
        "                correct_predictions += 1\n",
        "            \n",
        "            print(f\"\\n{class_name.upper()}:\")\n",
        "            print(f\"  - Classe real: {result['true_class']}\")\n",
        "            print(f\"  - Classe predita: {result['predicted_class']}\")\n",
        "            print(f\"  - Confian√ßa: {result['confidence']:.3f}\")\n",
        "            print(f\"  - Correto: {'Sim' if is_correct else 'N√£o'}\")\n",
        "        \n",
        "        accuracy = correct_predictions / total_predictions\n",
        "        print(f\"\\nACUR√ÅCIA GERAL: {accuracy:.3f} ({correct_predictions}/{total_predictions})\")\n",
        "        \n",
        "        return results\n",
        "\n",
        "# Executar demonstra√ß√£o\n",
        "print(\"=== DEMONSTRA√á√ÉO: CLASSIFICA√á√ÉO DE IMAGENS ===\")\n",
        "demo = ImageClassificationDemo()\n",
        "images = demo.create_sample_images()\n",
        "model = demo.create_simple_classifier()\n",
        "results = demo.simulate_classification(images, model)\n",
        "demo.visualize_classification_results(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### An√°lise dos Resultados\n",
        "\n",
        "**Observa√ß√µes Importantes:**\n",
        "\n",
        "1. **Classifica√ß√£o Bin√°ria**:\n",
        "   - **Precis√£o**: Alta para classes bem definidas\n",
        "   - **Confian√ßa**: Alta para padr√µes claros\n",
        "   - **Aplica√ß√£o**: Detec√ß√£o de spam, diagn√≥stico m√©dico\n",
        "\n",
        "2. **Classifica√ß√£o Multiclasse**:\n",
        "   - **Precis√£o**: Boa para classes distintas\n",
        "   - **Confian√ßa**: Vari√°vel dependendo da complexidade\n",
        "   - **Aplica√ß√£o**: Reconhecimento de objetos, categoriza√ß√£o\n",
        "\n",
        "3. **Classifica√ß√£o Multilabel**:\n",
        "   - **Precis√£o**: Desafiadora para m√∫ltiplas labels\n",
        "   - **Confian√ßa**: Pode ser baixa para labels raras\n",
        "   - **Aplica√ß√£o**: An√°lise de conte√∫do, tags\n",
        "\n",
        "---\n",
        "\n",
        "## üîç 5.5 Demonstra√ß√£o Pr√°tica: Detec√ß√£o de Objetos\n",
        "\n",
        "Vamos implementar e visualizar detec√ß√£o de objetos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "from matplotlib.patches import Rectangle\n",
        "\n",
        "class ObjectDetectionDemo:\n",
        "    \"\"\"Demonstra√ß√£o de detec√ß√£o de objetos\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        \n",
        "    def create_sample_scene(self):\n",
        "        \"\"\"Cria uma cena de exemplo com m√∫ltiplos objetos\"\"\"\n",
        "        \n",
        "        # Criar imagem de fundo\n",
        "        img = np.ones((400, 600, 3), dtype=np.uint8) * 255\n",
        "        \n",
        "        # Adicionar objetos\n",
        "        objects = []\n",
        "        \n",
        "        # Objeto 1: C√≠rculo (classe 0)\n",
        "        cv2.circle(img, (150, 100), 40, (255, 0, 0), -1)\n",
        "        objects.append({'class': 0, 'bbox': [110, 60, 190, 140], 'name': 'circle'})\n",
        "        \n",
        "        # Objeto 2: Ret√¢ngulo (classe 1)\n",
        "        cv2.rectangle(img, (300, 80), (450, 180), (0, 255, 0), -1)\n",
        "        objects.append({'class': 1, 'bbox': [300, 80, 450, 180], 'name': 'rectangle'})\n",
        "        \n",
        "        # Objeto 3: Tri√¢ngulo (classe 2)\n",
        "        pts = np.array([[500, 50], [450, 150], [550, 150]], np.int32)\n",
        "        cv2.fillPoly(img, [pts], (0, 0, 255))\n",
        "        objects.append({'class': 2, 'bbox': [450, 50, 550, 150], 'name': 'triangle'})\n",
        "        \n",
        "        # Objeto 4: C√≠rculo pequeno (classe 0)\n",
        "        cv2.circle(img, (200, 300), 25, (255, 255, 0), -1)\n",
        "        objects.append({'class': 0, 'bbox': [175, 275, 225, 325], 'name': 'circle'})\n",
        "        \n",
        "        # Objeto 5: Ret√¢ngulo pequeno (classe 1)\n",
        "        cv2.rectangle(img, (400, 280), (500, 320), (255, 0, 255), -1)\n",
        "        objects.append({'class': 1, 'bbox': [400, 280, 500, 320], 'name': 'rectangle'})\n",
        "        \n",
        "        return img, objects\n",
        "    \n",
        "    def simulate_object_detection(self, img, objects):\n",
        "        \"\"\"Simula detec√ß√£o de objetos\"\"\"\n",
        "        \n",
        "        # Simular detec√ß√µes com algumas imprecis√µes\n",
        "        detections = []\n",
        "        \n",
        "        for obj in objects:\n",
        "            # Adicionar ru√≠do √†s coordenadas\n",
        "            noise_x = np.random.randint(-10, 11)\n",
        "            noise_y = np.random.randint(-10, 11)\n",
        "            noise_w = np.random.randint(-5, 6)\n",
        "            noise_h = np.random.randint(-5, 6)\n",
        "            \n",
        "            # Coordenadas com ru√≠do\n",
        "            x1 = max(0, obj['bbox'][0] + noise_x)\n",
        "            y1 = max(0, obj['bbox'][1] + noise_y)\n",
        "            x2 = min(img.shape[1], obj['bbox'][2] + noise_w)\n",
        "            y2 = min(img.shape[0], obj['bbox'][3] + noise_h)\n",
        "            \n",
        "            # Simular confian√ßa\n",
        "            confidence = np.random.uniform(0.7, 0.95)\n",
        "            \n",
        "            detections.append({\n",
        "                'class': obj['class'],\n",
        "                'bbox': [x1, y1, x2, y2],\n",
        "                'confidence': confidence,\n",
        "                'name': obj['name']\n",
        "            })\n",
        "        \n",
        "        # Adicionar falsos positivos\n",
        "        false_positives = 2\n",
        "        for _ in range(false_positives):\n",
        "            x1 = np.random.randint(0, img.shape[1] - 50)\n",
        "            y1 = np.random.randint(0, img.shape[0] - 50)\n",
        "            x2 = x1 + np.random.randint(20, 80)\n",
        "            y2 = y1 + np.random.randint(20, 80)\n",
        "            \n",
        "            detections.append({\n",
        "                'class': np.random.randint(0, 3),\n",
        "                'bbox': [x1, y1, x2, y2],\n",
        "                'confidence': np.random.uniform(0.3, 0.6),\n",
        "                'name': 'false_positive'\n",
        "            })\n",
        "        \n",
        "        return detections\n",
        "    \n",
        "    def calculate_iou(self, box1, box2):\n",
        "        \"\"\"Calcula IoU entre duas caixas\"\"\"\n",
        "        \n",
        "        # Coordenadas das caixas\n",
        "        x1_1, y1_1, x2_1, y2_1 = box1\n",
        "        x1_2, y1_2, x2_2, y2_2 = box2\n",
        "        \n",
        "        # Calcular interse√ß√£o\n",
        "        x1_i = max(x1_1, x1_2)\n",
        "        y1_i = max(y1_1, y1_2)\n",
        "        x2_i = min(x2_1, x2_2)\n",
        "        y2_i = min(y2_1, y2_2)\n",
        "        \n",
        "        if x2_i <= x1_i or y2_i <= y1_i:\n",
        "            return 0.0\n",
        "        \n",
        "        intersection = (x2_i - x1_i) * (y2_i - y1_i)\n",
        "        \n",
        "        # Calcular uni√£o\n",
        "        area1 = (x2_1 - x1_1) * (y2_1 - y1_1)\n",
        "        area2 = (x2_2 - x1_2) * (y2_2 - y1_2)\n",
        "        union = area1 + area2 - intersection\n",
        "        \n",
        "        return intersection / union if union > 0 else 0.0\n",
        "    \n",
        "    def visualize_detection_results(self, img, objects, detections):\n",
        "        \"\"\"Visualiza resultados da detec√ß√£o\"\"\"\n",
        "        \n",
        "        fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
        "        \n",
        "        # Imagem original\n",
        "        axes[0].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "        axes[0].set_title('Imagem Original')\n",
        "        axes[0].axis('off')\n",
        "        \n",
        "        # Ground truth\n",
        "        axes[1].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "        colors = ['red', 'blue', 'green']\n",
        "        for obj in objects:\n",
        "            x1, y1, x2, y2 = obj['bbox']\n",
        "            rect = Rectangle((x1, y1), x2-x1, y2-y1, linewidth=2, edgecolor=colors[obj['class']], facecolor='none')\n",
        "            axes[1].add_patch(rect)\n",
        "            axes[1].text(x1, y1-5, f'{obj[\"name\"]}', fontsize=10, color=colors[obj['class']])\n",
        "        axes[1].set_title('Ground Truth')\n",
        "        axes[1].axis('off')\n",
        "        \n",
        "        # Detec√ß√µes\n",
        "        axes[2].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "        for det in detections:\n",
        "            x1, y1, x2, y2 = det['bbox']\n",
        "            color = colors[det['class']] if det['name'] != 'false_positive' else 'orange'\n",
        "            rect = Rectangle((x1, y1), x2-x1, y2-y1, linewidth=2, edgecolor=color, facecolor='none')\n",
        "            axes[2].add_patch(rect)\n",
        "            axes[2].text(x1, y1-5, f'{det[\"name\"]} ({det[\"confidence\"]:.2f})', fontsize=10, color=color)\n",
        "        axes[2].set_title('Detec√ß√µes')\n",
        "        axes[2].axis('off')\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        \n",
        "        # An√°lise quantitativa\n",
        "        print(\"=== AN√ÅLISE QUANTITATIVA DA DETEC√á√ÉO ===\")\n",
        "        \n",
        "        # Calcular m√©tricas\n",
        "        true_positives = 0\n",
        "        false_positives = 0\n",
        "        false_negatives = 0\n",
        "        \n",
        "        # Para cada detec√ß√£o\n",
        "        for det in detections:\n",
        "            if det['name'] == 'false_positive':\n",
        "                false_positives += 1\n",
        "            else:\n",
        "                # Verificar se h√° overlap com ground truth\n",
        "                max_iou = 0\n",
        "                for obj in objects:\n",
        "                    if obj['class'] == det['class']:\n",
        "                        iou = self.calculate_iou(det['bbox'], obj['bbox'])\n",
        "                        max_iou = max(max_iou, iou)\n",
        "                \n",
        "                if max_iou > 0.5:  # Threshold para considerar TP\n",
        "                    true_positives += 1\n",
        "                else:\n",
        "                    false_positives += 1\n",
        "        \n",
        "        # Calcular false negatives\n",
        "        for obj in objects:\n",
        "            max_iou = 0\n",
        "            for det in detections:\n",
        "                if det['name'] != 'false_positive' and det['class'] == obj['class']:\n",
        "                    iou = self.calculate_iou(det['bbox'], obj['bbox'])\n",
        "                    max_iou = max(max_iou, iou)\n",
        "            \n",
        "            if max_iou < 0.5:\n",
        "                false_negatives += 1\n",
        "        \n",
        "        # Calcular m√©tricas\n",
        "        precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0\n",
        "        recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0\n",
        "        f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "        \n",
        "        print(f\"\\nM√©tricas de Detec√ß√£o:\")\n",
        "        print(f\"  - True Positives: {true_positives}\")\n",
        "        print(f\"  - False Positives: {false_positives}\")\n",
        "        print(f\"  - False Negatives: {false_negatives}\")\n",
        "        print(f\"  - Precision: {precision:.3f}\")\n",
        "        print(f\"  - Recall: {recall:.3f}\")\n",
        "        print(f\"  - F1-Score: {f1_score:.3f}\")\n",
        "        \n",
        "        return {\n",
        "            'true_positives': true_positives,\n",
        "            'false_positives': false_positives,\n",
        "            'false_negatives': false_negatives,\n",
        "            'precision': precision,\n",
        "            'recall': recall,\n",
        "            'f1_score': f1_score\n",
        "        }\n",
        "\n",
        "# Executar demonstra√ß√£o\n",
        "print(\"=== DEMONSTRA√á√ÉO: DETEC√á√ÉO DE OBJETOS ===\")\n",
        "detection_demo = ObjectDetectionDemo()\n",
        "img, objects = detection_demo.create_sample_scene()\n",
        "detections = detection_demo.simulate_object_detection(img, objects)\n",
        "metrics = detection_demo.visualize_detection_results(img, objects, detections)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### An√°lise dos Resultados\n",
        "\n",
        "**Observa√ß√µes Importantes:**\n",
        "\n",
        "1. **True Positives**:\n",
        "   - **Detec√ß√µes corretas**: Objetos encontrados com IoU > 0.5\n",
        "   - **Confian√ßa**: Geralmente alta para detec√ß√µes corretas\n",
        "   - **Localiza√ß√£o**: Boa precis√£o nas coordenadas\n",
        "\n",
        "2. **False Positives**:\n",
        "   - **Detec√ß√µes incorretas**: Objetos que n√£o existem\n",
        "   - **Confian√ßa**: Geralmente baixa\n",
        "   - **Causa**: Ru√≠do, padr√µes similares\n",
        "\n",
        "3. **False Negatives**:\n",
        "   - **Objetos n√£o detectados**: Objetos que existem mas n√£o foram encontrados\n",
        "   - **Causa**: Objetos pequenos, oclus√£o, baixa qualidade\n",
        "\n",
        "---\n",
        "\n",
        "## üé® 5.6 Demonstra√ß√£o Pr√°tica: Segmenta√ß√£o de Imagens\n",
        "\n",
        "Vamos implementar e visualizar segmenta√ß√£o de imagens:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "from matplotlib.colors import ListedColormap\n",
        "\n",
        "class ImageSegmentationDemo:\n",
        "    \"\"\"Demonstra√ß√£o de segmenta√ß√£o de imagens\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        \n",
        "    def create_sample_scene(self):\n",
        "        \"\"\"Cria uma cena de exemplo para segmenta√ß√£o\"\"\"\n",
        "        \n",
        "        # Criar imagem de fundo\n",
        "        img = np.ones((300, 400, 3), dtype=np.uint8) * 128  # Fundo cinza\n",
        "        \n",
        "        # Adicionar objetos com diferentes classes\n",
        "        \n",
        "        # Classe 1: C√≠rculo azul (c√©u)\n",
        "        cv2.circle(img, (200, 80), 60, (255, 200, 100), -1)\n",
        "        \n",
        "        # Classe 2: Ret√¢ngulo verde (grama)\n",
        "        cv2.rectangle(img, (50, 200), (350, 300), (100, 255, 100), -1)\n",
        "        \n",
        "        # Classe 3: Tri√¢ngulo marrom (montanha)\n",
        "        pts = np.array([[100, 150], [50, 200], [150, 200]], np.int32)\n",
        "        cv2.fillPoly(img, [pts], (150, 100, 50))\n",
        "        \n",
        "        # Classe 4: Ret√¢ngulo azul (√°gua)\n",
        "        cv2.rectangle(img, (200, 220), (350, 280), (100, 150, 255), -1)\n",
        "        \n",
        "        # Classe 5: C√≠rculo pequeno amarelo (sol)\n",
        "        cv2.circle(img, (320, 60), 25, (255, 255, 100), -1)\n",
        "        \n",
        "        return img\n",
        "    \n",
        "    def create_ground_truth_mask(self, img):\n",
        "        \"\"\"Cria m√°scara de ground truth para segmenta√ß√£o\"\"\"\n",
        "        \n",
        "        # Criar m√°scara baseada na imagem\n",
        "        mask = np.zeros((img.shape[0], img.shape[1]), dtype=np.uint8)\n",
        "        \n",
        "        # Classe 0: Fundo\n",
        "        mask[:] = 0\n",
        "        \n",
        "        # Classe 1: C√©u (c√≠rculo azul)\n",
        "        cv2.circle(mask, (200, 80), 60, 1, -1)\n",
        "        \n",
        "        # Classe 2: Grama (ret√¢ngulo verde)\n",
        "        cv2.rectangle(mask, (50, 200), (350, 300), 2, -1)\n",
        "        \n",
        "        # Classe 3: Montanha (tri√¢ngulo marrom)\n",
        "        pts = np.array([[100, 150], [50, 200], [150, 200]], np.int32)\n",
        "        cv2.fillPoly(mask, [pts], 3)\n",
        "        \n",
        "        # Classe 4: √Ågua (ret√¢ngulo azul)\n",
        "        cv2.rectangle(mask, (200, 220), (350, 280), 4, -1)\n",
        "        \n",
        "        # Classe 5: Sol (c√≠rculo amarelo)\n",
        "        cv2.circle(mask, (320, 60), 25, 5, -1)\n",
        "        \n",
        "        return mask\n",
        "    \n",
        "    def simulate_segmentation(self, img, ground_truth):\n",
        "        \"\"\"Simula segmenta√ß√£o com algumas imprecis√µes\"\"\"\n",
        "        \n",
        "        # Criar predi√ß√£o simulada\n",
        "        prediction = ground_truth.copy()\n",
        "        \n",
        "        # Adicionar ru√≠do\n",
        "        noise = np.random.randint(0, 6, prediction.shape)\n",
        "        \n",
        "        # Aplicar ru√≠do em algumas regi√µes\n",
        "        for i in range(prediction.shape[0]):\n",
        "            for j in range(prediction.shape[1]):\n",
        "                if np.random.random() < 0.1:  # 10% de chance de erro\n",
        "                    prediction[i, j] = noise[i, j]\n",
        "        \n",
        "        # Suavizar bordas\n",
        "        prediction = cv2.medianBlur(prediction, 3)\n",
        "        \n",
        "        return prediction\n",
        "    \n",
        "    def calculate_segmentation_metrics(self, ground_truth, prediction):\n",
        "        \"\"\"Calcula m√©tricas de segmenta√ß√£o\"\"\"\n",
        "        \n",
        "        # Pixel Accuracy\n",
        "        pixel_accuracy = np.mean(ground_truth == prediction)\n",
        "        \n",
        "        # Mean IoU\n",
        "        num_classes = 6  # 0-5\n",
        "        ious = []\n",
        "        \n",
        "        for class_id in range(num_classes):\n",
        "            gt_mask = (ground_truth == class_id)\n",
        "            pred_mask = (prediction == class_id)\n",
        "            \n",
        "            intersection = np.sum(gt_mask & pred_mask)\n",
        "            union = np.sum(gt_mask | pred_mask)\n",
        "            \n",
        "            if union > 0:\n",
        "                iou = intersection / union\n",
        "                ious.append(iou)\n",
        "            else:\n",
        "                ious.append(0.0)\n",
        "        \n",
        "        mean_iou = np.mean(ious)\n",
        "        \n",
        "        # Dice Coefficient\n",
        "        dice_coeffs = []\n",
        "        \n",
        "        for class_id in range(num_classes):\n",
        "            gt_mask = (ground_truth == class_id)\n",
        "            pred_mask = (prediction == class_id)\n",
        "            \n",
        "            intersection = np.sum(gt_mask & pred_mask)\n",
        "            total = np.sum(gt_mask) + np.sum(pred_mask)\n",
        "            \n",
        "            if total > 0:\n",
        "                dice = 2 * intersection / total\n",
        "                dice_coeffs.append(dice)\n",
        "            else:\n",
        "                dice_coeffs.append(0.0)\n",
        "        \n",
        "        mean_dice = np.mean(dice_coeffs)\n",
        "        \n",
        "        return {\n",
        "            'pixel_accuracy': pixel_accuracy,\n",
        "            'mean_iou': mean_iou,\n",
        "            'mean_dice': mean_dice,\n",
        "            'class_ious': ious,\n",
        "            'class_dices': dice_coeffs\n",
        "        }\n",
        "    \n",
        "    def visualize_segmentation_results(self, img, ground_truth, prediction, metrics):\n",
        "        \"\"\"Visualiza resultados da segmenta√ß√£o\"\"\"\n",
        "        \n",
        "        fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "        \n",
        "        # Imagem original\n",
        "        axes[0, 0].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "        axes[0, 0].set_title('Imagem Original')\n",
        "        axes[0, 0].axis('off')\n",
        "        \n",
        "        # Ground truth\n",
        "        colors = ['black', 'lightblue', 'green', 'brown', 'blue', 'yellow']\n",
        "        cmap = ListedColormap(colors)\n",
        "        axes[0, 1].imshow(ground_truth, cmap=cmap, vmin=0, vmax=5)\n",
        "        axes[0, 1].set_title('Ground Truth')\n",
        "        axes[0, 1].axis('off')\n",
        "        \n",
        "        # Predi√ß√£o\n",
        "        axes[0, 2].imshow(prediction, cmap=cmap, vmin=0, vmax=5)\n",
        "        axes[0, 2].set_title('Predi√ß√£o')\n",
        "        axes[0, 2].axis('off')\n",
        "        \n",
        "        # Diferen√ßas\n",
        "        diff = np.abs(ground_truth.astype(float) - prediction.astype(float))\n",
        "        axes[1, 0].imshow(diff, cmap='hot')\n",
        "        axes[1, 0].set_title('Diferen√ßas (Ground Truth vs Predi√ß√£o)')\n",
        "        axes[1, 0].axis('off')\n",
        "        \n",
        "        # M√©tricas por classe\n",
        "        class_names = ['Fundo', 'C√©u', 'Grama', 'Montanha', '√Ågua', 'Sol']\n",
        "        x = np.arange(len(class_names))\n",
        "        \n",
        "        axes[1, 1].bar(x, metrics['class_ious'], color=colors, alpha=0.7)\n",
        "        axes[1, 1].set_title('IoU por Classe')\n",
        "        axes[1, 1].set_xlabel('Classe')\n",
        "        axes[1, 1].set_ylabel('IoU')\n",
        "        axes[1, 1].set_xticks(x)\n",
        "        axes[1, 1].set_xticklabels(class_names, rotation=45)\n",
        "        axes[1, 1].set_ylim(0, 1)\n",
        "        \n",
        "        # M√©tricas gerais\n",
        "        metric_names = ['Pixel\\nAccuracy', 'Mean\\nIoU', 'Mean\\nDice']\n",
        "        metric_values = [metrics['pixel_accuracy'], metrics['mean_iou'], metrics['mean_dice']]\n",
        "        \n",
        "        axes[1, 2].bar(metric_names, metric_values, color=['blue', 'green', 'red'], alpha=0.7)\n",
        "        axes[1, 2].set_title('M√©tricas Gerais')\n",
        "        axes[1, 2].set_ylabel('Valor')\n",
        "        axes[1, 2].set_ylim(0, 1)\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        \n",
        "        # An√°lise quantitativa\n",
        "        print(\"=== AN√ÅLISE QUANTITATIVA DA SEGMENTA√á√ÉO ===\")\n",
        "        \n",
        "        print(f\"\\nM√©tricas Gerais:\")\n",
        "        print(f\"  - Pixel Accuracy: {metrics['pixel_accuracy']:.3f}\")\n",
        "        print(f\"  - Mean IoU: {metrics['mean_iou']:.3f}\")\n",
        "        print(f\"  - Mean Dice: {metrics['mean_dice']:.3f}\")\n",
        "        \n",
        "        print(f\"\\nM√©tricas por Classe:\")\n",
        "        for i, class_name in enumerate(class_names):\n",
        "            print(f\"  - {class_name}: IoU={metrics['class_ious'][i]:.3f}, Dice={metrics['class_dices'][i]:.3f}\")\n",
        "        \n",
        "        return metrics\n",
        "\n",
        "# Executar demonstra√ß√£o\n",
        "print(\"=== DEMONSTRA√á√ÉO: SEGMENTA√á√ÉO DE IMAGENS ===\")\n",
        "segmentation_demo = ImageSegmentationDemo()\n",
        "img = segmentation_demo.create_sample_scene()\n",
        "ground_truth = segmentation_demo.create_ground_truth_mask(img)\n",
        "prediction = segmentation_demo.simulate_segmentation(img, ground_truth)\n",
        "metrics = segmentation_demo.calculate_segmentation_metrics(ground_truth, prediction)\n",
        "segmentation_demo.visualize_segmentation_results(img, ground_truth, prediction, metrics)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### An√°lise dos Resultados\n",
        "\n",
        "**Observa√ß√µes Importantes:**\n",
        "\n",
        "1. **Segmenta√ß√£o Sem√¢ntica**:\n",
        "   - **Precis√£o**: Boa para classes bem definidas\n",
        "   - **IoU**: Vari√°vel dependendo da complexidade da classe\n",
        "   - **Aplica√ß√£o**: An√°lise de cenas, medicina\n",
        "\n",
        "2. **Segmenta√ß√£o de Inst√¢ncia**:\n",
        "   - **Precis√£o**: Desafiadora para objetos sobrepostos\n",
        "   - **IoU**: Pode ser baixa para inst√¢ncias pequenas\n",
        "   - **Aplica√ß√£o**: Contagem de objetos, an√°lise de tr√°fego\n",
        "\n",
        "3. **Segmenta√ß√£o Pan√≥ptica**:\n",
        "   - **Precis√£o**: Combina√ß√£o de sem√¢ntica e inst√¢ncia\n",
        "   - **IoU**: Balance entre classes e inst√¢ncias\n",
        "   - **Aplica√ß√£o**: An√°lise completa de cenas\n",
        "\n",
        "---\n",
        "\n",
        "## üìù Resumo do M√≥dulo 5\n",
        "\n",
        "### Principais Conceitos Abordados\n",
        "\n",
        "1. **Classifica√ß√£o**: Determinar \"o que\" est√° na imagem\n",
        "2. **Detec√ß√£o**: Determinar \"o que\" e \"onde\" est√£o os objetos\n",
        "3. **Segmenta√ß√£o**: Determinar \"o que\" est√° em cada pixel\n",
        "4. **Arquiteturas**: Espec√≠ficas para cada tarefa\n",
        "5. **M√©tricas**: Avalia√ß√£o adequada para cada tarefa\n",
        "\n",
        "### Demonstra√ß√µes Pr√°ticas\n",
        "\n",
        "**1. Classifica√ß√£o de Imagens:**\n",
        "   - Implementa√ß√£o de classificador simples\n",
        "   - An√°lise de probabilidades por classe\n",
        "   - C√°lculo de acur√°cia\n",
        "\n",
        "**2. Detec√ß√£o de Objetos:**\n",
        "   - Simula√ß√£o de detec√ß√£o com bounding boxes\n",
        "   - C√°lculo de IoU e m√©tricas de detec√ß√£o\n",
        "   - An√°lise de true/false positives/negatives\n",
        "\n",
        "**3. Segmenta√ß√£o de Imagens:**\n",
        "   - Cria√ß√£o de m√°scaras de segmenta√ß√£o\n",
        "   - C√°lculo de m√©tricas de segmenta√ß√£o\n",
        "   - An√°lise de performance por classe\n",
        "\n",
        "### Pr√≥ximos Passos\n",
        "\n",
        "No **M√≥dulo 6**, aplicaremos essas t√©cnicas em **OCR e Reconhecimento de Texto**, uma aplica√ß√£o espec√≠fica de vis√£o computacional.\n",
        "\n",
        "### Refer√™ncias Principais\n",
        "\n",
        "- [ImageNet Classification with Deep Convolutional Neural Networks - Krizhevsky et al.](https://papers.nips.cc/paper/2012/hash/c399862d3b9d6b76c8436e924a68c45b-Abstract.html)\n",
        "- [Rich feature hierarchies for accurate object detection and semantic segmentation - Girshick et al.](https://arxiv.org/abs/1311.2524)\n",
        "\n",
        "---\n",
        "\n",
        "**Pr√≥ximo M√≥dulo**: OCR e Reconhecimento de Texto"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéØ Conex√£o com o Pr√≥ximo M√≥dulo\n",
        "\n",
        "Agora que dominamos as **tarefas fundamentais** de vis√£o computacional, estamos preparados para aplicar essas t√©cnicas em **OCR e Reconhecimento de Texto**.\n",
        "\n",
        "No **M√≥dulo 6**, veremos como:\n",
        "\n",
        "### üîó **Conex√µes Diretas:**\n",
        "\n",
        "1. **Classifica√ß√£o** ‚Üí **Reconhecimento de Caracteres**\n",
        "   - Classificar cada caractere em uma categoria\n",
        "   - Aplicar CNNs para reconhecimento de padr√µes\n",
        "\n",
        "2. **Detec√ß√£o** ‚Üí **Localiza√ß√£o de Texto**\n",
        "   - Encontrar regi√µes de texto na imagem\n",
        "   - Usar bounding boxes para delimitar texto\n",
        "\n",
        "3. **Segmenta√ß√£o** ‚Üí **Separa√ß√£o de Caracteres**\n",
        "   - Dividir texto em caracteres individuais\n",
        "   - Criar m√°scaras para cada caractere\n",
        "\n",
        "4. **M√©tricas** ‚Üí **Avalia√ß√£o de OCR**\n",
        "   - Adaptar m√©tricas para texto\n",
        "   - Medir precis√£o de reconhecimento\n",
        "\n",
        "### üöÄ **Evolu√ß√£o Natural:**\n",
        "\n",
        "- **Tarefas Gerais** ‚Üí **Aplica√ß√£o Espec√≠fica**\n",
        "- **Objetos Visuais** ‚Üí **Caracteres de Texto**\n",
        "- **Classifica√ß√£o Simples** ‚Üí **Reconhecimento Sequencial**\n",
        "- **M√©tricas Visuais** ‚Üí **M√©tricas de Texto**\n",
        "\n",
        "Esta transi√ß√£o marca o in√≠cio da **aplica√ß√£o especializada** em reconhecimento de texto!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üñºÔ∏è Imagens de Refer√™ncia - M√≥dulo 5\n\n",
        "![Arquiteturas de Detec√ß√£o](https://cdn.jsdelivr.net/gh/rfapo/visao-computacional@main/images/modulo5/arquiteturas_deteccao.png)\n\n",
        "![Arquiteturas de Segmenta√ß√£o](https://cdn.jsdelivr.net/gh/rfapo/visao-computacional@main/images/modulo5/arquiteturas_segmentacao.png)\n\n",
        "![Compara√ß√£o das Tarefas](https://cdn.jsdelivr.net/gh/rfapo/visao-computacional@main/images/modulo5/comparacao_tarefas.png)\n\n",
        "![Evolu√ß√£o das Tarefas](https://cdn.jsdelivr.net/gh/rfapo/visao-computacional@main/images/modulo5/evolucao_tarefas.png)\n\n",
        "![M√©tricas de Avalia√ß√£o](https://cdn.jsdelivr.net/gh/rfapo/visao-computacional@main/images/modulo5/metricas_avaliacao.png)\n\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}