{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# M√≥dulo 3: Deep Learning para Vis√£o Computacional\n",
        "\n",
        "## üéØ Objetivos de Aprendizagem\n",
        "\n",
        "Ao final deste m√≥dulo, voc√™ ser√° capaz de:\n",
        "\n",
        "- ‚úÖ Compreender arquiteturas de CNNs (Redes Neurais Convolucionais)\n",
        "- ‚úÖ Entender o funcionamento de redes neurais convolucionais\n",
        "- ‚úÖ Conhecer arquiteturas cl√°ssicas e sua evolu√ß√£o\n",
        "- ‚úÖ Analisar diferen√ßas entre AlexNet, VGG e ResNet\n",
        "- ‚úÖ Implementar conceitos pr√°ticos com PyTorch\n",
        "\n",
        "---\n",
        "\n",
        "## üß† 3.1 Redes Neurais Convolucionais (CNNs)\n",
        "\n",
        "### Conceito Fundamental\n",
        "\n",
        "As **Redes Neurais Convolucionais** s√£o arquiteturas de deep learning especificamente projetadas para processar dados com estrutura espacial, como imagens. Elas foram inspiradas no sistema visual biol√≥gico e revolucionaram a vis√£o computacional.\n",
        "\n",
        "![CNNs - Conceito Geral](https://raw.githubusercontent.com/rfapo/visao-computacional/main/images/modulo3/cnns_conceito_geral.png?raw=true)\n",
        "\n",
        "### Inspira√ß√£o Biol√≥gica\n",
        "\n",
        "**Sistema Visual Humano:**\n",
        "- **Camadas hier√°rquicas** de processamento\n",
        "- **Campos receptivos locais** em cada neur√¥nio\n",
        "- **Detec√ß√£o progressiva** de caracter√≠sticas\n",
        "- **Invari√¢ncia a transla√ß√£o** e escala\n",
        "\n",
        "**Analogia com CNNs:**\n",
        "| Sistema Biol√≥gico | CNN | Fun√ß√£o |\n",
        "|-------------------|-----|--------|\n",
        "| **C√©lulas simples** | Conv Layers | Detec√ß√£o de bordas |\n",
        "| **C√©lulas complexas** | Deep Conv | Padr√µes complexos |\n",
        "| **Campos receptivos** | Kernels | Regi√£o de influ√™ncia |\n",
        "| **Pooling** | Pooling | Invari√¢ncia espacial |\n",
        "\n",
        "---\n",
        "\n",
        "## üèóÔ∏è 3.2 Arquitetura B√°sica de CNNs\n",
        "\n",
        "### Componentes Fundamentais\n",
        "\n",
        "![Arquitetura B√°sica CNNs](https://raw.githubusercontent.com/rfapo/visao-computacional/main/images/modulo3/arquitetura_basica_cnns.png?raw=true)\n",
        "\n",
        "#### **1. Camadas Convolucionais**\n",
        "\n",
        "**Caracter√≠sticas:**\n",
        "- **Filtros/Kernels aprend√≠veis**: Matrizes de pesos que detectam caracter√≠sticas espec√≠ficas\n",
        "- **Campo receptivo local**: Cada neur√¥nio conecta-se apenas a uma regi√£o local da entrada\n",
        "- **Compartilhamento de par√¢metros**: Mesmo filtro aplicado em toda a imagem\n",
        "- **Feature maps**: Mapas de caracter√≠sticas extra√≠das em cada camada\n",
        "- **Detec√ß√£o hier√°rquica**: Padr√µes simples ‚Üí complexos conforme profundidade\n",
        "\n",
        "**Matem√°tica da Convolu√ß√£o:**\n",
        "```\n",
        "Y[i,j] = Œ£ Œ£ X[i+m, j+n] * W[m,n] + b\n",
        "```\n",
        "\n",
        "**Par√¢metros Importantes:**\n",
        "| Par√¢metro | Descri√ß√£o | Efeito |\n",
        "|-----------|-----------|--------|\n",
        "| **Kernel Size** | Tamanho do filtro | Campo receptivo |\n",
        "| **Stride** | Passo de deslizamento | Resolu√ß√£o espacial |\n",
        "| **Padding** | Preenchimento de bordas | Controle de tamanho |\n",
        "| **Channels** | N√∫mero de filtros | Diversidade de features |\n",
        "\n",
        "#### **2. Camadas de Pooling**\n",
        "\n",
        "**Tipos:**\n",
        "- **Max Pooling**: Seleciona o valor m√°ximo em cada regi√£o\n",
        "- **Average Pooling**: Calcula a m√©dia dos valores na regi√£o\n",
        "- **Global Average Pooling**: M√©dia de toda a feature map\n",
        "\n",
        "**Benef√≠cios:**\n",
        "- **Redu√ß√£o de dimensionalidade espacial**: Diminui tamanho das feature maps\n",
        "- **Invari√¢ncia a transla√ß√£o**: Robustez a pequenos deslocamentos\n",
        "- **Redu√ß√£o de par√¢metros**: Menos computa√ß√£o nas camadas seguintes\n",
        "- **Preven√ß√£o de overfitting**: Regulariza√ß√£o impl√≠cita\n",
        "\n",
        "#### **3. Camadas Fully Connected**\n",
        "\n",
        "**Fun√ß√£o:**\n",
        "- **Classifica√ß√£o final**: Conecta todas as features extra√≠das\n",
        "- **Fun√ß√£o de ativa√ß√£o**: ReLU, Sigmoid, Softmax\n",
        "- **Dropout**: Regulariza√ß√£o para prevenir overfitting\n",
        "- **Output**: Probabilidades para cada classe\n",
        "\n",
        "**Estrutura T√≠pica:**\n",
        "```\n",
        "Flatten ‚Üí FC1 ‚Üí ReLU ‚Üí Dropout ‚Üí FC2 ‚Üí Softmax\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## üìà 3.3 Evolu√ß√£o das Arquiteturas\n",
        "\n",
        "### Progress√£o Hist√≥rica\n",
        "\n",
        "![Evolu√ß√£o das Arquiteturas](https://raw.githubusercontent.com/rfapo/visao-computacional/main/images/modulo3/evolucao_arquiteturas.png?raw=true)\n",
        "\n",
        "#### **2012 - AlexNet: A Revolu√ß√£o**\n",
        "\n",
        "**Caracter√≠sticas:**\n",
        "- **8 camadas** (5 conv + 3 FC)\n",
        "- **ReLU**: Primeira fun√ß√£o de ativa√ß√£o n√£o-linear eficiente\n",
        "- **Dropout**: Regulariza√ß√£o para prevenir overfitting\n",
        "- **Data Augmentation**: Aumento artificial de dados\n",
        "- **GPU Training**: Treinamento paralelo\n",
        "\n",
        "**Impacto:**\n",
        "- **Vencedor do ImageNet 2012**\n",
        "- **Redu√ß√£o de erro**: 26% ‚Üí 15.3%\n",
        "- **In√≠cio da era deep learning**\n",
        "\n",
        "#### **2014 - VGG: Simplicidade e Consist√™ncia**\n",
        "\n",
        "**Caracter√≠sticas:**\n",
        "- **Arquitetura simples**: Apenas 3√ó3 convolu√ß√µes\n",
        "- **Profundidade**: 16-19 camadas\n",
        "- **Consist√™ncia**: Mesmo padr√£o em todas as camadas\n",
        "- **Par√¢metros**: 138M (VGG-16)\n",
        "\n",
        "**Vantagens:**\n",
        "- **F√°cil de entender** e implementar\n",
        "- **Boa performance** em transfer learning\n",
        "- **Base s√≥lida** para outras arquiteturas\n",
        "\n",
        "#### **2015 - ResNet: Skip Connections**\n",
        "\n",
        "**Inova√ß√£o:**\n",
        "- **Skip Connections**: Conex√µes diretas entre camadas\n",
        "- **Residual Learning**: Aprender diferen√ßas (res√≠duos)\n",
        "- **Profundidade extrema**: At√© 152 camadas\n",
        "- **Gradient Flow**: Resolu√ß√£o do problema de vanishing gradients\n",
        "\n",
        "**F√≥rmula do Res√≠duo:**\n",
        "```\n",
        "H(x) = F(x) + x\n",
        "```\n",
        "\n",
        "**Benef√≠cios:**\n",
        "- **Treinamento de redes muito profundas**\n",
        "- **Melhor acur√°cia** com menos par√¢metros\n",
        "- **Estabilidade** no treinamento\n",
        "\n",
        "### Tend√™ncias Observadas\n",
        "\n",
        "| Aspecto | Tend√™ncia | Benef√≠cio |\n",
        "|--------|-----------|-----------|\n",
        "| **Profundidade** | Aumento constante | Maior capacidade |\n",
        "| **Efici√™ncia** | Menos par√¢metros | Menos computa√ß√£o |\n",
        "| **Inova√ß√£o** | Resolu√ß√£o de problemas | Melhor performance |\n",
        "| **Aplica√ß√£o** | Transfer learning | Reutiliza√ß√£o |\n",
        "\n",
        "---\n",
        "\n",
        "## üîç 3.4 Demonstra√ß√£o Pr√°tica: Visualiza√ß√£o de CNNs\n",
        "\n",
        "Vamos implementar e visualizar como as CNNs processam imagens:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "\n",
        "class SimpleCNN(nn.Module):\n",
        "    \"\"\"CNN simples para demonstra√ß√£o\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        \n",
        "        # Camada convolucional 1\n",
        "        self.conv1 = nn.Conv2d(1, 6, kernel_size=5, stride=1, padding=2)\n",
        "        \n",
        "        # Pooling\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        \n",
        "        # Camada convolucional 2\n",
        "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5, stride=1, padding=2)\n",
        "        \n",
        "        # Camadas fully connected\n",
        "        self.fc1 = nn.Linear(16 * 8 * 8, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # Primeira camada convolucional + pooling\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        \n",
        "        # Segunda camada convolucional + pooling\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        \n",
        "        # Flatten para fully connected\n",
        "        x = x.view(-1, 16 * 8 * 8)\n",
        "        \n",
        "        # Camadas fully connected\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        \n",
        "        return x\n",
        "\n",
        "def create_sample_image():\n",
        "    \"\"\"Cria uma imagem de exemplo para demonstra√ß√£o\"\"\"\n",
        "    # Criar imagem sint√©tica com formas\n",
        "    img = np.zeros((32, 32), dtype=np.uint8)\n",
        "    \n",
        "    # Adicionar formas\n",
        "    cv2.circle(img, (16, 16), 8, 255, -1)\n",
        "    cv2.rectangle(img, (8, 8), (24, 24), 128, 2)\n",
        "    \n",
        "    # Adicionar ru√≠do\n",
        "    noise = np.random.normal(0, 10, img.shape).astype(np.uint8)\n",
        "    img = cv2.add(img, noise)\n",
        "    \n",
        "    return img\n",
        "\n",
        "def visualize_cnn_layers():\n",
        "    \"\"\"Visualiza como uma CNN processa uma imagem\"\"\"\n",
        "    \n",
        "    # Criar modelo\n",
        "    model = SimpleCNN()\n",
        "    model.eval()\n",
        "    \n",
        "    # Criar imagem de exemplo\n",
        "    img = create_sample_image()\n",
        "    \n",
        "    # Converter para tensor\n",
        "    img_tensor = torch.FloatTensor(img).unsqueeze(0).unsqueeze(0) / 255.0\n",
        "    \n",
        "    # Processar atrav√©s das camadas\n",
        "    with torch.no_grad():\n",
        "        # Primeira camada convolucional\n",
        "        conv1_out = F.relu(model.conv1(img_tensor))\n",
        "        pool1_out = model.pool(conv1_out)\n",
        "        \n",
        "        # Segunda camada convolucional\n",
        "        conv2_out = F.relu(model.conv2(pool1_out))\n",
        "        pool2_out = model.pool(conv2_out)\n",
        "    \n",
        "    # Visualiza√ß√£o\n",
        "    fig, axes = plt.subplots(3, 6, figsize=(18, 9))\n",
        "    \n",
        "    # Imagem original\n",
        "    axes[0, 0].imshow(img, cmap='gray')\n",
        "    axes[0, 0].set_title('Imagem Original\\n(32√ó32)')\n",
        "    axes[0, 0].axis('off')\n",
        "    \n",
        "    # Primeira camada convolucional\n",
        "    for i in range(6):\n",
        "        feature_map = conv1_out[0, i].numpy()\n",
        "        axes[0, i+1].imshow(feature_map, cmap='viridis')\n",
        "        axes[0, i+1].set_title(f'Conv1 - Filtro {i+1}\\n({feature_map.shape[0]}√ó{feature_map.shape[1]})')\n",
        "        axes[0, i+1].axis('off')\n",
        "    \n",
        "    # Primeira camada de pooling\n",
        "    axes[1, 0].imshow(img, cmap='gray')\n",
        "    axes[1, 0].set_title('Ap√≥s Pooling 1\\n(16√ó16)')\n",
        "    axes[1, 0].axis('off')\n",
        "    \n",
        "    for i in range(6):\n",
        "        feature_map = pool1_out[0, i].numpy()\n",
        "        axes[1, i+1].imshow(feature_map, cmap='viridis')\n",
        "        axes[1, i+1].set_title(f'Pool1 - Filtro {i+1}\\n({feature_map.shape[0]}√ó{feature_map.shape[1]})')\n",
        "        axes[1, i+1].axis('off')\n",
        "    \n",
        "    # Segunda camada convolucional\n",
        "    axes[2, 0].imshow(img, cmap='gray')\n",
        "    axes[2, 0].set_title('Ap√≥s Pooling 2\\n(8√ó8)')\n",
        "    axes[2, 0].axis('off')\n",
        "    \n",
        "    for i in range(6):\n",
        "        feature_map = pool2_out[0, i].numpy()\n",
        "        axes[2, i+1].imshow(feature_map, cmap='viridis')\n",
        "        axes[2, i+1].set_title(f'Pool2 - Filtro {i+1}\\n({feature_map.shape[0]}√ó{feature_map.shape[1]})')\n",
        "        axes[2, i+1].axis('off')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # An√°lise quantitativa\n",
        "    print(\"=== AN√ÅLISE QUANTITATIVA DA CNN ===\")\n",
        "    print(f\"\\nImagem Original:\")\n",
        "    print(f\"  - Formato: {img.shape}\")\n",
        "    print(f\"  - Valores: {img.min()} - {img.max()}\")\n",
        "    \n",
        "    print(f\"\\nPrimeira Camada Convolucional:\")\n",
        "    print(f\"  - Feature maps: {conv1_out.shape[1]}\")\n",
        "    print(f\"  - Formato: {conv1_out.shape[2]}√ó{conv1_out.shape[3]}\")\n",
        "    print(f\"  - Valores: {conv1_out.min():.3f} - {conv1_out.max():.3f}\")\n",
        "    \n",
        "    print(f\"\\nAp√≥s Pooling 1:\")\n",
        "    print(f\"  - Feature maps: {pool1_out.shape[1]}\")\n",
        "    print(f\"  - Formato: {pool1_out.shape[2]}√ó{pool1_out.shape[3]}\")\n",
        "    print(f\"  - Redu√ß√£o: {conv1_out.shape[2]/pool1_out.shape[2]:.1f}x\")\n",
        "    \n",
        "    print(f\"\\nSegunda Camada Convolucional:\")\n",
        "    print(f\"  - Feature maps: {conv2_out.shape[1]}\")\n",
        "    print(f\"  - Formato: {conv2_out.shape[2]}√ó{conv2_out.shape[3]}\")\n",
        "    \n",
        "    print(f\"\\nAp√≥s Pooling 2:\")\n",
        "    print(f\"  - Feature maps: {pool2_out.shape[1]}\")\n",
        "    print(f\"  - Formato: {pool2_out.shape[2]}√ó{pool2_out.shape[3]}\")\n",
        "    print(f\"  - Redu√ß√£o total: {img.shape[0]/pool2_out.shape[2]:.1f}x\")\n",
        "    \n",
        "    return {\n",
        "        'original': img,\n",
        "        'conv1': conv1_out,\n",
        "        'pool1': pool1_out,\n",
        "        'conv2': conv2_out,\n",
        "        'pool2': pool2_out\n",
        "    }\n",
        "\n",
        "# Executar demonstra√ß√£o\n",
        "print(\"=== DEMONSTRA√á√ÉO: PROCESSAMENTO DE CNN ===\")\n",
        "cnn_results = visualize_cnn_layers()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### An√°lise dos Resultados\n",
        "\n",
        "**Observa√ß√µes Importantes:**\n",
        "\n",
        "1. **Primeira Camada Convolucional**:\n",
        "   - **Detec√ß√£o de bordas** e padr√µes simples\n",
        "   - **6 feature maps** diferentes\n",
        "   - **Preserva√ß√£o de resolu√ß√£o** espacial\n",
        "\n",
        "2. **Pooling 1**:\n",
        "   - **Redu√ß√£o de 2x** na resolu√ß√£o espacial\n",
        "   - **Invari√¢ncia a transla√ß√£o**\n",
        "   - **Redu√ß√£o de par√¢metros**\n",
        "\n",
        "3. **Segunda Camada Convolucional**:\n",
        "   - **Detec√ß√£o de padr√µes complexos**\n",
        "   - **16 feature maps** (mais diversidade)\n",
        "   - **Abstra√ß√£o hier√°rquica**\n",
        "\n",
        "4. **Pooling 2**:\n",
        "   - **Redu√ß√£o total de 4x**\n",
        "   - **Features altamente abstratas**\n",
        "   - **Prepara√ß√£o para classifica√ß√£o**\n",
        "\n",
        "---\n",
        "\n",
        "## üèõÔ∏è 3.5 Arquiteturas Cl√°ssicas em Detalhe\n",
        "\n",
        "### Compara√ß√£o Detalhada\n",
        "\n",
        "![Arquiteturas Cl√°ssicas](https://raw.githubusercontent.com/rfapo/visao-computacional/main/images/modulo3/arquiteturas_classicas.png?raw=true)\n",
        "\n",
        "#### **AlexNet (2012)**\n",
        "\n",
        "**Estrutura:**\n",
        "```\n",
        "Input (227√ó227√ó3)\n",
        "‚Üì\n",
        "Conv1 (11√ó11, 96) ‚Üí ReLU ‚Üí MaxPool (3√ó3)\n",
        "‚Üì\n",
        "Conv2 (5√ó5, 256) ‚Üí ReLU ‚Üí MaxPool (3√ó3)\n",
        "‚Üì\n",
        "Conv3 (3√ó3, 384) ‚Üí ReLU\n",
        "‚Üì\n",
        "Conv4 (3√ó3, 384) ‚Üí ReLU\n",
        "‚Üì\n",
        "Conv5 (3√ó3, 256) ‚Üí ReLU ‚Üí MaxPool (3√ó3)\n",
        "‚Üì\n",
        "FC1 (4096) ‚Üí ReLU ‚Üí Dropout\n",
        "‚Üì\n",
        "FC2 (4096) ‚Üí ReLU ‚Üí Dropout\n",
        "‚Üì\n",
        "FC3 (1000) ‚Üí Softmax\n",
        "```\n",
        "\n",
        "**Caracter√≠sticas:**\n",
        "- **Par√¢metros**: 60M\n",
        "- **Inova√ß√µes**: ReLU, Dropout, Data Augmentation\n",
        "- **Performance**: 15.3% erro no ImageNet\n",
        "\n",
        "#### **VGG (2014)**\n",
        "\n",
        "**Estrutura VGG-16:**\n",
        "```\n",
        "Input (224√ó224√ó3)\n",
        "‚Üì\n",
        "Conv3√ó3 (64) ‚Üí ReLU ‚Üí Conv3√ó3 (64) ‚Üí ReLU ‚Üí MaxPool\n",
        "‚Üì\n",
        "Conv3√ó3 (128) ‚Üí ReLU ‚Üí Conv3√ó3 (128) ‚Üí ReLU ‚Üí MaxPool\n",
        "‚Üì\n",
        "Conv3√ó3 (256) ‚Üí ReLU ‚Üí Conv3√ó3 (256) ‚Üí ReLU ‚Üí Conv3√ó3 (256) ‚Üí ReLU ‚Üí MaxPool\n",
        "‚Üì\n",
        "Conv3√ó3 (512) ‚Üí ReLU ‚Üí Conv3√ó3 (512) ‚Üí ReLU ‚Üí Conv3√ó3 (512) ‚Üí ReLU ‚Üí MaxPool\n",
        "‚Üì\n",
        "Conv3√ó3 (512) ‚Üí ReLU ‚Üí Conv3√ó3 (512) ‚Üí ReLU ‚Üí Conv3√ó3 (512) ‚Üí ReLU ‚Üí MaxPool\n",
        "‚Üì\n",
        "FC (4096) ‚Üí ReLU ‚Üí Dropout ‚Üí FC (4096) ‚Üí ReLU ‚Üí Dropout ‚Üí FC (1000)\n",
        "```\n",
        "\n",
        "**Caracter√≠sticas:**\n",
        "- **Par√¢metros**: 138M\n",
        "- **Simplicidade**: Apenas 3√ó3 convolu√ß√µes\n",
        "- **Performance**: 7.3% erro no ImageNet\n",
        "\n",
        "#### **ResNet (2015)**\n",
        "\n",
        "**Estrutura ResNet-50:**\n",
        "```\n",
        "Input (224√ó224√ó3)\n",
        "‚Üì\n",
        "Conv7√ó7 (64) ‚Üí BatchNorm ‚Üí ReLU ‚Üí MaxPool\n",
        "‚Üì\n",
        "Residual Block 1 (64) ‚Üí Residual Block 2 (64) ‚Üí Residual Block 3 (64)\n",
        "‚Üì\n",
        "Residual Block 4 (128) ‚Üí Residual Block 5 (128) ‚Üí Residual Block 6 (128) ‚Üí Residual Block 7 (128)\n",
        "‚Üì\n",
        "Residual Block 8 (256) ‚Üí ... ‚Üí Residual Block 15 (256)\n",
        "‚Üì\n",
        "Residual Block 16 (512) ‚Üí ... ‚Üí Residual Block 18 (512)\n",
        "‚Üì\n",
        "Global Average Pooling ‚Üí FC (1000)\n",
        "```\n",
        "\n",
        "**Caracter√≠sticas:**\n",
        "- **Par√¢metros**: 25M\n",
        "- **Inova√ß√£o**: Skip connections\n",
        "- **Performance**: 3.6% erro no ImageNet\n",
        "\n",
        "### Compara√ß√£o Quantitativa\n",
        "\n",
        "| Arquitetura | Par√¢metros | Camadas | Erro ImageNet | Inova√ß√£o Principal |\n",
        "|-------------|------------|---------|---------------|-------------------|\n",
        "| **AlexNet** | 60M | 8 | 15.3% | ReLU, Dropout |\n",
        "| **VGG-16** | 138M | 16 | 7.3% | Simplicidade |\n",
        "| **ResNet-50** | 25M | 50 | 3.6% | Skip Connections |\n",
        "\n",
        "---\n",
        "\n",
        "## üîç 3.6 Demonstra√ß√£o Pr√°tica: Compara√ß√£o de Arquiteturas\n",
        "\n",
        "Vamos implementar e comparar diferentes arquiteturas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "class AlexNetLike(nn.Module):\n",
        "    \"\"\"Implementa√ß√£o simplificada do AlexNet\"\"\"\n",
        "    \n",
        "    def __init__(self, num_classes=10):\n",
        "        super(AlexNetLike, self).__init__()\n",
        "        \n",
        "        # Camadas convolucionais\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2)\n",
        "        self.conv2 = nn.Conv2d(64, 192, kernel_size=5, padding=2)\n",
        "        self.conv3 = nn.Conv2d(192, 384, kernel_size=3, padding=1)\n",
        "        self.conv4 = nn.Conv2d(384, 256, kernel_size=3, padding=1)\n",
        "        self.conv5 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
        "        \n",
        "        # Pooling\n",
        "        self.pool = nn.MaxPool2d(kernel_size=3, stride=2)\n",
        "        \n",
        "        # Camadas fully connected\n",
        "        self.fc1 = nn.Linear(256 * 6 * 6, 4096)\n",
        "        self.fc2 = nn.Linear(4096, 4096)\n",
        "        self.fc3 = nn.Linear(4096, num_classes)\n",
        "        \n",
        "        # Dropout\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # Camadas convolucionais\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = F.relu(self.conv4(x))\n",
        "        x = self.pool(F.relu(self.conv5(x)))\n",
        "        \n",
        "        # Flatten\n",
        "        x = x.view(-1, 256 * 6 * 6)\n",
        "        \n",
        "        # Fully connected\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc3(x)\n",
        "        \n",
        "        return x\n",
        "\n",
        "class VGGLike(nn.Module):\n",
        "    \"\"\"Implementa√ß√£o simplificada do VGG\"\"\"\n",
        "    \n",
        "    def __init__(self, num_classes=10):\n",
        "        super(VGGLike, self).__init__()\n",
        "        \n",
        "        # Camadas convolucionais\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.conv4 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
        "        self.conv5 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
        "        self.conv6 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
        "        \n",
        "        # Pooling\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        \n",
        "        # Camadas fully connected\n",
        "        self.fc1 = nn.Linear(256 * 4 * 4, 512)\n",
        "        self.fc2 = nn.Linear(512, 512)\n",
        "        self.fc3 = nn.Linear(512, num_classes)\n",
        "        \n",
        "        # Dropout\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # Camadas convolucionais\n",
        "        x = self.pool(F.relu(self.conv2(F.relu(self.conv1(x)))))\n",
        "        x = self.pool(F.relu(self.conv4(F.relu(self.conv3(x)))))\n",
        "        x = self.pool(F.relu(self.conv6(F.relu(self.conv5(x)))))\n",
        "        \n",
        "        # Flatten\n",
        "        x = x.view(-1, 256 * 4 * 4)\n",
        "        \n",
        "        # Fully connected\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc3(x)\n",
        "        \n",
        "        return x\n",
        "\n",
        "class ResNetLike(nn.Module):\n",
        "    \"\"\"Implementa√ß√£o simplificada do ResNet\"\"\"\n",
        "    \n",
        "    def __init__(self, num_classes=10):\n",
        "        super(ResNetLike, self).__init__()\n",
        "        \n",
        "        # Camada inicial\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        \n",
        "        # Blocos residuais\n",
        "        self.layer1 = self._make_layer(64, 64, 2)\n",
        "        self.layer2 = self._make_layer(64, 128, 2, stride=2)\n",
        "        self.layer3 = self._make_layer(128, 256, 2, stride=2)\n",
        "        \n",
        "        # Camada final\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(256, num_classes)\n",
        "        \n",
        "    def _make_layer(self, in_channels, out_channels, blocks, stride=1):\n",
        "        layers = []\n",
        "        \n",
        "        # Primeiro bloco com mudan√ßa de dimens√£o\n",
        "        layers.append(ResidualBlock(in_channels, out_channels, stride))\n",
        "        \n",
        "        # Blocos restantes\n",
        "        for _ in range(1, blocks):\n",
        "            layers.append(ResidualBlock(out_channels, out_channels))\n",
        "        \n",
        "        return nn.Sequential(*layers)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = self.pool(x)\n",
        "        \n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        \n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc(x)\n",
        "        \n",
        "        return x\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "    \"\"\"Bloco residual para ResNet\"\"\"\n",
        "    \n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        \n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        \n",
        "        # Skip connection\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_channels != out_channels:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride),\n",
        "                nn.BatchNorm2d(out_channels)\n",
        "            )\n",
        "    \n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        \n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        \n",
        "        out += self.shortcut(residual)\n",
        "        out = F.relu(out)\n",
        "        \n",
        "        return out\n",
        "\n",
        "def compare_architectures():\n",
        "    \"\"\"Compara diferentes arquiteturas de CNN\"\"\"\n",
        "    \n",
        "    # Criar modelos\n",
        "    alexnet = AlexNetLike()\n",
        "    vgg = VGGLike()\n",
        "    resnet = ResNetLike()\n",
        "    \n",
        "    # Contar par√¢metros\n",
        "    alexnet_params = sum(p.numel() for p in alexnet.parameters())\n",
        "    vgg_params = sum(p.numel() for p in vgg.parameters())\n",
        "    resnet_params = sum(p.numel() for p in resnet.parameters())\n",
        "    \n",
        "    # Simular tempo de treinamento\n",
        "    alexnet_time = alexnet_params / 1000000 * 0.1  # segundos por √©poca\n",
        "    vgg_time = vgg_params / 1000000 * 0.1\n",
        "    resnet_time = resnet_params / 1000000 * 0.1\n",
        "    \n",
        "    # Simular acur√°cia\n",
        "    alexnet_acc = 0.85\n",
        "    vgg_acc = 0.92\n",
        "    resnet_acc = 0.95\n",
        "    \n",
        "    # Visualiza√ß√£o\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "    \n",
        "    # Par√¢metros\n",
        "    architectures = ['AlexNet', 'VGG', 'ResNet']\n",
        "    params = [alexnet_params, vgg_params, resnet_params]\n",
        "    \n",
        "    axes[0, 0].bar(architectures, params, color=['red', 'blue', 'green'])\n",
        "    axes[0, 0].set_title('N√∫mero de Par√¢metros')\n",
        "    axes[0, 0].set_ylabel('Par√¢metros (milh√µes)')\n",
        "    axes[0, 0].tick_params(axis='x', rotation=45)\n",
        "    \n",
        "    # Tempo de treinamento\n",
        "    times = [alexnet_time, vgg_time, resnet_time]\n",
        "    \n",
        "    axes[0, 1].bar(architectures, times, color=['red', 'blue', 'green'])\n",
        "    axes[0, 1].set_title('Tempo de Treinamento (simulado)')\n",
        "    axes[0, 1].set_ylabel('Segundos por √©poca')\n",
        "    axes[0, 1].tick_params(axis='x', rotation=45)\n",
        "    \n",
        "    # Acur√°cia\n",
        "    accuracies = [alexnet_acc, vgg_acc, resnet_acc]\n",
        "    \n",
        "    axes[1, 0].bar(architectures, accuracies, color=['red', 'blue', 'green'])\n",
        "    axes[1, 0].set_title('Acur√°cia (simulada)')\n",
        "    axes[1, 0].set_ylabel('Acur√°cia')\n",
        "    axes[1, 0].set_ylim(0, 1)\n",
        "    axes[1, 0].tick_params(axis='x', rotation=45)\n",
        "    \n",
        "    # Compara√ß√£o geral\n",
        "    x = np.arange(len(architectures))\n",
        "    width = 0.25\n",
        "    \n",
        "    # Normalizar para compara√ß√£o\n",
        "    norm_params = [p/max(params) for p in params]\n",
        "    norm_times = [t/max(times) for t in times]\n",
        "    \n",
        "    axes[1, 1].bar(x - width, norm_params, width, label='Par√¢metros (norm)', alpha=0.7)\n",
        "    axes[1, 1].bar(x, norm_times, width, label='Tempo (norm)', alpha=0.7)\n",
        "    axes[1, 1].bar(x + width, accuracies, width, label='Acur√°cia', alpha=0.7)\n",
        "    \n",
        "    axes[1, 1].set_title('Compara√ß√£o Geral (Normalizada)')\n",
        "    axes[1, 1].set_ylabel('Valor Normalizado')\n",
        "    axes[1, 1].set_xticks(x)\n",
        "    axes[1, 1].set_xticklabels(architectures)\n",
        "    axes[1, 1].legend()\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # An√°lise quantitativa\n",
        "    print(\"=== COMPARA√á√ÉO DE ARQUITETURAS ===\")\n",
        "    \n",
        "    for i, arch in enumerate(architectures):\n",
        "        print(f\"\\n{arch}:\")\n",
        "        print(f\"  - Par√¢metros: {params[i]:,} ({params[i]/1000000:.1f}M)\")\n",
        "        print(f\"  - Tempo/√©poca: {times[i]:.2f}s\")\n",
        "        print(f\"  - Acur√°cia: {accuracies[i]:.2%}\")\n",
        "        print(f\"  - Efici√™ncia: {accuracies[i]/(params[i]/1000000):.2f}% por M par√¢metros\")\n",
        "    \n",
        "    return {\n",
        "        'alexnet': {'params': alexnet_params, 'time': alexnet_time, 'acc': alexnet_acc},\n",
        "        'vgg': {'params': vgg_params, 'time': vgg_time, 'acc': vgg_acc},\n",
        "        'resnet': {'params': resnet_params, 'time': resnet_time, 'acc': resnet_acc}\n",
        "    }\n",
        "\n",
        "# Executar demonstra√ß√£o\n",
        "print(\"=== DEMONSTRA√á√ÉO: COMPARA√á√ÉO DE ARQUITETURAS ===\")\n",
        "comparison_results = compare_architectures()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### An√°lise dos Resultados\n",
        "\n",
        "**Observa√ß√µes Importantes:**\n",
        "\n",
        "1. **AlexNet**:\n",
        "   - **Par√¢metros**: Moderados (60M)\n",
        "   - **Performance**: Boa para √©poca\n",
        "   - **Inova√ß√£o**: ReLU, Dropout\n",
        "\n",
        "2. **VGG**:\n",
        "   - **Par√¢metros**: Muitos (138M)\n",
        "   - **Performance**: Excelente\n",
        "   - **Simplicidade**: Arquitetura limpa\n",
        "\n",
        "3. **ResNet**:\n",
        "   - **Par√¢metros**: Poucos (25M)\n",
        "   - **Performance**: Superior\n",
        "   - **Efici√™ncia**: Melhor rela√ß√£o par√¢metros/performance\n",
        "\n",
        "---\n",
        "\n",
        "## üìù Resumo do M√≥dulo 3\n",
        "\n",
        "### Principais Conceitos Abordados\n",
        "\n",
        "1. **Fundamentos**: CNNs e inspira√ß√£o biol√≥gica\n",
        "2. **Arquitetura**: Componentes b√°sicos (Conv, Pool, FC)\n",
        "3. **Evolu√ß√£o**: AlexNet ‚Üí VGG ‚Üí ResNet\n",
        "4. **Inova√ß√µes**: ReLU, Dropout, Skip Connections\n",
        "5. **Compara√ß√£o**: Par√¢metros, performance, efici√™ncia\n",
        "\n",
        "### Demonstra√ß√µes Pr√°ticas\n",
        "\n",
        "**1. Processamento de CNN:**\n",
        "   - Visualiza√ß√£o de feature maps\n",
        "   - An√°lise de camadas\n",
        "   - Redu√ß√£o de dimensionalidade\n",
        "\n",
        "**2. Compara√ß√£o de Arquiteturas:**\n",
        "   - Implementa√ß√£o de AlexNet, VGG, ResNet\n",
        "   - An√°lise de par√¢metros\n",
        "   - Compara√ß√£o de performance\n",
        "\n",
        "### Pr√≥ximos Passos\n",
        "\n",
        "No **M√≥dulo 4**, aprenderemos como aproveitar essas arquiteturas atrav√©s de **Transfer Learning**, aplicando modelos pr√©-treinados em problemas espec√≠ficos.\n",
        "\n",
        "### Refer√™ncias Principais\n",
        "\n",
        "- [Deep Learning - Goodfellow, Bengio & Courville](https://www.deeplearningbook.org/)\n",
        "- [CS231n Course - Stanford](http://cs231n.stanford.edu/)\n",
        "\n",
        "---\n",
        "\n",
        "**Pr√≥ximo M√≥dulo**: Transfer Learning e Aplica√ß√µes Pr√°ticas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéØ Conex√£o com o Pr√≥ximo M√≥dulo\n",
        "\n",
        "Agora que dominamos as **arquiteturas de CNNs**, estamos preparados para entender como aproveitar esse conhecimento atrav√©s de **Transfer Learning**.\n",
        "\n",
        "No **M√≥dulo 4**, veremos como:\n",
        "\n",
        "### üîó **Conex√µes Diretas:**\n",
        "\n",
        "1. **Modelos Pr√©-treinados** ‚Üí **Aproveitamento de Conhecimento**\n",
        "   - AlexNet, VGG, ResNet treinados no ImageNet\n",
        "   - Reutiliza√ß√£o de representa√ß√µes aprendidas\n",
        "\n",
        "2. **Feature Extraction** ‚Üí **Primeiras Camadas Congeladas**\n",
        "   - Aproveitamento de caracter√≠sticas universais\n",
        "   - Treinamento apenas da camada de classifica√ß√£o\n",
        "\n",
        "3. **Fine-tuning** ‚Üí **Ajuste Fino de Par√¢metros**\n",
        "   - Descongelamento de camadas finais\n",
        "   - Adapta√ß√£o a dom√≠nios espec√≠ficos\n",
        "\n",
        "4. **Efici√™ncia** ‚Üí **Menos Dados e Tempo**\n",
        "   - Redu√ß√£o de 10x no tempo de treinamento\n",
        "   - Requisito de 5-10x menos dados\n",
        "\n",
        "### üöÄ **Evolu√ß√£o Natural:**\n",
        "\n",
        "- **Treinamento do Zero** ‚Üí **Aproveitamento de Conhecimento**\n",
        "- **Grandes Datasets** ‚Üí **Datasets Pequenos**\n",
        "- **Tempo Longo** ‚Üí **Treinamento R√°pido**\n",
        "- **Uma Tarefa** ‚Üí **M√∫ltiplas Aplica√ß√µes**\n",
        "\n",
        "Esta transi√ß√£o marca o in√≠cio da **era pr√°tica** do deep learning em vis√£o computacional!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üñºÔ∏è Imagens de Refer√™ncia - M√≥dulo 3\n\n",
        "![Arquitetura AlexNet](https://raw.githubusercontent.com/rfapo/visao-computacional/main/images/modulo3/arquitetura_alexnet.png?raw=true)\n\n",
        "![Arquitetura ResNet](https://raw.githubusercontent.com/rfapo/visao-computacional/main/images/modulo3/arquitetura_resnet.png?raw=true)\n\n",
        "![Arquitetura VGG](https://raw.githubusercontent.com/rfapo/visao-computacional/main/images/modulo3/arquitetura_vgg.png?raw=true)\n\n",
        "![Fun√ß√µes de Ativa√ß√£o](https://raw.githubusercontent.com/rfapo/visao-computacional/main/images/modulo3/funcoes_ativacao.png?raw=true)\n\n",
        "![T√©cnicas de Regulariza√ß√£o](https://raw.githubusercontent.com/rfapo/visao-computacional/main/images/modulo3/tecnicas_regularizacao.png?raw=true)\n\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}