{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Módulo 3: Deep Learning para Visão Computacional",
        "",
        "## Objetivos de Aprendizagem",
        "- Compreender arquiteturas de CNNs (Redes Neurais Convolucionais)",
        "- Entender o funcionamento de redes neurais convolucionais",
        "- Conhecer arquiteturas clássicas e sua evolução",
        "- Analisar diferenças entre AlexNet, VGG e ResNet",
        "- Implementar conceitos práticos com PyTorch",
        "",
        "---",
        "",
        "## 3.1 Redes Neurais Convolucionais (CNNs)",
        "",
        "As **Redes Neurais Convolucionais** são arquiteturas de deep learning especificamente projetadas para processar dados com estrutura espacial, como imagens. Elas foram inspiradas no sistema visual biológico e revolucionaram a visão computacional.",
        "",
        "![CNNs - Conceito Geral](https://raw.githubusercontent.com/rfapo/visao-computacional/main/images/modulo3/cnns_conceito_geral.png)",
        "",
        "### Arquitetura Básica de CNNs",
        "",
        "**Componentes Fundamentais:**",
        "",
        "![Arquitetura Básica CNNs](https://raw.githubusercontent.com/rfapo/visao-computacional/main/images/modulo3/arquitetura_basica_cnns.png)",
        "",
        "#### **1. Camadas Convolucionais**",
        "- **Filtros/Kernels aprendíveis**: Matrizes de pesos que detectam características específicas",
        "- **Campo receptivo local**: Cada neurônio conecta-se apenas a uma região local da entrada",
        "- **Compartilhamento de parâmetros**: Mesmo filtro aplicado em toda a imagem",
        "- **Operação de convolução matemática**: Produto elemento a elemento + soma",
        "- **Feature maps**: Mapas de características extraídas em cada camada",
        "- **Detecção hierárquica**: Padrões simples → complexos conforme profundidade",
        "",
        "**Matemática da Convolução:**",
        "```",
        "Y[i,j] = Σ Σ X[i+m, j+n] * W[m,n] + b",
        "```",
        "",
        "#### **2. Camadas de Pooling**",
        "- **Max Pooling**: Seleciona o valor máximo em cada região",
        "- **Average Pooling**: Calcula a média dos valores na região",
        "- **Redução de dimensionalidade espacial**: Diminui tamanho das feature maps",
        "- **Invariância a translação**: Robustez a pequenos deslocamentos",
        "- **Stride**: Passo de deslizamento do kernel",
        "- **Receptive field**: Campo de visão de cada neurônio",
        "",
        "#### **3. Camadas Fully Connected**",
        "- **Classificação final**: Conecta todas as features extraídas",
        "- **Função de ativação**: ReLU, Sigmoid, Softmax",
        "- **Dropout**: Regularização para prevenir overfitting",
        "- **Output**: Probabilidades para cada classe",
        "",
        "### Evolução das Arquiteturas",
        "",
        "**Progressão Histórica:**",
        "- **2012 - AlexNet**: Primeira CNN vencedora do ImageNet",
        "- **2014 - VGG**: Arquitetura simples e consistente",
        "- **2015 - ResNet**: Skip connections e redes profundas",
        "- **2016+**: Evoluções e melhorias incrementais",
        "",
        "![Evolução das Arquiteturas](https://raw.githubusercontent.com/rfapo/visao-computacional/main/images/modulo3/evolucao_arquiteturas.png)",
        "",
        "**Tendências Observadas:**",
        "- **Profundidade**: Aumento constante do número de camadas",
        "- **Eficiência**: Redução de parâmetros com melhor performance",
        "- **Inovação**: Resolução de problemas específicos",
        "- **Aplicação**: Transfer learning e modelos pré-treinados",
        "",
        "**Referências:**",
        "- [Deep Learning - Goodfellow, Bengio & Courville](https://www.deeplearningbook.org/)",
        "- [CS231n Course - Stanford](http://cs231n.stanford.edu/)",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3.2 Demonstração Prática: Visualização de CNNs\n",
        "\n",
        "Vamos implementar e visualizar como as CNNs processam imagens:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "\n",
        "class SimpleCNN(nn.Module):\n",
        "    \"\"\"CNN simples para demonstração\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        \n",
        "        # Camada convolucional 1\n",
        "        self.conv1 = nn.Conv2d(1, 6, kernel_size=5, stride=1, padding=2)\n",
        "        \n",
        "        # Pooling\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        \n",
        "        # Camada convolucional 2\n",
        "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5, stride=1, padding=2)\n",
        "        \n",
        "        # Camadas fully connected\n",
        "        self.fc1 = nn.Linear(16 * 8 * 8, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # Primeira camada convolucional + pooling\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        \n",
        "        # Segunda camada convolucional + pooling\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        \n",
        "        # Flatten para fully connected\n",
        "        x = x.view(-1, 16 * 8 * 8)\n",
        "        \n",
        "        # Camadas fully connected\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        \n",
        "        return x\n",
        "\n",
        "def create_sample_image():\n",
        "    \"\"\"Cria uma imagem de exemplo para demonstração\"\"\"\n",
        "    # Criar imagem sintética com formas\n",
        "    img = np.zeros((32, 32), dtype=np.uint8)\n",
        "    \n",
        "    # Adicionar formas\n",
        "    cv2.circle(img, (16, 16), 8, 255, -1)\n",
        "    cv2.rectangle(img, (8, 8), (24, 24), 128, 2)\n",
        "    \n",
        "    # Adicionar ruído\n",
        "    noise = np.random.normal(0, 10, img.shape).astype(np.uint8)\n",
        "    img = cv2.add(img, noise)\n",
        "    \n",
        "    return img\n",
        "\n",
        "def visualize_cnn_layers():\n",
        "    \"\"\"Visualiza como uma CNN processa uma imagem\"\"\"\n",
        "    \n",
        "    # Criar modelo\n",
        "    model = SimpleCNN()\n",
        "    model.eval()\n",
        "    \n",
        "    # Criar imagem de exemplo\n",
        "    img = create_sample_image()\n",
        "    \n",
        "    # Converter para tensor\n",
        "    img_tensor = torch.FloatTensor(img).unsqueeze(0).unsqueeze(0) / 255.0\n",
        "    \n",
        "    # Processar através das camadas\n",
        "    with torch.no_grad():\n",
        "        # Primeira camada convolucional\n",
        "        conv1_out = F.relu(model.conv1(img_tensor))\n",
        "        pool1_out = model.pool(conv1_out)\n",
        "        \n",
        "        # Segunda camada convolucional\n",
        "        conv2_out = F.relu(model.conv2(pool1_out))\n",
        "        pool2_out = model.pool(conv2_out)\n",
        "        \n",
        "        # Flatten\n",
        "        flattened = pool2_out.view(-1, 16 * 8 * 8)\n",
        "        \n",
        "        # Fully connected\n",
        "        fc1_out = F.relu(model.fc1(flattened))\n",
        "        fc2_out = F.relu(model.fc2(fc1_out))\n",
        "        output = model.fc3(fc2_out)\n",
        "        \n",
        "    # Visualização\n",
        "    fig, axes = plt.subplots(3, 6, figsize=(18, 12))\n",
        "    \n",
        "    # Imagem original\n",
        "    axes[0, 0].imshow(img, cmap='gray')\n",
        "    axes[0, 0].set_title('Imagem Original\\n(32×32)')\n",
        "    axes[0, 0].axis('off')\n",
        "    \n",
        "    # Primeira camada convolucional (6 filtros)\n",
        "    for i in range(6):\n",
        "        if i < 5:\n",
        "            axes[0, i+1].imshow(conv1_out[0, i].numpy(), cmap='viridis')\n",
        "            axes[0, i+1].set_title(f'Conv1 - Filtro {i+1}')\n",
        "            axes[0, i+1].axis('off')\n",
        "        else:\n",
        "            axes[0, i+1].axis('off')\n",
        "    \n",
        "    # Primeira camada de pooling\n",
        "    for i in range(6):\n",
        "        if i < 5:\n",
        "            axes[1, i+1].imshow(pool1_out[0, i].numpy(), cmap='viridis')\n",
        "            axes[1, i+1].set_title(f'Pool1 - Filtro {i+1}')\n",
        "            axes[1, i+1].axis('off')\n",
        "        else:\n",
        "            axes[1, i+1].axis('off')\n",
        "    \n",
        "    # Segunda camada convolucional (16 filtros)\n",
        "    for i in range(6):\n",
        "        if i < 5:\n",
        "            axes[2, i+1].imshow(conv2_out[0, i].numpy(), cmap='viridis')\n",
        "            axes[2, i+1].set_title(f'Conv2 - Filtro {i+1}')\n",
        "            axes[2, i+1].axis('off')\n",
        "        else:\n",
        "            axes[2, i+1].axis('off')\n",
        "    \n",
        "    # Adicionar informações sobre dimensões\n",
        "    axes[1, 0].text(0.5, 0.5, f'Conv1 Output:\\n{conv1_out.shape[2]}×{conv1_out.shape[3]}\\n6 filtros', \n",
        "                    ha='center', va='center', fontsize=10,\n",
        "                    bbox=dict(boxstyle='round', facecolor='lightblue'))\n",
        "    axes[1, 0].axis('off')\n",
        "    \n",
        "    axes[2, 0].text(0.5, 0.5, f'Conv2 Output:\\n{conv2_out.shape[2]}×{conv2_out.shape[3]}\\n16 filtros', \n",
        "                    ha='center', va='center', fontsize=10,\n",
        "                    bbox=dict(boxstyle='round', facecolor='lightgreen'))\n",
        "    axes[2, 0].axis('off')\n",
        "    \n",
        "    plt.suptitle('Processamento de Imagem através de CNN', fontsize=16)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    return {\n",
        "        'original': img,\n",
        "        'conv1': conv1_out,\n",
        "        'pool1': pool1_out,\n",
        "        'conv2': conv2_out,\n",
        "        'pool2': pool2_out,\n",
        "        'output': output\n",
        "    }\n",
        "\n",
        "# Executar demonstração\n",
        "cnn_results = visualize_cnn_layers()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Análise dos Resultados\n",
        "\n",
        "**Processamento Observado:**\n",
        "\n",
        "1. **Imagem Original (32×32)**: Formas geométricas com ruído\n",
        "2. **Conv1 (6 filtros)**: Detecção de bordas e padrões básicos\n",
        "3. **Pool1**: Redução de dimensionalidade, preservação de características\n",
        "4. **Conv2 (16 filtros)**: Detecção de padrões mais complexos\n",
        "5. **Pool2**: Redução final, preparação para classificação\n",
        "\n",
        "**Insights Importantes:**\n",
        "- **Hierarquia**: Padrões simples → complexos\n",
        "- **Redução**: Dimensionalidade diminui a cada camada\n",
        "- **Features**: Cada filtro detecta características específicas\n",
        "- **Robustez**: Pooling aumenta invariância a translação\n",
        "\n",
        "**Referências:**\n",
        "- [Deep Learning - Goodfellow, Bengio & Courville](https://www.deeplearningbook.org/)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3.3 Arquiteturas Clássicas",
        "",
        "### AlexNet (2012) - A Revolução",
        "",
        "**Características Principais:**",
        "- **8 camadas**: 5 convolucionais + 3 fully connected",
        "- **60M parâmetros**: Modelo grande para época",
        "- **ReLU activation**: Primeira aplicação em larga escala",
        "- **Dropout**: Regularização eficaz",
        "- **Data augmentation**: Expansão do dataset",
        "- **GPU training**: Paralelização massiva",
        "",
        "![Arquitetura AlexNet](https://raw.githubusercontent.com/rfapo/visao-computacional/main/images/modulo3/arquitetura_alexnet.png)",
        "",
        "**Inovações Técnicas:**",
        "- **ReLU**: Solução para vanishing gradient",
        "- **Dropout**: Prevenção de overfitting",
        "- **GPU**: Treinamento em paralelo",
        "- **Data augmentation**: Rotação, espelhamento, crop",
        "",
        "### VGG (2014) - Simplicidade e Profundidade",
        "",
        "**Características Principais:**",
        "- **16-19 camadas**: VGG-16 e VGG-19",
        "- **138M parâmetros**: Modelo muito grande",
        "- **Kernels 3×3**: Filtros pequenos e consistentes",
        "- **Arquitetura simples**: Padrão repetitivo",
        "- **Transfer learning**: Base para muitos modelos",
        "",
        "![Arquitetura VGG](https://raw.githubusercontent.com/rfapo/visao-computacional/main/images/modulo3/arquitetura_vgg.png)",
        "",
        "**Vantagens:**",
        "- **Simplicidade**: Arquitetura fácil de entender",
        "- **Profundidade**: Muitas camadas para features complexas",
        "- **Transfer learning**: Excelente para fine-tuning",
        "- **Robustez**: Performance consistente",
        "",
        "### ResNet (2015) - Skip Connections",
        "",
        "**Características Principais:**",
        "- **50-152 camadas**: ResNet-50, ResNet-101, ResNet-152",
        "- **25M parâmetros**: Menos que VGG-16",
        "- **Skip connections**: Conexões residuais",
        "- **Batch normalization**: Normalização por lotes",
        "- **Degradação resolvida**: Treinamento de redes muito profundas",
        "",
        "![Arquitetura ResNet](https://raw.githubusercontent.com/rfapo/visao-computacional/main/images/modulo3/arquitetura_resnet.png)",
        "",
        "**Inovações Técnicas:**",
        "- **Skip connections**: H(x) = F(x) + x",
        "- **Residual learning**: Aprende diferenças (resíduos)",
        "- **Batch normalization**: Estabilização do treinamento",
        "- **Identity mapping**: Preserva informação original",
        "",
        "**Referências:**",
        "- [ImageNet Classification with Deep Convolutional Neural Networks - Krizhevsky et al.](https://papers.nips.cc/paper/2012/hash/c399862d3b9d6b76c8436e924a68c45b-Abstract.html)",
        "- [Very Deep Convolutional Networks for Large-Scale Image Recognition - Simonyan & Zisserman](https://arxiv.org/abs/1409.1556)",
        "- [Deep Residual Learning for Image Recognition - He et al.](https://arxiv.org/abs/1512.03385)",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3.4 Demonstração Prática: Comparação de Arquiteturas\n",
        "\n",
        "Vamos implementar e comparar diferentes arquiteturas de CNN:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "class AlexNetLike(nn.Module):\n",
        "    \"\"\"Implementação simplificada do AlexNet\"\"\"\n",
        "    \n",
        "    def __init__(self, num_classes=10):\n",
        "        super(AlexNetLike, self).__init__()\n",
        "        \n",
        "        # Camadas convolucionais\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2)\n",
        "        self.conv2 = nn.Conv2d(64, 192, kernel_size=5, padding=2)\n",
        "        self.conv3 = nn.Conv2d(192, 384, kernel_size=3, padding=1)\n",
        "        self.conv4 = nn.Conv2d(384, 256, kernel_size=3, padding=1)\n",
        "        self.conv5 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
        "        \n",
        "        # Pooling\n",
        "        self.pool = nn.MaxPool2d(kernel_size=3, stride=2)\n",
        "        \n",
        "        # Dropout\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        \n",
        "        # Fully connected\n",
        "        self.fc1 = nn.Linear(256 * 6 * 6, 4096)\n",
        "        self.fc2 = nn.Linear(4096, 4096)\n",
        "        self.fc3 = nn.Linear(4096, num_classes)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.pool(torch.relu(self.conv1(x)))\n",
        "        x = self.pool(torch.relu(self.conv2(x)))\n",
        "        x = torch.relu(self.conv3(x))\n",
        "        x = torch.relu(self.conv4(x))\n",
        "        x = self.pool(torch.relu(self.conv5(x)))\n",
        "        \n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.dropout(torch.relu(self.fc1(x)))\n",
        "        x = self.dropout(torch.relu(self.fc2(x)))\n",
        "        x = self.fc3(x)\n",
        "        \n",
        "        return x\n",
        "\n",
        "class VGGLike(nn.Module):\n",
        "    \"\"\"Implementação simplificada do VGG\"\"\"\n",
        "    \n",
        "    def __init__(self, num_classes=10):\n",
        "        super(VGGLike, self).__init__()\n",
        "        \n",
        "        # Camadas convolucionais (VGG-16 simplificado)\n",
        "        self.features = nn.Sequential(\n",
        "            # Bloco 1\n",
        "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            \n",
        "            # Bloco 2\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            \n",
        "            # Bloco 3\n",
        "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "        \n",
        "        # Classificador\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(256 * 4 * 4, 512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(512, num_classes),\n",
        "        )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "class ResNetLike(nn.Module):\n",
        "    \"\"\"Implementação simplificada do ResNet\"\"\"\n",
        "    \n",
        "    def __init__(self, num_classes=10):\n",
        "        super(ResNetLike, self).__init__()\n",
        "        \n",
        "        # Camada inicial\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        \n",
        "        # Blocos residuais\n",
        "        self.layer1 = self._make_layer(64, 64, 2)\n",
        "        self.layer2 = self._make_layer(64, 128, 2, stride=2)\n",
        "        self.layer3 = self._make_layer(128, 256, 2, stride=2)\n",
        "        \n",
        "        # Classificador\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(256, num_classes)\n",
        "        \n",
        "    def _make_layer(self, in_channels, out_channels, blocks, stride=1):\n",
        "        layers = []\n",
        "        \n",
        "        # Primeiro bloco com stride\n",
        "        layers.append(BasicBlock(in_channels, out_channels, stride))\n",
        "        \n",
        "        # Blocos restantes\n",
        "        for _ in range(1, blocks):\n",
        "            layers.append(BasicBlock(out_channels, out_channels))\n",
        "        \n",
        "        return nn.Sequential(*layers)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.maxpool(torch.relu(self.bn1(self.conv1(x))))\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    \"\"\"Bloco básico do ResNet\"\"\"\n",
        "    \n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        \n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        \n",
        "        # Skip connection\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_channels != out_channels:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride),\n",
        "                nn.BatchNorm2d(out_channels)\n",
        "            )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        \n",
        "        out = torch.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        \n",
        "        out += self.shortcut(residual)\n",
        "        out = torch.relu(out)\n",
        "        \n",
        "        return out\n",
        "\n",
        "def compare_architectures():\n",
        "    \"\"\"Compara diferentes arquiteturas de CNN\"\"\"\n",
        "    \n",
        "    # Criar modelos\n",
        "    alexnet = AlexNetLike()\n",
        "    vgg = VGGLike()\n",
        "    resnet = ResNetLike()\n",
        "    \n",
        "    # Calcular parâmetros\n",
        "    alexnet_params = sum(p.numel() for p in alexnet.parameters())\n",
        "    vgg_params = sum(p.numel() for p in vgg.parameters())\n",
        "    resnet_params = sum(p.numel() for p in resnet.parameters())\n",
        "    \n",
        "    # Criar dados de exemplo\n",
        "    input_tensor = torch.randn(1, 3, 224, 224)\n",
        "    \n",
        "    # Testar forward pass\n",
        "    with torch.no_grad():\n",
        "        alexnet.eval()\n",
        "        vgg.eval()\n",
        "        resnet.eval()\n",
        "        \n",
        "        alexnet_output = alexnet(input_tensor)\n",
        "        vgg_output = vgg(input_tensor)\n",
        "        resnet_output = resnet(input_tensor)\n",
        "    \n",
        "    # Visualização\n",
        "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "    \n",
        "    # Informações dos modelos\n",
        "    models_info = [\n",
        "        ('AlexNet', alexnet_params, alexnet_output.shape),\n",
        "        ('VGG', vgg_params, vgg_output.shape),\n",
        "        ('ResNet', resnet_params, resnet_output.shape)\n",
        "    ]\n",
        "    \n",
        "    # Gráfico de parâmetros\n",
        "    model_names = [info[0] for info in models_info]\n",
        "    param_counts = [info[1] for info in models_info]\n",
        "    \n",
        "    axes[0, 0].bar(model_names, param_counts, color=['red', 'green', 'blue'])\n",
        "    axes[0, 0].set_title('Número de Parâmetros')\n",
        "    axes[0, 0].set_ylabel('Parâmetros (milhões)')\n",
        "    axes[0, 0].tick_params(axis='x', rotation=45)\n",
        "    \n",
        "    # Adicionar valores nas barras\n",
        "    for i, v in enumerate(param_counts):\n",
        "        axes[0, 0].text(i, v + max(param_counts) * 0.01, f'{v/1e6:.1f}M', \n",
        "                        ha='center', va='bottom')\n",
        "    \n",
        "    # Comparação de características\n",
        "    characteristics = {\n",
        "        'Profundidade': [8, 16, 18],\n",
        "        'Inovação': [3, 2, 5],  # Escala 1-5\n",
        "        'Simplicidade': [3, 5, 2],  # Escala 1-5\n",
        "        'Performance': [3, 4, 5]  # Escala 1-5\n",
        "    }\n",
        "    \n",
        "    x = np.arange(len(model_names))\n",
        "    width = 0.2\n",
        "    \n",
        "    for i, (char, values) in enumerate(characteristics.items()):\n",
        "        axes[0, 1].bar(x + i*width, values, width, label=char)\n",
        "    \n",
        "    axes[0, 1].set_title('Comparação de Características')\n",
        "    axes[0, 1].set_ylabel('Pontuação')\n",
        "    axes[0, 1].set_xticks(x + width * 1.5)\n",
        "    axes[0, 1].set_xticklabels(model_names)\n",
        "    axes[0, 1].legend()\n",
        "    \n",
        "    # Evolução temporal\n",
        "    years = [2012, 2014, 2015]\n",
        "    accuracy = [15.3, 7.3, 3.6]  # Top-5 error rates\n",
        "    \n",
        "    axes[0, 2].plot(years, accuracy, 'o-', linewidth=2, markersize=8)\n",
        "    axes[0, 2].set_title('Evolução da Performance (ImageNet)')\n",
        "    axes[0, 2].set_xlabel('Ano')\n",
        "    axes[0, 2].set_ylabel('Top-5 Error Rate (%)')\n",
        "    axes[0, 2].grid(True, alpha=0.3)\n",
        "    \n",
        "    # Adicionar labels dos pontos\n",
        "    for i, (year, acc) in enumerate(zip(years, accuracy)):\n",
        "        axes[0, 2].annotate(f'{model_names[i]}\\n{acc}%', \n",
        "                          (year, acc), textcoords=\"offset points\", \n",
        "                          xytext=(0,10), ha='center')\n",
        "    \n",
        "    # Informações detalhadas\n",
        "    info_text = \"\"\"\n",
        "    ALEXNET (2012):\n",
        "    • Primeira CNN vencedora do ImageNet\n",
        "    • ReLU activation\n",
        "    • Dropout regularization\n",
        "    • GPU training\n",
        "    \n",
        "    VGG (2014):\n",
        "    • Arquitetura simples e consistente\n",
        "    • Kernels 3×3 apenas\n",
        "    • Muito profundo\n",
        "    • Excelente para transfer learning\n",
        "    \n",
        "    RESNET (2015):\n",
        "    • Skip connections\n",
        "    • Resolve problema de degradação\n",
        "    • Batch normalization\n",
        "    • Redes muito profundas\n",
        "    \"\"\"\n",
        "    \n",
        "    axes[1, 0].text(0.05, 0.95, info_text, transform=axes[1, 0].transAxes, \n",
        "                    fontsize=10, verticalalignment='top',\n",
        "                    bbox=dict(boxstyle='round', facecolor='lightgray', alpha=0.8))\n",
        "    axes[1, 0].set_title('Características Principais')\n",
        "    axes[1, 0].axis('off')\n",
        "    \n",
        "    # Vantagens e desvantagens\n",
        "    comparison_text = \"\"\"\n",
        "    COMPARAÇÃO:\n",
        "    \n",
        "    ALEXNET:\n",
        "    ✓ Pioneiro, ReLU, Dropout\n",
        "    ✗ Pouco profundo, muitos parâmetros\n",
        "    \n",
        "    VGG:\n",
        "    ✓ Simples, consistente, transfer learning\n",
        "    ✗ Muitos parâmetros, lento\n",
        "    \n",
        "    RESNET:\n",
        "    ✓ Skip connections, eficiente, profundo\n",
        "    ✗ Complexo, difícil de interpretar\n",
        "    \"\"\"\n",
        "    \n",
        "    axes[1, 1].text(0.05, 0.95, comparison_text, transform=axes[1, 1].transAxes, \n",
        "                    fontsize=10, verticalalignment='top',\n",
        "                    bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.8))\n",
        "    axes[1, 1].set_title('Vantagens e Desvantagens')\n",
        "    axes[1, 1].axis('off')\n",
        "    \n",
        "    # Impacto histórico\n",
        "    impact_text = \"\"\"\n",
        "    IMPACTO HISTÓRICO:\n",
        "    \n",
        "    2012 - ALEXNET:\n",
        "    • Início da era deep learning\n",
        "    • Redução de erro de 26% para 16%\n",
        "    • Revolução na visão computacional\n",
        "    \n",
        "    2014 - VGG:\n",
        "    • Padrão de arquitetura\n",
        "    • Base para muitos modelos\n",
        "    • Transfer learning popularizado\n",
        "    \n",
        "    2015 - RESNET:\n",
        "    • Resolve degradação\n",
        "    • Redes de 100+ camadas\n",
        "    • Influência em todas as áreas\n",
        "    \"\"\"\n",
        "    \n",
        "    axes[1, 2].text(0.05, 0.95, impact_text, transform=axes[1, 2].transAxes, \n",
        "                    fontsize=10, verticalalignment='top',\n",
        "                    bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.8))\n",
        "    axes[1, 2].set_title('Impacto Histórico')\n",
        "    axes[1, 2].axis('off')\n",
        "    \n",
        "    plt.suptitle('Comparação de Arquiteturas Clássicas de CNN', fontsize=16)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    return {\n",
        "        'alexnet_params': alexnet_params,\n",
        "        'vgg_params': vgg_params,\n",
        "        'resnet_params': resnet_params,\n",
        "        'models_info': models_info\n",
        "    }\n",
        "\n",
        "# Executar comparação\n",
        "comparison_results = compare_architectures()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Análise da Comparação\n",
        "\n",
        "**Características Observadas:**\n",
        "\n",
        "1. **AlexNet (2012)**:\n",
        "   - **Parâmetros**: ~60M (mais que ResNet)\n",
        "   - **Profundidade**: 8 camadas\n",
        "   - **Inovação**: Pioneiro em ReLU e Dropout\n",
        "   - **Impacto**: Revolução na área\n",
        "\n",
        "2. **VGG (2014)**:\n",
        "   - **Parâmetros**: ~138M (mais que todos)\n",
        "   - **Profundidade**: 16-19 camadas\n",
        "   - **Simplicidade**: Arquitetura consistente\n",
        "   - **Uso**: Excelente para transfer learning\n",
        "\n",
        "3. **ResNet (2015)**:\n",
        "   - **Parâmetros**: ~25M (mais eficiente)\n",
        "   - **Profundidade**: 50-152 camadas\n",
        "   - **Inovação**: Skip connections\n",
        "   - **Performance**: Melhor accuracy\n",
        "\n",
        "**Insights Importantes:**\n",
        "- **Evolução**: Menos parâmetros, mais profundidade\n",
        "- **Eficiência**: ResNet é mais eficiente que VGG\n",
        "- **Inovação**: Cada arquitetura resolve problemas específicos\n",
        "- **Impacto**: Progressão constante da performance\n",
        "\n",
        "**Referências:**\n",
        "- [ImageNet Classification with Deep Convolutional Neural Networks - Krizhevsky et al.](https://papers.nips.cc/paper/2012/hash/c399862d3b9d6b76c8436e924a68c45b-Abstract.html)\n",
        "- [Very Deep Convolutional Networks for Large-Scale Image Recognition - Simonyan & Zisserman](https://arxiv.org/abs/1409.1556)\n",
        "- [Deep Residual Learning for Image Recognition - He et al.](https://arxiv.org/abs/1512.03385)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3.5 Funções de Ativação e Regularização",
        "",
        "### Funções de Ativação",
        "",
        "**ReLU (Rectified Linear Unit):**",
        "- **Fórmula**: f(x) = max(0, x)",
        "- **Vantagens**: Simples, eficiente, resolve vanishing gradient",
        "- **Desvantagens**: Dying ReLU problem",
        "- **Uso**: Padrão em CNNs modernas",
        "",
        "**Leaky ReLU:**",
        "- **Fórmula**: f(x) = max(0.01x, x)",
        "- **Vantagens**: Evita dying ReLU",
        "- **Uso**: Alternativa ao ReLU",
        "",
        "**Sigmoid:**",
        "- **Fórmula**: f(x) = 1 / (1 + e^(-x))",
        "- **Uso**: Classificação binária",
        "- **Problema**: Vanishing gradient",
        "",
        "**Softmax:**",
        "- **Fórmula**: f(x_i) = e^(x_i) / Σ e^(x_j)",
        "- **Uso**: Classificação multiclasse",
        "- **Output**: Probabilidades normalizadas",
        "",
        "![Funções de Ativação](https://raw.githubusercontent.com/rfapo/visao-computacional/main/images/modulo3/funcoes_ativacao.png)",
        "",
        "### Técnicas de Regularização",
        "",
        "**Dropout:**",
        "- **Funcionamento**: Desativa neurônios aleatoriamente",
        "- **Taxa**: 0.5 comum para fully connected",
        "- **Efeito**: Previne overfitting",
        "- **Uso**: Durante treinamento apenas",
        "",
        "**Batch Normalization:**",
        "- **Funcionamento**: Normaliza inputs por lote",
        "- **Efeito**: Acelera treinamento, estabiliza",
        "- **Uso**: Após camadas convolucionais",
        "- **Vantagem**: Permite learning rates maiores",
        "",
        "**Data Augmentation:**",
        "- **Técnicas**: Rotação, espelhamento, crop, color jitter",
        "- **Efeito**: Aumenta diversidade do dataset",
        "- **Uso**: Durante treinamento",
        "- **Vantagem**: Melhora generalização",
        "",
        "![Técnicas de Regularização](https://raw.githubusercontent.com/rfapo/visao-computacional/main/images/modulo3/tecnicas_regularizacao.png)",
        "",
        "**Referências:**",
        "- [Deep Learning - Goodfellow, Bengio & Courville](https://www.deeplearningbook.org/)",
        "- [Batch Normalization: Accelerating Deep Network Training - Ioffe & Szegedy](https://arxiv.org/abs/1502.03167)",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Resumo do Módulo 3\n",
        "\n",
        "### Principais Conceitos Abordados\n",
        "\n",
        "1. **Redes Neurais Convolucionais (CNNs)**\n",
        "   - Arquitetura básica e componentes\n",
        "   - Camadas convolucionais, pooling e fully connected\n",
        "   - Matemática da convolução\n",
        "   - Processamento hierárquico de features\n",
        "\n",
        "2. **Arquiteturas Clássicas**\n",
        "   - AlexNet: Pioneiro e revolucionário\n",
        "   - VGG: Simplicidade e profundidade\n",
        "   - ResNet: Skip connections e eficiência\n",
        "   - Evolução e comparação\n",
        "\n",
        "3. **Funções de Ativação e Regularização**\n",
        "   - ReLU, Leaky ReLU, Sigmoid, Softmax\n",
        "   - Dropout, Batch Normalization, Data Augmentation\n",
        "   - Técnicas para prevenir overfitting\n",
        "\n",
        "### Demonstrações Práticas\n",
        "\n",
        "**1. Visualização de CNNs:**\n",
        "   - Processamento de imagem através de camadas\n",
        "   - Feature maps em diferentes níveis\n",
        "   - Análise de dimensionalidade\n",
        "\n",
        "**2. Comparação de Arquiteturas:**\n",
        "   - Implementação de AlexNet, VGG e ResNet\n",
        "   - Análise de parâmetros e eficiência\n",
        "   - Comparação de características\n",
        "\n",
        "### Próximos Passos\n",
        "\n",
        "No próximo módulo, exploraremos **Transfer Learning**, onde aprenderemos a usar modelos pré-treinados para resolver problemas específicos.\n",
        "\n",
        "### Referências Principais\n",
        "\n",
        "- [Deep Learning - Goodfellow, Bengio & Courville](https://www.deeplearningbook.org/)\n",
        "- [ImageNet Classification with Deep Convolutional Neural Networks - Krizhevsky et al.](https://papers.nips.cc/paper/2012/hash/c399862d3b9d6b76c8436e924a68c45b-Abstract.html)\n",
        "- [Deep Residual Learning for Image Recognition - He et al.](https://arxiv.org/abs/1512.03385)\n",
        "\n",
        "---\n",
        "\n",
        "**Próximo Módulo**: Transfer Learning e Aplicações Práticas\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}