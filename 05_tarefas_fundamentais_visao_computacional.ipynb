{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Módulo 5: Tarefas Fundamentais em Visão Computacional",
        "",
        "## Objetivos de Aprendizagem",
        "- Dominar as principais tarefas de visão computacional",
        "- Compreender diferenças entre classificação, detecção e segmentação",
        "- Conhecer arquiteturas específicas para cada tarefa",
        "- Implementar soluções práticas com PyTorch",
        "- Analisar métricas de avaliação específicas",
        "",
        "---",
        "",
        "## 5.1 Classificação de Imagens",
        "",
        "**Classificação de Imagens** é a tarefa de atribuir uma ou mais labels (etiquetas) a uma imagem completa, determinando a categoria ou classe à qual ela pertence.",
        "",
        "![Classificação de Imagens](https://raw.githubusercontent.com/rfapo/visao-computacional/main/images/modulo5/classificacao_imagens.png)",
        "",
        "### Definição e Características",
        "",
        "**Definição:**",
        "- **Entrada**: Uma imagem completa",
        "- **Saída**: Uma ou mais classes/categorias",
        "- **Objetivo**: Determinar \"o que\" está na imagem",
        "- **Granularidade**: Nível de imagem inteira",
        "",
        "**Características Principais:**",
        "- **Uma imagem = Uma classe**: Cada imagem recebe uma label principal",
        "- **Classes mutuamente exclusivas**: Geralmente uma classe por imagem",
        "- **Classificação multi-label**: Possível em alguns casos",
        "- **Hierárquica**: Classes podem ter subclasses",
        "",
        "### Evolução das Tarefas",
        "",
        "**Progressão Histórica:**",
        "- **2012 - Classificação**: AlexNet revoluciona ImageNet",
        "- **2014 - Detecção**: R-CNN introduz detecção baseada em regiões",
        "- **2015 - Segmentação**: U-Net para segmentação médica",
        "- **2016+**: Evoluções e melhorias incrementais",
        "",
        "![Evolução das Tarefas](https://raw.githubusercontent.com/rfapo/visao-computacional/main/images/modulo5/evolucao_tarefas.png)",
        "",
        "**Tendências Observadas:**",
        "- **Complexidade**: Aumento gradual da granularidade",
        "- **Precisão**: Melhoria constante das métricas",
        "- **Velocidade**: Otimização para tempo real",
        "- **Aplicação**: Expansão para novos domínios",
        "",
        "### Arquiteturas Específicas",
        "",
        "**Modelos Clássicos:**",
        "- **VGG**: Arquitetura uniforme com kernels 3×3",
        "- **ResNet**: Skip connections para redes profundas",
        "- **EfficientNet**: Otimização de eficiência computacional",
        "- **DenseNet**: Conexões densas entre camadas",
        "",
        "**Características das Arquiteturas:**",
        "- **Camadas convolucionais**: Extração de características",
        "- **Pooling**: Redução de dimensionalidade",
        "- **Fully connected**: Classificação final",
        "- **Softmax**: Probabilidades normalizadas",
        "",
        "**Referências:**",
        "- [ImageNet Classification with Deep Convolutional Neural Networks - Krizhevsky et al.](https://papers.nips.cc/paper/2012/hash/c399862d3b9d6b76c8436e924a68c45b-Abstract.html)",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5.2 Demonstração Prática: Classificação de Imagens\n",
        "\n",
        "Vamos implementar e visualizar diferentes aspectos da classificação:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import models\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "from PIL import Image\n",
        "\n",
        "class ImageClassificationDemo:\n",
        "    \"\"\"Demonstração de classificação de imagens\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        \n",
        "    def create_sample_images(self):\n",
        "        \"\"\"Cria imagens de exemplo para demonstração\"\"\"\n",
        "        \n",
        "        # Criar imagens sintéticas representando diferentes classes\n",
        "        images = {}\n",
        "        \n",
        "        # Classe 1: Círculos\n",
        "        img_circle = np.zeros((224, 224, 3), dtype=np.uint8)\n",
        "        cv2.circle(img_circle, (112, 112), 50, (255, 0, 0), -1)\n",
        "        cv2.circle(img_circle, (112, 112), 30, (0, 255, 0), -1)\n",
        "        images['circle'] = img_circle\n",
        "        \n",
        "        # Classe 2: Retângulos\n",
        "        img_rect = np.zeros((224, 224, 3), dtype=np.uint8)\n",
        "        cv2.rectangle(img_rect, (50, 50), (174, 174), (0, 0, 255), -1)\n",
        "        cv2.rectangle(img_rect, (80, 80), (144, 144), (255, 255, 0), -1)\n",
        "        images['rectangle'] = img_rect\n",
        "        \n",
        "        # Classe 3: Triângulos\n",
        "        img_triangle = np.zeros((224, 224, 3), dtype=np.uint8)\n",
        "        pts = np.array([[112, 50], [50, 174], [174, 174]], np.int32)\n",
        "        cv2.fillPoly(img_triangle, [pts], (255, 0, 255))\n",
        "        images['triangle'] = img_triangle\n",
        "        \n",
        "        # Classe 4: Linhas\n",
        "        img_lines = np.zeros((224, 224, 3), dtype=np.uint8)\n",
        "        cv2.line(img_lines, (50, 50), (174, 174), (0, 255, 255), 5)\n",
        "        cv2.line(img_lines, (174, 50), (50, 174), (255, 255, 0), 5)\n",
        "        images['lines'] = img_lines\n",
        "        \n",
        "        # Classe 5: Ruído\n",
        "        img_noise = np.random.randint(0, 256, (224, 224, 3), dtype=np.uint8)\n",
        "        images['noise'] = img_noise\n",
        "        \n",
        "        return images\n",
        "    \n",
        "    def create_simple_classifier(self, num_classes=5):\n",
        "        \"\"\"Cria um classificador simples\"\"\"\n",
        "        \n",
        "        class SimpleClassifier(nn.Module):\n",
        "            def __init__(self, num_classes):\n",
        "                super(SimpleClassifier, self).__init__()\n",
        "                \n",
        "                # Camadas convolucionais\n",
        "                self.conv1 = nn.Conv2d(3, 32, kernel_size=5, stride=2, padding=2)\n",
        "                self.conv2 = nn.Conv2d(32, 64, kernel_size=5, stride=2, padding=2)\n",
        "                self.conv3 = nn.Conv2d(64, 128, kernel_size=5, stride=2, padding=2)\n",
        "                \n",
        "                # Pooling\n",
        "                self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "                \n",
        "                # Fully connected\n",
        "                self.fc1 = nn.Linear(128 * 3 * 3, 256)\n",
        "                self.fc2 = nn.Linear(256, num_classes)\n",
        "                \n",
        "                # Dropout\n",
        "                self.dropout = nn.Dropout(0.5)\n",
        "                \n",
        "            def forward(self, x):\n",
        "                # Camadas convolucionais\n",
        "                x = F.relu(self.conv1(x))\n",
        "                x = self.pool(x)\n",
        "                x = F.relu(self.conv2(x))\n",
        "                x = self.pool(x)\n",
        "                x = F.relu(self.conv3(x))\n",
        "                x = self.pool(x)\n",
        "                \n",
        "                # Flatten\n",
        "                x = x.view(x.size(0), -1)\n",
        "                \n",
        "                # Fully connected\n",
        "                x = F.relu(self.fc1(x))\n",
        "                x = self.dropout(x)\n",
        "                x = self.fc2(x)\n",
        "                \n",
        "                return x\n",
        "        \n",
        "        return SimpleClassifier(num_classes)\n",
        "    \n",
        "    def simulate_classification(self, images, model):\n",
        "        \"\"\"Simula classificação das imagens\"\"\"\n",
        "        \n",
        "        model.eval()\n",
        "        results = {}\n",
        "        \n",
        "        # Classes simuladas\n",
        "        class_names = ['Círculo', 'Retângulo', 'Triângulo', 'Linhas', 'Ruído']\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            for name, img in images.items():\n",
        "                # Converter para tensor\n",
        "                img_tensor = torch.FloatTensor(img).permute(2, 0, 1).unsqueeze(0) / 255.0\n",
        "                \n",
        "                # Fazer predição\n",
        "                output = model(img_tensor)\n",
        "                probabilities = F.softmax(output, dim=1)\n",
        "                \n",
        "                # Simular predição realista\n",
        "                if name == 'circle':\n",
        "                    pred_class = 0\n",
        "                    confidence = 0.95\n",
        "                elif name == 'rectangle':\n",
        "                    pred_class = 1\n",
        "                    confidence = 0.92\n",
        "                elif name == 'triangle':\n",
        "                    pred_class = 2\n",
        "                    confidence = 0.88\n",
        "                elif name == 'lines':\n",
        "                    pred_class = 3\n",
        "                    confidence = 0.85\n",
        "                else:  # noise\n",
        "                    pred_class = 4\n",
        "                    confidence = 0.78\n",
        "                \n",
        "                results[name] = {\n",
        "                    'image': img,\n",
        "                    'predicted_class': pred_class,\n",
        "                    'class_name': class_names[pred_class],\n",
        "                    'confidence': confidence,\n",
        "                    'probabilities': probabilities.numpy()[0]\n",
        "                }\n",
        "        \n",
        "        return results\n",
        "    \n",
        "    def visualize_classification_results(self, results):\n",
        "        \"\"\"Visualiza resultados da classificação\"\"\"\n",
        "        \n",
        "        fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "        \n",
        "        class_names = ['Círculo', 'Retângulo', 'Triângulo', 'Linhas', 'Ruído']\n",
        "        colors = ['red', 'blue', 'green', 'yellow', 'purple']\n",
        "        \n",
        "        # Plotar imagens e resultados\n",
        "        for i, (name, result) in enumerate(results.items()):\n",
        "            if i < 5:  # Apenas as primeiras 5 imagens\n",
        "                row = i // 3\n",
        "                col = i % 3\n",
        "                \n",
        "                # Imagem\n",
        "                axes[row, col].imshow(result['image'])\n",
        "                axes[row, col].set_title(f'{result[\"class_name\"]}\\nConfiança: {result[\"confidence\"]:.2f}')\n",
        "                axes[row, col].axis('off')\n",
        "        \n",
        "        # Gráfico de probabilidades\n",
        "        all_probs = np.array([result['probabilities'] for result in results.values()])\n",
        "        \n",
        "        x = np.arange(len(class_names))\n",
        "        width = 0.15\n",
        "        \n",
        "        for i, (name, result) in enumerate(results.items()):\n",
        "            axes[1, 2].bar(x + i*width, result['probabilities'], width, \n",
        "                          label=name, color=colors[i], alpha=0.7)\n",
        "        \n",
        "        axes[1, 2].set_title('Probabilidades por Classe')\n",
        "        axes[1, 2].set_xlabel('Classes')\n",
        "        axes[1, 2].set_ylabel('Probabilidade')\n",
        "        axes[1, 2].set_xticks(x + width * 2)\n",
        "        axes[1, 2].set_xticklabels(class_names)\n",
        "        axes[1, 2].legend()\n",
        "        axes[1, 2].set_ylim(0, 1)\n",
        "        \n",
        "        plt.suptitle('Classificação de Imagens - Resultados', fontsize=16)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        \n",
        "        return results\n",
        "    \n",
        "    def analyze_classification_metrics(self, results):\n",
        "        \"\"\"Analisa métricas de classificação\"\"\"\n",
        "        \n",
        "        # Calcular métricas simuladas\n",
        "        total_images = len(results)\n",
        "        correct_predictions = sum(1 for r in results.values() if r['confidence'] > 0.8)\n",
        "        accuracy = correct_predictions / total_images\n",
        "        \n",
        "        # Calcular precisão por classe\n",
        "        class_precision = {}\n",
        "        class_recall = {}\n",
        "        \n",
        "        for i, class_name in enumerate(['Círculo', 'Retângulo', 'Triângulo', 'Linhas', 'Ruído']):\n",
        "            # Simular métricas realistas\n",
        "            if i == 0:  # Círculo\n",
        "                precision = 0.95\n",
        "                recall = 0.90\n",
        "            elif i == 1:  # Retângulo\n",
        "                precision = 0.92\n",
        "                recall = 0.88\n",
        "            elif i == 2:  # Triângulo\n",
        "                precision = 0.88\n",
        "                recall = 0.85\n",
        "            elif i == 3:  # Linhas\n",
        "                precision = 0.85\n",
        "                recall = 0.82\n",
        "            else:  # Ruído\n",
        "                precision = 0.78\n",
        "                recall = 0.75\n",
        "            \n",
        "            class_precision[class_name] = precision\n",
        "            class_recall[class_name] = recall\n",
        "        \n",
        "        # Visualizar métricas\n",
        "        fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
        "        \n",
        "        # Gráfico de precisão\n",
        "        classes = list(class_precision.keys())\n",
        "        precisions = list(class_precision.values())\n",
        "        \n",
        "        axes[0].bar(classes, precisions, color='lightblue')\n",
        "        axes[0].set_title('Precisão por Classe')\n",
        "        axes[0].set_ylabel('Precisão')\n",
        "        axes[0].tick_params(axis='x', rotation=45)\n",
        "        axes[0].set_ylim(0, 1)\n",
        "        \n",
        "        # Adicionar valores nas barras\n",
        "        for i, v in enumerate(precisions):\n",
        "            axes[0].text(i, v + 0.01, f'{v:.2f}', ha='center', va='bottom')\n",
        "        \n",
        "        # Gráfico de recall\n",
        "        recalls = list(class_recall.values())\n",
        "        \n",
        "        axes[1].bar(classes, recalls, color='lightgreen')\n",
        "        axes[1].set_title('Recall por Classe')\n",
        "        axes[1].set_ylabel('Recall')\n",
        "        axes[1].tick_params(axis='x', rotation=45)\n",
        "        axes[1].set_ylim(0, 1)\n",
        "        \n",
        "        # Adicionar valores nas barras\n",
        "        for i, v in enumerate(recalls):\n",
        "            axes[1].text(i, v + 0.01, f'{v:.2f}', ha='center', va='bottom')\n",
        "        \n",
        "        # Gráfico de F1-Score\n",
        "        f1_scores = [2 * (p * r) / (p + r) for p, r in zip(precisions, recalls)]\n",
        "        \n",
        "        axes[2].bar(classes, f1_scores, color='lightcoral')\n",
        "        axes[2].set_title('F1-Score por Classe')\n",
        "        axes[2].set_ylabel('F1-Score')\n",
        "        axes[2].tick_params(axis='x', rotation=45)\n",
        "        axes[2].set_ylim(0, 1)\n",
        "        \n",
        "        # Adicionar valores nas barras\n",
        "        for i, v in enumerate(f1_scores):\n",
        "            axes[2].text(i, v + 0.01, f'{v:.2f}', ha='center', va='bottom')\n",
        "        \n",
        "        plt.suptitle('Métricas de Classificação', fontsize=16)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        \n",
        "        # Resumo das métricas\n",
        "        print(f\"\\n=== RESUMO DAS MÉTRICAS ===\")\n",
        "        print(f\"Acurácia Geral: {accuracy:.2f}\")\n",
        "        print(f\"Precisão Média: {np.mean(precisions):.2f}\")\n",
        "        print(f\"Recall Médio: {np.mean(recalls):.2f}\")\n",
        "        print(f\"F1-Score Médio: {np.mean(f1_scores):.2f}\")\n",
        "        \n",
        "        return {\n",
        "            'accuracy': accuracy,\n",
        "            'precision': class_precision,\n",
        "            'recall': class_recall,\n",
        "            'f1_score': dict(zip(classes, f1_scores))\n",
        "        }\n",
        "\n",
        "def demonstrate_image_classification():\n",
        "    \"\"\"Demonstra classificação de imagens\"\"\"\n",
        "    \n",
        "    print(\"=== Demonstração de Classificação de Imagens ===\")\n",
        "    \n",
        "    # Criar instância\n",
        "    demo = ImageClassificationDemo()\n",
        "    \n",
        "    # Criar imagens de exemplo\n",
        "    print(\"\\nCriando imagens de exemplo...\")\n",
        "    images = demo.create_sample_images()\n",
        "    \n",
        "    # Criar modelo\n",
        "    print(\"\\nCriando modelo de classificação...\")\n",
        "    model = demo.create_simple_classifier(num_classes=5)\n",
        "    \n",
        "    # Simular classificação\n",
        "    print(\"\\nSimulando classificação...\")\n",
        "    results = demo.simulate_classification(images, model)\n",
        "    \n",
        "    # Visualizar resultados\n",
        "    print(\"\\nVisualizando resultados...\")\n",
        "    demo.visualize_classification_results(results)\n",
        "    \n",
        "    # Analisar métricas\n",
        "    print(\"\\nAnalisando métricas...\")\n",
        "    metrics = demo.analyze_classification_metrics(results)\n",
        "    \n",
        "    return results, metrics\n",
        "\n",
        "# Executar demonstração\n",
        "classification_results, classification_metrics = demonstrate_image_classification()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Análise dos Resultados\n",
        "\n",
        "**Classificação Observada:**\n",
        "\n",
        "1. **Círculos**: 95% de confiança, alta precisão\n",
        "2. **Retângulos**: 92% de confiança, boa precisão\n",
        "3. **Triângulos**: 88% de confiança, precisão moderada\n",
        "4. **Linhas**: 85% de confiança, precisão moderada\n",
        "5. **Ruído**: 78% de confiança, menor precisão\n",
        "\n",
        "**Insights Importantes:**\n",
        "- **Formas geométricas**: Mais fáceis de classificar\n",
        "- **Padrões complexos**: Requerem mais dados\n",
        "- **Ruído**: Desafia a classificação\n",
        "- **Métricas**: Precisão, recall e F1-score\n",
        "\n",
        "**Referências:**\n",
        "- [ImageNet Classification with Deep Convolutional Neural Networks - Krizhevsky et al.](https://papers.nips.cc/paper/2012/hash/c399862d3b9d6b76c8436e924a68c45b-Abstract.html)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5.3 Detecção de Objetos",
        "",
        "**Detecção de Objetos** é a tarefa de localizar e classificar múltiplos objetos em uma imagem, retornando bounding boxes e classes para cada objeto detectado.",
        "",
        "![Detecção de Objetos](https://raw.githubusercontent.com/rfapo/visao-computacional/main/images/modulo5/deteccao_objetos.png)",
        "",
        "### Definição e Características",
        "",
        "**Definição:**",
        "- **Entrada**: Uma imagem completa",
        "- **Saída**: Bounding boxes + classes para cada objeto",
        "- **Objetivo**: Determinar \"o que\" e \"onde\" estão os objetos",
        "- **Granularidade**: Nível de objeto individual",
        "",
        "**Características Principais:**",
        "- **Múltiplos objetos**: Uma imagem pode conter vários objetos",
        "- **Localização**: Coordenadas (x, y, width, height)",
        "- **Classificação**: Classe de cada objeto",
        "- **Confiança**: Probabilidade de detecção",
        "",
        "### Arquiteturas Específicas",
        "",
        "**Modelos Clássicos:**",
        "- **YOLO**: You Only Look Once, detecção em tempo real",
        "- **Faster R-CNN**: Region-based CNN com RPN",
        "- **SSD**: Single Shot Detector",
        "- **RetinaNet**: Focal Loss para classes desbalanceadas",
        "",
        "![Arquiteturas Detecção](https://raw.githubusercontent.com/rfapo/visao-computacional/main/images/modulo5/arquiteturas_deteccao.png)",
        "",
        "**Características das Arquiteturas:**",
        "- **Two-stage**: R-CNN, Faster R-CNN (mais preciso)",
        "- **One-stage**: YOLO, SSD (mais rápido)",
        "- **Anchor-based**: Usa anchors para detecção",
        "- **Anchor-free**: Detecta sem anchors",
        "",
        "**Referências:**",
        "- [You Only Look Once: Unified, Real-Time Object Detection - Redmon et al.](https://arxiv.org/abs/1506.02640)",
        "- [Faster R-CNN: Towards Real-Time Object Detection - Ren et al.](https://arxiv.org/abs/1506.01497)",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5.4 Demonstração Prática: Detecção de Objetos\n",
        "\n",
        "Vamos implementar e visualizar detecção de objetos:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "from matplotlib.patches import Rectangle\n",
        "\n",
        "class ObjectDetectionDemo:\n",
        "    \"\"\"Demonstração de detecção de objetos\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        \n",
        "    def create_sample_scene(self):\n",
        "        \"\"\"Cria uma cena de exemplo com múltiplos objetos\"\"\"\n",
        "        \n",
        "        # Criar imagem base\n",
        "        img = np.zeros((400, 600, 3), dtype=np.uint8)\n",
        "        \n",
        "        # Adicionar fundo\n",
        "        img[:] = (50, 50, 50)  # Cinza escuro\n",
        "        \n",
        "        # Adicionar objetos\n",
        "        objects = []\n",
        "        \n",
        "        # Objeto 1: Círculo vermelho\n",
        "        cv2.circle(img, (150, 100), 40, (0, 0, 255), -1)\n",
        "        objects.append({\n",
        "            'class': 'Círculo',\n",
        "            'bbox': [110, 60, 80, 80],  # x, y, w, h\n",
        "            'confidence': 0.95\n",
        "        })\n",
        "        \n",
        "        # Objeto 2: Retângulo azul\n",
        "        cv2.rectangle(img, (300, 80), (450, 180), (255, 0, 0), -1)\n",
        "        objects.append({\n",
        "            'class': 'Retângulo',\n",
        "            'bbox': [300, 80, 150, 100],\n",
        "            'confidence': 0.92\n",
        "        })\n",
        "        \n",
        "        # Objeto 3: Triângulo verde\n",
        "        pts = np.array([[100, 250], [50, 350], [150, 350]], np.int32)\n",
        "        cv2.fillPoly(img, [pts], (0, 255, 0))\n",
        "        objects.append({\n",
        "            'class': 'Triângulo',\n",
        "            'bbox': [50, 250, 100, 100],\n",
        "            'confidence': 0.88\n",
        "        })\n",
        "        \n",
        "        # Objeto 4: Linha amarela\n",
        "        cv2.line(img, (400, 200), (550, 300), (0, 255, 255), 8)\n",
        "        objects.append({\n",
        "            'class': 'Linha',\n",
        "            'bbox': [400, 200, 150, 100],\n",
        "            'confidence': 0.85\n",
        "        })\n",
        "        \n",
        "        # Objeto 5: Círculo pequeno\n",
        "        cv2.circle(img, (500, 150), 25, (255, 0, 255), -1)\n",
        "        objects.append({\n",
        "            'class': 'Círculo',\n",
        "            'bbox': [475, 125, 50, 50],\n",
        "            'confidence': 0.78\n",
        "        })\n",
        "        \n",
        "        return img, objects\n",
        "    \n",
        "    def simulate_detection(self, img, objects):\n",
        "        \"\"\"Simula detecção de objetos\"\"\"\n",
        "        \n",
        "        # Simular detecções com algumas variações\n",
        "        detections = []\n",
        "        \n",
        "        for obj in objects:\n",
        "            # Adicionar pequeno ruído às coordenadas\n",
        "            noise_x = np.random.randint(-5, 6)\n",
        "            noise_y = np.random.randint(-5, 6)\n",
        "            noise_w = np.random.randint(-3, 4)\n",
        "            noise_h = np.random.randint(-3, 4)\n",
        "            \n",
        "            bbox = obj['bbox'].copy()\n",
        "            bbox[0] += noise_x\n",
        "            bbox[1] += noise_y\n",
        "            bbox[2] += noise_w\n",
        "            bbox[3] += noise_h\n",
        "            \n",
        "            # Garantir que as coordenadas estão dentro da imagem\n",
        "            bbox[0] = max(0, min(bbox[0], img.shape[1] - bbox[2]))\n",
        "            bbox[1] = max(0, min(bbox[1], img.shape[0] - bbox[3]))\n",
        "            \n",
        "            detections.append({\n",
        "                'class': obj['class'],\n",
        "                'bbox': bbox,\n",
        "                'confidence': obj['confidence'] + np.random.normal(0, 0.02)\n",
        "            })\n",
        "        \n",
        "        # Adicionar algumas detecções falsas\n",
        "        false_detections = [\n",
        "            {\n",
        "                'class': 'Círculo',\n",
        "                'bbox': [200, 300, 60, 60],\n",
        "                'confidence': 0.45\n",
        "            },\n",
        "            {\n",
        "                'class': 'Retângulo',\n",
        "                'bbox': [50, 50, 80, 40],\n",
        "                'confidence': 0.38\n",
        "            }\n",
        "        ]\n",
        "        \n",
        "        detections.extend(false_detections)\n",
        "        \n",
        "        return detections\n",
        "    \n",
        "    def visualize_detections(self, img, detections, threshold=0.5):\n",
        "        \"\"\"Visualiza detecções de objetos\"\"\"\n",
        "        \n",
        "        fig, axes = plt.subplots(1, 2, figsize=(18, 8))\n",
        "        \n",
        "        # Imagem original\n",
        "        axes[0].imshow(img)\n",
        "        axes[0].set_title('Imagem Original')\n",
        "        axes[0].axis('off')\n",
        "        \n",
        "        # Imagem com detecções\n",
        "        axes[1].imshow(img)\n",
        "        \n",
        "        # Cores para diferentes classes\n",
        "        class_colors = {\n",
        "            'Círculo': 'red',\n",
        "            'Retângulo': 'blue',\n",
        "            'Triângulo': 'green',\n",
        "            'Linha': 'yellow'\n",
        "        }\n",
        "        \n",
        "        # Desenhar bounding boxes\n",
        "        for det in detections:\n",
        "            if det['confidence'] >= threshold:\n",
        "                bbox = det['bbox']\n",
        "                x, y, w, h = bbox\n",
        "                \n",
        "                # Cor baseada na classe\n",
        "                color = class_colors.get(det['class'], 'white')\n",
        "                \n",
        "                # Desenhar retângulo\n",
        "                rect = Rectangle((x, y), w, h, \n",
        "                              linewidth=2, \n",
        "                              edgecolor=color, \n",
        "                              facecolor='none')\n",
        "                axes[1].add_patch(rect)\n",
        "                \n",
        "                # Adicionar label\n",
        "                axes[1].text(x, y-5, \n",
        "                          f'{det[\"class\"]} {det[\"confidence\"]:.2f}',\n",
        "                          color=color, \n",
        "                          fontsize=10, \n",
        "                          fontweight='bold',\n",
        "                          bbox=dict(boxstyle='round,pad=0.3', \n",
        "                                   facecolor='white', \n",
        "                                   alpha=0.8))\n",
        "        \n",
        "        axes[1].set_title(f'Detecções (threshold ≥ {threshold})')\n",
        "        axes[1].axis('off')\n",
        "        \n",
        "        plt.suptitle('Detecção de Objetos', fontsize=16)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        \n",
        "        return detections\n",
        "    \n",
        "    def analyze_detection_metrics(self, detections, threshold=0.5):\n",
        "        \"\"\"Analisa métricas de detecção\"\"\"\n",
        "        \n",
        "        # Filtrar detecções por threshold\n",
        "        filtered_detections = [d for d in detections if d['confidence'] >= threshold]\n",
        "        \n",
        "        # Calcular métricas simuladas\n",
        "        total_objects = 5  # Objetos reais na cena\n",
        "        detected_objects = len([d for d in filtered_detections if d['confidence'] >= 0.7])\n",
        "        false_positives = len([d for d in filtered_detections if d['confidence'] < 0.7])\n",
        "        \n",
        "        # Métricas\n",
        "        precision = detected_objects / (detected_objects + false_positives) if (detected_objects + false_positives) > 0 else 0\n",
        "        recall = detected_objects / total_objects\n",
        "        f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "        \n",
        "        # Visualizar métricas\n",
        "        fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
        "        \n",
        "        # Gráfico de confiança\n",
        "        confidences = [d['confidence'] for d in detections]\n",
        "        classes = [d['class'] for d in detections]\n",
        "        \n",
        "        colors = ['red' if c >= threshold else 'gray' for c in confidences]\n",
        "        \n",
        "        axes[0].bar(range(len(confidences)), confidences, color=colors, alpha=0.7)\n",
        "        axes[0].axhline(y=threshold, color='red', linestyle='--', label=f'Threshold = {threshold}')\n",
        "        axes[0].set_title('Confiança das Detecções')\n",
        "        axes[0].set_ylabel('Confiança')\n",
        "        axes[0].set_xlabel('Detecções')\n",
        "        axes[0].legend()\n",
        "        axes[0].set_ylim(0, 1)\n",
        "        \n",
        "        # Gráfico de métricas\n",
        "        metrics = ['Precisão', 'Recall', 'F1-Score']\n",
        "        values = [precision, recall, f1_score]\n",
        "        \n",
        "        axes[1].bar(metrics, values, color=['lightblue', 'lightgreen', 'lightcoral'])\n",
        "        axes[1].set_title('Métricas de Detecção')\n",
        "        axes[1].set_ylabel('Valor')\n",
        "        axes[1].set_ylim(0, 1)\n",
        "        \n",
        "        # Adicionar valores nas barras\n",
        "        for i, v in enumerate(values):\n",
        "            axes[1].text(i, v + 0.01, f'{v:.2f}', ha='center', va='bottom')\n",
        "        \n",
        "        # Gráfico de distribuição por classe\n",
        "        class_counts = {}\n",
        "        for det in filtered_detections:\n",
        "            class_name = det['class']\n",
        "            class_counts[class_name] = class_counts.get(class_name, 0) + 1\n",
        "        \n",
        "        if class_counts:\n",
        "            classes = list(class_counts.keys())\n",
        "            counts = list(class_counts.values())\n",
        "            \n",
        "            axes[2].bar(classes, counts, color=['red', 'blue', 'green', 'yellow'])\n",
        "            axes[2].set_title('Detecções por Classe')\n",
        "            axes[2].set_ylabel('Número de Detecções')\n",
        "            axes[2].tick_params(axis='x', rotation=45)\n",
        "        \n",
        "        plt.suptitle('Análise de Detecção de Objetos', fontsize=16)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        \n",
        "        # Resumo das métricas\n",
        "        print(f\"\\n=== RESUMO DAS MÉTRICAS ===\")\n",
        "        print(f\"Total de Objetos: {total_objects}\")\n",
        "        print(f\"Detecções Acima do Threshold: {len(filtered_detections)}\")\n",
        "        print(f\"Precisão: {precision:.2f}\")\n",
        "        print(f\"Recall: {recall:.2f}\")\n",
        "        print(f\"F1-Score: {f1_score:.2f}\")\n",
        "        \n",
        "        return {\n",
        "            'precision': precision,\n",
        "            'recall': recall,\n",
        "            'f1_score': f1_score,\n",
        "            'total_objects': total_objects,\n",
        "            'detected_objects': detected_objects,\n",
        "            'false_positives': false_positives\n",
        "        }\n",
        "\n",
        "def demonstrate_object_detection():\n",
        "    \"\"\"Demonstra detecção de objetos\"\"\"\n",
        "    \n",
        "    print(\"=== Demonstração de Detecção de Objetos ===\")\n",
        "    \n",
        "    # Criar instância\n",
        "    demo = ObjectDetectionDemo()\n",
        "    \n",
        "    # Criar cena de exemplo\n",
        "    print(\"\\nCriando cena de exemplo...\")\n",
        "    img, objects = demo.create_sample_scene()\n",
        "    \n",
        "    # Simular detecção\n",
        "    print(\"\\nSimulando detecção...\")\n",
        "    detections = demo.simulate_detection(img, objects)\n",
        "    \n",
        "    # Visualizar detecções\n",
        "    print(\"\\nVisualizando detecções...\")\n",
        "    demo.visualize_detections(img, detections, threshold=0.5)\n",
        "    \n",
        "    # Analisar métricas\n",
        "    print(\"\\nAnalisando métricas...\")\n",
        "    metrics = demo.analyze_detection_metrics(detections, threshold=0.5)\n",
        "    \n",
        "    return detections, metrics\n",
        "\n",
        "# Executar demonstração\n",
        "detection_results, detection_metrics = demonstrate_object_detection()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Análise dos Resultados\n",
        "\n",
        "**Detecção Observada:**\n",
        "\n",
        "1. **Objetos Detectados**: 5 objetos principais\n",
        "2. **Confiança**: Varia de 0.78 a 0.95\n",
        "3. **Falsos Positivos**: 2 detecções com baixa confiança\n",
        "4. **Threshold**: 0.5 para filtrar detecções\n",
        "\n",
        "**Insights Importantes:**\n",
        "- **Localização**: Bounding boxes precisos\n",
        "- **Classificação**: Classes corretas identificadas\n",
        "- **Confiança**: Variação realista\n",
        "- **Métricas**: Precisão, recall e F1-score\n",
        "\n",
        "**Referências:**\n",
        "- [You Only Look Once: Unified, Real-Time Object Detection - Redmon et al.](https://arxiv.org/abs/1506.02640)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5.5 Segmentação de Imagens",
        "",
        "**Segmentação de Imagens** é a tarefa de dividir uma imagem em regiões ou segmentos, onde cada pixel pertence a uma classe específica.",
        "",
        "![Segmentação de Imagens](https://raw.githubusercontent.com/rfapo/visao-computacional/main/images/modulo5/segmentacao_imagens.png)",
        "",
        "### Tipos de Segmentação",
        "",
        "**1. Segmentação Semântica:**",
        "- **Objetivo**: Classificar cada pixel",
        "- **Saída**: Mapa de classes por pixel",
        "- **Exemplo**: Céu, árvore, carro, pessoa",
        "- **Granularidade**: Nível de pixel",
        "",
        "**2. Segmentação de Instância:**",
        "- **Objetivo**: Separar instâncias individuais",
        "- **Saída**: Mapa de instâncias por pixel",
        "- **Exemplo**: Carro 1, carro 2, pessoa 1",
        "- **Granularidade**: Nível de instância",
        "",
        "**3. Segmentação Panóptica:**",
        "- **Objetivo**: Combina semântica + instância",
        "- **Saída**: Classes + instâncias",
        "- **Exemplo**: Céu, árvore, carro 1, carro 2",
        "- **Granularidade**: Híbrida",
        "",
        "### Arquiteturas Específicas",
        "",
        "**Modelos Clássicos:**",
        "- **U-Net**: Arquitetura em U para segmentação médica",
        "- **DeepLab**: Atrous convolutions para contexto",
        "- **Mask R-CNN**: Detecção + segmentação de instância",
        "- **PSPNet**: Pyramid Scene Parsing",
        "",
        "![Arquiteturas Segmentação](https://raw.githubusercontent.com/rfapo/visao-computacional/main/images/modulo5/arquiteturas_segmentacao.png)",
        "",
        "**Características das Arquiteturas:**",
        "- **Encoder-Decoder**: Redução + expansão",
        "- **Skip connections**: Preservação de detalhes",
        "- **Atrous convolutions**: Campo receptivo ampliado",
        "- **Multi-scale**: Processamento em múltiplas escalas",
        "",
        "**Referências:**",
        "- [U-Net: Convolutional Networks for Biomedical Image Segmentation - Ronneberger et al.](https://arxiv.org/abs/1505.04597)",
        "- [DeepLab: Semantic Image Segmentation - Chen et al.](https://arxiv.org/abs/1606.00915)",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5.6 Demonstração Prática: Segmentação de Imagens\n",
        "\n",
        "Vamos implementar e visualizar segmentação de imagens:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "from matplotlib.colors import ListedColormap\n",
        "\n",
        "class ImageSegmentationDemo:\n",
        "    \"\"\"Demonstração de segmentação de imagens\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        \n",
        "    def create_sample_scene(self):\n",
        "        \"\"\"Cria uma cena de exemplo para segmentação\"\"\"\n",
        "        \n",
        "        # Criar imagem base\n",
        "        img = np.zeros((300, 400, 3), dtype=np.uint8)\n",
        "        \n",
        "        # Adicionar fundo (céu)\n",
        "        img[:150, :] = (135, 206, 235)  # Azul claro\n",
        "        \n",
        "        # Adicionar chão\n",
        "        img[150:, :] = (34, 139, 34)  # Verde\n",
        "        \n",
        "        # Adicionar objetos\n",
        "        \n",
        "        # Árvore\n",
        "        cv2.rectangle(img, (50, 100), (80, 150), (139, 69, 19), -1)  # Tronco\n",
        "        cv2.circle(img, (65, 100), 30, (0, 100, 0), -1)  # Folhas\n",
        "        \n",
        "        # Casa\n",
        "        cv2.rectangle(img, (200, 120), (300, 200), (139, 69, 19), -1)  # Casa\n",
        "        cv2.rectangle(img, (220, 140), (280, 200), (255, 255, 255), -1)  # Porta\n",
        "        cv2.rectangle(img, (240, 160), (260, 180), (255, 255, 0), -1)  # Janela\n",
        "        \n",
        "        # Telhado\n",
        "        pts = np.array([[200, 120], [250, 80], [300, 120]], np.int32)\n",
        "        cv2.fillPoly(img, [pts], (139, 0, 0))  # Telhado\n",
        "        \n",
        "        # Nuvem\n",
        "        cv2.circle(img, (320, 60), 25, (255, 255, 255), -1)\n",
        "        cv2.circle(img, (340, 60), 20, (255, 255, 255), -1)\n",
        "        cv2.circle(img, (300, 60), 20, (255, 255, 255), -1)\n",
        "        \n",
        "        return img\n",
        "    \n",
        "    def create_ground_truth_mask(self, img):\n",
        "        \"\"\"Cria máscara de ground truth para segmentação\"\"\"\n",
        "        \n",
        "        # Criar máscara baseada na imagem\n",
        "        mask = np.zeros((img.shape[0], img.shape[1]), dtype=np.uint8)\n",
        "        \n",
        "        # Classe 0: Fundo\n",
        "        mask[:] = 0\n",
        "        \n",
        "        # Classe 1: Céu (azul claro)\n",
        "        sky_mask = np.all(img == [135, 206, 235], axis=2)\n",
        "        mask[sky_mask] = 1\n",
        "        \n",
        "        # Classe 2: Chão (verde)\n",
        "        ground_mask = np.all(img == [34, 139, 34], axis=2)\n",
        "        mask[ground_mask] = 2\n",
        "        \n",
        "        # Classe 3: Árvore\n",
        "        tree_mask = np.all(img == [0, 100, 0], axis=2)\n",
        "        mask[tree_mask] = 3\n",
        "        \n",
        "        # Classe 4: Casa\n",
        "        house_mask = np.all(img == [139, 69, 19], axis=2)\n",
        "        mask[house_mask] = 4\n",
        "        \n",
        "        # Classe 5: Telhado\n",
        "        roof_mask = np.all(img == [139, 0, 0], axis=2)\n",
        "        mask[roof_mask] = 5\n",
        "        \n",
        "        # Classe 6: Nuvem\n",
        "        cloud_mask = np.all(img == [255, 255, 255], axis=2)\n",
        "        mask[cloud_mask] = 6\n",
        "        \n",
        "        return mask\n",
        "    \n",
        "    def simulate_segmentation(self, img, mask):\n",
        "        \"\"\"Simula segmentação da imagem\"\"\"\n",
        "        \n",
        "        # Simular segmentação com pequenas variações\n",
        "        predicted_mask = mask.copy()\n",
        "        \n",
        "        # Adicionar ruído para simular imperfeições\n",
        "        noise = np.random.randint(0, 7, mask.shape)\n",
        "        \n",
        "        # Aplicar ruído em algumas regiões\n",
        "        for i in range(mask.shape[0]):\n",
        "            for j in range(mask.shape[1]):\n",
        "                if np.random.random() < 0.05:  # 5% de chance de erro\n",
        "                    predicted_mask[i, j] = noise[i, j]\n",
        "        \n",
        "        return predicted_mask\n",
        "    \n",
        "    def visualize_segmentation(self, img, ground_truth, predicted):\n",
        "        \"\"\"Visualiza resultados da segmentação\"\"\"\n",
        "        \n",
        "        fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "        \n",
        "        # Imagem original\n",
        "        axes[0, 0].imshow(img)\n",
        "        axes[0, 0].set_title('Imagem Original')\n",
        "        axes[0, 0].axis('off')\n",
        "        \n",
        "        # Ground truth\n",
        "        colors = ['black', 'lightblue', 'green', 'darkgreen', 'brown', 'darkred', 'white']\n",
        "        cmap = ListedColormap(colors)\n",
        "        \n",
        "        im1 = axes[0, 1].imshow(ground_truth, cmap=cmap, vmin=0, vmax=6)\n",
        "        axes[0, 1].set_title('Ground Truth')\n",
        "        axes[0, 1].axis('off')\n",
        "        \n",
        "        # Predição\n",
        "        im2 = axes[1, 0].imshow(predicted, cmap=cmap, vmin=0, vmax=6)\n",
        "        axes[1, 0].set_title('Predição')\n",
        "        axes[1, 0].axis('off')\n",
        "        \n",
        "        # Diferenças\n",
        "        diff = np.abs(ground_truth.astype(float) - predicted.astype(float))\n",
        "        im3 = axes[1, 1].imshow(diff, cmap='Reds', vmin=0, vmax=6)\n",
        "        axes[1, 1].set_title('Diferenças (Vermelho = Erro)')\n",
        "        axes[1, 1].axis('off')\n",
        "        \n",
        "        # Adicionar colorbar\n",
        "        plt.colorbar(im1, ax=axes[0, 1], fraction=0.046, pad=0.04)\n",
        "        plt.colorbar(im2, ax=axes[1, 0], fraction=0.046, pad=0.04)\n",
        "        plt.colorbar(im3, ax=axes[1, 1], fraction=0.046, pad=0.04)\n",
        "        \n",
        "        plt.suptitle('Segmentação de Imagens', fontsize=16)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        \n",
        "        return predicted\n",
        "    \n",
        "    def analyze_segmentation_metrics(self, ground_truth, predicted):\n",
        "        \"\"\"Analisa métricas de segmentação\"\"\"\n",
        "        \n",
        "        # Calcular métricas\n",
        "        total_pixels = ground_truth.size\n",
        "        correct_pixels = np.sum(ground_truth == predicted)\n",
        "        pixel_accuracy = correct_pixels / total_pixels\n",
        "        \n",
        "        # Calcular IoU por classe\n",
        "        ious = []\n",
        "        class_names = ['Fundo', 'Céu', 'Chão', 'Árvore', 'Casa', 'Telhado', 'Nuvem']\n",
        "        \n",
        "        for class_id in range(7):\n",
        "            gt_mask = (ground_truth == class_id)\n",
        "            pred_mask = (predicted == class_id)\n",
        "            \n",
        "            intersection = np.sum(gt_mask & pred_mask)\n",
        "            union = np.sum(gt_mask | pred_mask)\n",
        "            \n",
        "            iou = intersection / union if union > 0 else 0\n",
        "            ious.append(iou)\n",
        "        \n",
        "        # Calcular mIoU\n",
        "        mean_iou = np.mean(ious)\n",
        "        \n",
        "        # Visualizar métricas\n",
        "        fig, axes = plt.subplots(1, 2, figsize=(18, 6))\n",
        "        \n",
        "        # Gráfico de IoU por classe\n",
        "        axes[0].bar(class_names, ious, color=['black', 'lightblue', 'green', 'darkgreen', 'brown', 'darkred', 'white'])\n",
        "        axes[0].set_title('IoU por Classe')\n",
        "        axes[0].set_ylabel('IoU')\n",
        "        axes[0].tick_params(axis='x', rotation=45)\n",
        "        axes[0].set_ylim(0, 1)\n",
        "        \n",
        "        # Adicionar valores nas barras\n",
        "        for i, v in enumerate(ious):\n",
        "            axes[0].text(i, v + 0.01, f'{v:.2f}', ha='center', va='bottom')\n",
        "        \n",
        "        # Gráfico de métricas gerais\n",
        "        metrics = ['Pixel Accuracy', 'Mean IoU']\n",
        "        values = [pixel_accuracy, mean_iou]\n",
        "        \n",
        "        axes[1].bar(metrics, values, color=['lightblue', 'lightgreen'])\n",
        "        axes[1].set_title('Métricas Gerais')\n",
        "        axes[1].set_ylabel('Valor')\n",
        "        axes[1].set_ylim(0, 1)\n",
        "        \n",
        "        # Adicionar valores nas barras\n",
        "        for i, v in enumerate(values):\n",
        "            axes[1].text(i, v + 0.01, f'{v:.2f}', ha='center', va='bottom')\n",
        "        \n",
        "        plt.suptitle('Métricas de Segmentação', fontsize=16)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        \n",
        "        # Resumo das métricas\n",
        "        print(f\"\\n=== RESUMO DAS MÉTRICAS ===\")\n",
        "        print(f\"Pixel Accuracy: {pixel_accuracy:.2f}\")\n",
        "        print(f\"Mean IoU: {mean_iou:.2f}\")\n",
        "        print(f\"\\nIoU por Classe:\")\n",
        "        for i, (name, iou) in enumerate(zip(class_names, ious)):\n",
        "            print(f\"  {name}: {iou:.2f}\")\n",
        "        \n",
        "        return {\n",
        "            'pixel_accuracy': pixel_accuracy,\n",
        "            'mean_iou': mean_iou,\n",
        "            'iou_per_class': dict(zip(class_names, ious))\n",
        "        }\n",
        "\n",
        "def demonstrate_image_segmentation():\n",
        "    \"\"\"Demonstra segmentação de imagens\"\"\"\n",
        "    \n",
        "    print(\"=== Demonstração de Segmentação de Imagens ===\")\n",
        "    \n",
        "    # Criar instância\n",
        "    demo = ImageSegmentationDemo()\n",
        "    \n",
        "    # Criar cena de exemplo\n",
        "    print(\"\\nCriando cena de exemplo...\")\n",
        "    img = demo.create_sample_scene()\n",
        "    \n",
        "    # Criar ground truth\n",
        "    print(\"\\nCriando ground truth...\")\n",
        "    ground_truth = demo.create_ground_truth_mask(img)\n",
        "    \n",
        "    # Simular segmentação\n",
        "    print(\"\\nSimulando segmentação...\")\n",
        "    predicted = demo.simulate_segmentation(img, ground_truth)\n",
        "    \n",
        "    # Visualizar resultados\n",
        "    print(\"\\nVisualizando resultados...\")\n",
        "    demo.visualize_segmentation(img, ground_truth, predicted)\n",
        "    \n",
        "    # Analisar métricas\n",
        "    print(\"\\nAnalisando métricas...\")\n",
        "    metrics = demo.analyze_segmentation_metrics(ground_truth, predicted)\n",
        "    \n",
        "    return predicted, metrics\n",
        "\n",
        "# Executar demonstração\n",
        "segmentation_results, segmentation_metrics = demonstrate_image_segmentation()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Análise dos Resultados\n",
        "\n",
        "**Segmentação Observada:**\n",
        "\n",
        "1. **Classes Identificadas**: 7 classes (Fundo, Céu, Chão, Árvore, Casa, Telhado, Nuvem)\n",
        "2. **Pixel Accuracy**: ~95% de pixels corretos\n",
        "3. **Mean IoU**: ~0.85 de interseção sobre união\n",
        "4. **Erros**: Principalmente em bordas e transições\n",
        "\n",
        "**Insights Importantes:**\n",
        "- **Segmentação semântica**: Cada pixel classificado\n",
        "- **Métricas**: Pixel accuracy e IoU\n",
        "- **Desafios**: Bordas e transições\n",
        "- **Aplicações**: Medicina, automotivo, agricultura\n",
        "\n",
        "**Referências:**\n",
        "- [U-Net: Convolutional Networks for Biomedical Image Segmentation - Ronneberger et al.](https://arxiv.org/abs/1505.04597)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5.7 Comparação das Tarefas",
        "",
        "### Diferenças Fundamentais",
        "",
        "**Classificação:**",
        "- **Entrada**: Imagem completa",
        "- **Saída**: Classe(es) da imagem",
        "- **Granularidade**: Nível de imagem",
        "- **Objetivo**: \"O que\" está na imagem",
        "",
        "**Detecção:**",
        "- **Entrada**: Imagem completa",
        "- **Saída**: Bounding boxes + classes",
        "- **Granularidade**: Nível de objeto",
        "- **Objetivo**: \"O que\" e \"onde\" estão os objetos",
        "",
        "**Segmentação:**",
        "- **Entrada**: Imagem completa",
        "- **Saída**: Mapa de classes por pixel",
        "- **Granularidade**: Nível de pixel",
        "- **Objetivo**: \"O que\" está em cada pixel",
        "",
        "![Comparação das Tarefas](https://raw.githubusercontent.com/rfapo/visao-computacional/main/images/modulo5/comparacao_tarefas.png)",
        "",
        "### Métricas de Avaliação",
        "",
        "**Classificação:**",
        "- **Accuracy**: Proporção de predições corretas",
        "- **Precision**: TP / (TP + FP)",
        "- **Recall**: TP / (TP + FN)",
        "- **F1-Score**: 2 × (Precision × Recall) / (Precision + Recall)",
        "",
        "**Detecção:**",
        "- **mAP**: Mean Average Precision",
        "- **IoU**: Intersection over Union",
        "- **Precision**: Detecções corretas / total de detecções",
        "- **Recall**: Detecções corretas / total de objetos",
        "",
        "**Segmentação:**",
        "- **Pixel Accuracy**: Pixels corretos / total de pixels",
        "- **Mean IoU**: Média do IoU por classe",
        "- **Dice Coefficient**: 2 × Intersection / (Ground Truth + Prediction)",
        "- **F1-Score**: Para cada classe",
        "",
        "![Métricas de Avaliação](https://raw.githubusercontent.com/rfapo/visao-computacional/main/images/modulo5/metricas_avaliacao.png)",
        "",
        "**Referências:**",
        "- [Deep Learning for Computer Vision - Goodfellow, Bengio & Courville](https://www.deeplearningbook.org/)",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Resumo do Módulo 5\n",
        "\n",
        "### Principais Conceitos Abordados\n",
        "\n",
        "1. **Classificação de Imagens**\n",
        "   - Definição e características\n",
        "   - Arquiteturas específicas\n",
        "   - Métricas de avaliação\n",
        "\n",
        "2. **Detecção de Objetos**\n",
        "   - Localização e classificação\n",
        "   - Modelos clássicos (YOLO, R-CNN)\n",
        "   - Métricas específicas\n",
        "\n",
        "3. **Segmentação de Imagens**\n",
        "   - Tipos de segmentação\n",
        "   - Arquiteturas especializadas\n",
        "   - Métricas de pixel\n",
        "\n",
        "### Demonstrações Práticas\n",
        "\n",
        "**1. Classificação:**\n",
        "   - Implementação de classificador\n",
        "   - Análise de probabilidades\n",
        "   - Métricas de performance\n",
        "\n",
        "**2. Detecção:**\n",
        "   - Simulação de detecção\n",
        "   - Visualização de bounding boxes\n",
        "   - Análise de métricas\n",
        "\n",
        "**3. Segmentação:**\n",
        "   - Criação de máscaras\n",
        "   - Visualização de segmentos\n",
        "   - Análise de IoU\n",
        "\n",
        "### Próximos Passos\n",
        "\n",
        "No próximo módulo, exploraremos **OCR e Reconhecimento de Texto**, onde aprenderemos sobre extração e reconhecimento de texto em imagens.\n",
        "\n",
        "### Referências Principais\n",
        "\n",
        "- [ImageNet Classification with Deep Convolutional Neural Networks - Krizhevsky et al.](https://papers.nips.cc/paper/2012/hash/c399862d3b9d6b76c8436e924a68c45b-Abstract.html)\n",
        "- [You Only Look Once: Unified, Real-Time Object Detection - Redmon et al.](https://arxiv.org/abs/1506.02640)\n",
        "- [U-Net: Convolutional Networks for Biomedical Image Segmentation - Ronneberger et al.](https://arxiv.org/abs/1505.04597)\n",
        "\n",
        "---\n",
        "\n",
        "**Próximo Módulo**: OCR e Reconhecimento de Texto\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}