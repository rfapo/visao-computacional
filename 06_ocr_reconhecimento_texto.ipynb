{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Módulo 6: OCR e Reconhecimento de Texto",
        "",
        "## Objetivos de Aprendizagem",
        "- Compreender os fundamentos do OCR (Optical Character Recognition)",
        "- Conhecer ferramentas modernas como Tesseract e EasyOCR",
        "- Implementar soluções de reconhecimento de texto",
        "- Aplicar OCR em casos práticos do mercado",
        "- Entender limitações e desafios do OCR",
        "",
        "---",
        "",
        "## 6.1 Introdução ao OCR",
        "",
        "**OCR (Optical Character Recognition)** é uma tecnologia que converte imagens contendo texto em texto editável e pesquisável.",
        "",
        "![Introdução OCR](https://raw.githubusercontent.com/rfapo/visao-computacional/main/images/modulo6/introducao_ocr.png)",
        "",
        "### Conceitos Fundamentais",
        "",
        "**Definição:**",
        "- **Conversão de imagem para texto**: Transformar pixels em caracteres",
        "- **Processamento de documentos**: Digitalização inteligente",
        "- **Extração de informação**: Dados estruturados de imagens",
        "- **Automação de processos**: Redução de trabalho manual",
        "",
        "**Componentes do OCR:**",
        "1. **Pré-processamento**: Melhoria da qualidade da imagem",
        "2. **Detecção de texto**: Localização de regiões com texto",
        "3. **Reconhecimento de caracteres**: Identificação de letras e números",
        "4. **Pós-processamento**: Correção e formatação do texto",
        "",
        "### Histórico e Evolução",
        "",
        "**Evolução Cronológica:**",
        "- **1950s-1960s**: Primeiros sistemas OCR comerciais",
        "- **1970s-1980s**: Melhoria na precisão e velocidade",
        "- **1990s-2000s**: Integração com computadores pessoais",
        "- **2010s**: Deep Learning revoluciona o campo",
        "- **2020s**: OCR baseado em redes neurais profundas",
        "",
        "![Evolução OCR](https://raw.githubusercontent.com/rfapo/visao-computacional/main/images/modulo6/evolucao_ocr.png)",
        "",
        "**Marcos Importantes:**",
        "- **1951**: Primeiro sistema OCR comercial (IBM)",
        "- **1974**: Ray Kurzweil desenvolve primeiro OCR para cegos",
        "- **1995**: Tesseract OCR open source",
        "- **2018**: EasyOCR com deep learning",
        "- **2020**: PaddleOCR com alta precisão",
        "",
        "**Referências:**",
        "- [Optical Character Recognition - An Illustrated Guide to the Frontier - Casey & Lecolinet](https://ieeexplore.ieee.org/document/546110)",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6.2 Demonstração Prática: OCR com Python\n",
        "\n",
        "Vamos implementar e comparar diferentes ferramentas de OCR:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "import pytesseract\n",
        "import easyocr\n",
        "import time\n",
        "import re\n",
        "\n",
        "class OCRDemo:\n",
        "    \"\"\"Demonstração de diferentes ferramentas de OCR\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.reader = None\n",
        "        \n",
        "    def create_sample_text_images(self):\n",
        "        \"\"\"Cria imagens de exemplo com texto para demonstração\"\"\"\n",
        "        \n",
        "        images = {}\n",
        "        \n",
        "        # Imagem 1: Texto simples\n",
        "        img1 = np.ones((200, 600, 3), dtype=np.uint8) * 255\n",
        "        cv2.putText(img1, 'Hello World!', (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 0, 0), 3)\n",
        "        cv2.putText(img1, 'OCR Demo', (50, 150), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 0, 0), 2)\n",
        "        images['simple_text'] = img1\n",
        "        \n",
        "        # Imagem 2: Texto com números\n",
        "        img2 = np.ones((200, 600, 3), dtype=np.uint8) * 255\n",
        "        cv2.putText(img2, 'Price: $29.99', (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 0, 0), 3)\n",
        "        cv2.putText(img2, 'Date: 2024-01-15', (50, 150), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 0, 0), 2)\n",
        "        images['numbers_text'] = img2\n",
        "        \n",
        "        # Imagem 3: Texto com ruído\n",
        "        img3 = np.ones((200, 600, 3), dtype=np.uint8) * 255\n",
        "        cv2.putText(img3, 'Noisy Text', (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 0, 0), 3)\n",
        "        cv2.putText(img3, 'Recognition', (50, 150), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 0, 0), 2)\n",
        "        \n",
        "        # Adicionar ruído\n",
        "        noise = np.random.randint(0, 50, img3.shape, dtype=np.uint8)\n",
        "        img3 = cv2.add(img3, noise)\n",
        "        images['noisy_text'] = img3\n",
        "        \n",
        "        # Imagem 4: Texto rotacionado\n",
        "        img4 = np.ones((200, 600, 3), dtype=np.uint8) * 255\n",
        "        cv2.putText(img4, 'Rotated Text', (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 0, 0), 3)\n",
        "        cv2.putText(img4, 'Challenge', (50, 150), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 0, 0), 2)\n",
        "        \n",
        "        # Rotacionar imagem\n",
        "        center = (img4.shape[1] // 2, img4.shape[0] // 2)\n",
        "        rotation_matrix = cv2.getRotationMatrix2D(center, 15, 1.0)\n",
        "        img4 = cv2.warpAffine(img4, rotation_matrix, (img4.shape[1], img4.shape[0]))\n",
        "        images['rotated_text'] = img4\n",
        "        \n",
        "        # Imagem 5: Texto pequeno\n",
        "        img5 = np.ones((200, 600, 3), dtype=np.uint8) * 255\n",
        "        cv2.putText(img5, 'Small Text', (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 2)\n",
        "        cv2.putText(img5, 'Hard to Read', (50, 150), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 0), 1)\n",
        "        images['small_text'] = img5\n",
        "        \n",
        "        return images\n",
        "    \n",
        "    def preprocess_image(self, img, method='basic'):\n",
        "        \"\"\"Pré-processa a imagem para melhorar OCR\"\"\"\n",
        "        \n",
        "        if method == 'basic':\n",
        "            # Conversão para escala de cinza\n",
        "            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "            \n",
        "            # Binarização\n",
        "            _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "            \n",
        "            return binary\n",
        "        \n",
        "        elif method == 'advanced':\n",
        "            # Conversão para escala de cinza\n",
        "            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "            \n",
        "            # Redução de ruído\n",
        "            denoised = cv2.medianBlur(gray, 3)\n",
        "            \n",
        "            # Binarização adaptativa\n",
        "            binary = cv2.adaptiveThreshold(denoised, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)\n",
        "            \n",
        "            # Morfologia para limpeza\n",
        "            kernel = np.ones((2, 2), np.uint8)\n",
        "            cleaned = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel)\n",
        "            \n",
        "            return cleaned\n",
        "        \n",
        "        return img\n",
        "    \n",
        "    def ocr_with_tesseract(self, img, preprocess=True):\n",
        "        \"\"\"Executa OCR usando Tesseract\"\"\"\n",
        "        \n",
        "        try:\n",
        "            if preprocess:\n",
        "                processed_img = self.preprocess_image(img, 'basic')\n",
        "            else:\n",
        "                processed_img = img\n",
        "            \n",
        "            # Configurações do Tesseract\n",
        "            config = '--oem 3 --psm 6 -c tessedit_char_whitelist=ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789.,!?$: '\n",
        "            \n",
        "            # Executar OCR\n",
        "            start_time = time.time()\n",
        "            text = pytesseract.image_to_string(processed_img, config=config)\n",
        "            processing_time = time.time() - start_time\n",
        "            \n",
        "            # Limpar texto\n",
        "            text = text.strip()\n",
        "            \n",
        "            return {\n",
        "                'text': text,\n",
        "                'time': processing_time,\n",
        "                'method': 'Tesseract'\n",
        "            }\n",
        "        \n",
        "        except Exception as e:\n",
        "            return {\n",
        "                'text': f'Erro: {str(e)}',\n",
        "                'time': 0,\n",
        "                'method': 'Tesseract'\n",
        "            }\n",
        "    \n",
        "    def ocr_with_easyocr(self, img, preprocess=False):\n",
        "        \"\"\"Executa OCR usando EasyOCR\"\"\"\n",
        "        \n",
        "        try:\n",
        "            # Inicializar EasyOCR (apenas uma vez)\n",
        "            if self.reader is None:\n",
        "                self.reader = easyocr.Reader(['en'])\n",
        "            \n",
        "            if preprocess:\n",
        "                processed_img = self.preprocess_image(img, 'advanced')\n",
        "            else:\n",
        "                processed_img = img\n",
        "            \n",
        "            # Executar OCR\n",
        "            start_time = time.time()\n",
        "            results = self.reader.readtext(processed_img)\n",
        "            processing_time = time.time() - start_time\n",
        "            \n",
        "            # Extrair texto\n",
        "            text_parts = []\n",
        "            for (bbox, text, confidence) in results:\n",
        "                if confidence > 0.5:  # Threshold de confiança\n",
        "                    text_parts.append(text)\n",
        "            \n",
        "            text = ' '.join(text_parts)\n",
        "            \n",
        "            return {\n",
        "                'text': text,\n",
        "                'time': processing_time,\n",
        "                'method': 'EasyOCR',\n",
        "                'confidence': np.mean([conf for _, _, conf in results]) if results else 0\n",
        "            }\n",
        "        \n",
        "        except Exception as e:\n",
        "            return {\n",
        "                'text': f'Erro: {str(e)}',\n",
        "                'time': 0,\n",
        "                'method': 'EasyOCR'\n",
        "            }\n",
        "    \n",
        "    def simulate_ocr_results(self, img_name, img):\n",
        "        \"\"\"Simula resultados de OCR para demonstração\"\"\"\n",
        "        \n",
        "        # Simular resultados baseados no tipo de imagem\n",
        "        if img_name == 'simple_text':\n",
        "            tesseract_result = {\n",
        "                'text': 'Hello World!\\nOCR Demo',\n",
        "                'time': 0.15,\n",
        "                'method': 'Tesseract'\n",
        "            }\n",
        "            easyocr_result = {\n",
        "                'text': 'Hello World! OCR Demo',\n",
        "                'time': 0.25,\n",
        "                'method': 'EasyOCR',\n",
        "                'confidence': 0.95\n",
        "            }\n",
        "        \n",
        "        elif img_name == 'numbers_text':\n",
        "            tesseract_result = {\n",
        "                'text': 'Price: $29.99\\nDate: 2024-01-15',\n",
        "                'time': 0.18,\n",
        "                'method': 'Tesseract'\n",
        "            }\n",
        "            easyocr_result = {\n",
        "                'text': 'Price: $29.99 Date: 2024-01-15',\n",
        "                'time': 0.28,\n",
        "                'method': 'EasyOCR',\n",
        "                'confidence': 0.92\n",
        "            }\n",
        "        \n",
        "        elif img_name == 'noisy_text':\n",
        "            tesseract_result = {\n",
        "                'text': 'Noisy Text\\nRecognition',\n",
        "                'time': 0.22,\n",
        "                'method': 'Tesseract'\n",
        "            }\n",
        "            easyocr_result = {\n",
        "                'text': 'Noisy Text Recognition',\n",
        "                'time': 0.32,\n",
        "                'method': 'EasyOCR',\n",
        "                'confidence': 0.78\n",
        "            }\n",
        "        \n",
        "        elif img_name == 'rotated_text':\n",
        "            tesseract_result = {\n",
        "                'text': 'Rotated Text\\nChallenge',\n",
        "                'time': 0.20,\n",
        "                'method': 'Tesseract'\n",
        "            }\n",
        "            easyocr_result = {\n",
        "                'text': 'Rotated Text Challenge',\n",
        "                'time': 0.30,\n",
        "                'method': 'EasyOCR',\n",
        "                'confidence': 0.85\n",
        "            }\n",
        "        \n",
        "        else:  # small_text\n",
        "            tesseract_result = {\n",
        "                'text': 'Small Text\\nHard to Read',\n",
        "                'time': 0.25,\n",
        "                'method': 'Tesseract'\n",
        "            }\n",
        "            easyocr_result = {\n",
        "                'text': 'Small Text Hard to Read',\n",
        "                'time': 0.35,\n",
        "                'method': 'EasyOCR',\n",
        "                'confidence': 0.68\n",
        "            }\n",
        "        \n",
        "        return tesseract_result, easyocr_result\n",
        "    \n",
        "    def visualize_ocr_results(self, images, results):\n",
        "        \"\"\"Visualiza resultados do OCR\"\"\"\n",
        "        \n",
        "        fig, axes = plt.subplots(3, 5, figsize=(20, 12))\n",
        "        \n",
        "        for i, (img_name, img) in enumerate(images.items()):\n",
        "            # Imagem original\n",
        "            axes[0, i].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "            axes[0, i].set_title(f'Original: {img_name}')\n",
        "            axes[0, i].axis('off')\n",
        "            \n",
        "            # Imagem pré-processada\n",
        "            processed = self.preprocess_image(img, 'basic')\n",
        "            axes[1, i].imshow(processed, cmap='gray')\n",
        "            axes[1, i].set_title('Pré-processada')\n",
        "            axes[1, i].axis('off')\n",
        "            \n",
        "            # Resultados do OCR\n",
        "            tesseract_result, easyocr_result = results[img_name]\n",
        "            \n",
        "            result_text = f\"Tesseract:\\n{tesseract_result['text'][:50]}...\\n\\nEasyOCR:\\n{easyocr_result['text'][:50]}...\"\n",
        "            \n",
        "            axes[2, i].text(0.05, 0.95, result_text, transform=axes[2, i].transAxes, \n",
        "                          fontsize=8, verticalalignment='top',\n",
        "                          bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.8))\n",
        "            axes[2, i].set_title('Resultados OCR')\n",
        "            axes[2, i].axis('off')\n",
        "        \n",
        "        plt.suptitle('Comparação de Ferramentas de OCR', fontsize=16)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        \n",
        "        return results\n",
        "    \n",
        "    def analyze_ocr_performance(self, results):\n",
        "        \"\"\"Analisa performance das ferramentas de OCR\"\"\"\n",
        "        \n",
        "        # Calcular métricas\n",
        "        tesseract_times = []\n",
        "        easyocr_times = []\n",
        "        easyocr_confidences = []\n",
        "        \n",
        "        for img_name, (tesseract_result, easyocr_result) in results.items():\n",
        "            tesseract_times.append(tesseract_result['time'])\n",
        "            easyocr_times.append(easyocr_result['time'])\n",
        "            if 'confidence' in easyocr_result:\n",
        "                easyocr_confidences.append(easyocr_result['confidence'])\n",
        "        \n",
        "        # Visualizar métricas\n",
        "        fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
        "        \n",
        "        # Gráfico de tempo de processamento\n",
        "        img_names = list(results.keys())\n",
        "        x = np.arange(len(img_names))\n",
        "        width = 0.35\n",
        "        \n",
        "        axes[0].bar(x - width/2, tesseract_times, width, label='Tesseract', color='lightblue')\n",
        "        axes[0].bar(x + width/2, easyocr_times, width, label='EasyOCR', color='lightgreen')\n",
        "        axes[0].set_title('Tempo de Processamento')\n",
        "        axes[0].set_ylabel('Tempo (segundos)')\n",
        "        axes[0].set_xticks(x)\n",
        "        axes[0].set_xticklabels([name.replace('_', ' ').title() for name in img_names], rotation=45)\n",
        "        axes[0].legend()\n",
        "        \n",
        "        # Gráfico de confiança (EasyOCR)\n",
        "        axes[1].bar(img_names, easyocr_confidences, color='lightcoral')\n",
        "        axes[1].set_title('Confiança do EasyOCR')\n",
        "        axes[1].set_ylabel('Confiança')\n",
        "        axes[1].tick_params(axis='x', rotation=45)\n",
        "        axes[1].set_ylim(0, 1)\n",
        "        \n",
        "        # Adicionar valores nas barras\n",
        "        for i, v in enumerate(easyocr_confidences):\n",
        "            axes[1].text(i, v + 0.01, f'{v:.2f}', ha='center', va='bottom')\n",
        "        \n",
        "        # Comparação de características\n",
        "        characteristics = {\n",
        "            'Velocidade': [np.mean(tesseract_times), np.mean(easyocr_times)],\n",
        "            'Precisão': [0.85, 0.90],  # Valores simulados\n",
        "            'Facilidade': [0.95, 0.80],  # Valores simulados\n",
        "            'Suporte': [0.90, 0.85]  # Valores simulados\n",
        "        }\n",
        "        \n",
        "        methods = ['Tesseract', 'EasyOCR']\n",
        "        x = np.arange(len(methods))\n",
        "        width = 0.2\n",
        "        \n",
        "        for i, (char, values) in enumerate(characteristics.items()):\n",
        "            axes[2].bar(x + i*width, values, width, label=char)\n",
        "        \n",
        "        axes[2].set_title('Comparação de Características')\n",
        "        axes[2].set_ylabel('Pontuação')\n",
        "        axes[2].set_xticks(x + width * 1.5)\n",
        "        axes[2].set_xticklabels(methods)\n",
        "        axes[2].legend()\n",
        "        axes[2].set_ylim(0, 1)\n",
        "        \n",
        "        plt.suptitle('Análise de Performance do OCR', fontsize=16)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        \n",
        "        # Resumo das métricas\n",
        "        print(f\"\\n=== RESUMO DAS MÉTRICAS ===\")\n",
        "        print(f\"Tesseract - Tempo Médio: {np.mean(tesseract_times):.2f}s\")\n",
        "        print(f\"EasyOCR - Tempo Médio: {np.mean(easyocr_times):.2f}s\")\n",
        "        print(f\"EasyOCR - Confiança Média: {np.mean(easyocr_confidences):.2f}\")\n",
        "        \n",
        "        return {\n",
        "            'tesseract_times': tesseract_times,\n",
        "            'easyocr_times': easyocr_times,\n",
        "            'easyocr_confidences': easyocr_confidences\n",
        "        }\n",
        "\n",
        "def demonstrate_ocr():\n",
        "    \"\"\"Demonstra diferentes ferramentas de OCR\"\"\"\n",
        "    \n",
        "    print(\"=== Demonstração de OCR ===\")\n",
        "    print(\"\\nNota: Esta demonstração simula resultados de OCR para fins educacionais.\")\n",
        "    print(\"Em aplicações reais, use as ferramentas reais com imagens reais.\")\n",
        "    \n",
        "    # Criar instância\n",
        "    demo = OCRDemo()\n",
        "    \n",
        "    # Criar imagens de exemplo\n",
        "    print(\"\\nCriando imagens de exemplo...\")\n",
        "    images = demo.create_sample_text_images()\n",
        "    \n",
        "    # Simular resultados de OCR\n",
        "    print(\"\\nSimulando resultados de OCR...\")\n",
        "    results = {}\n",
        "    for img_name, img in images.items():\n",
        "        tesseract_result, easyocr_result = demo.simulate_ocr_results(img_name, img)\n",
        "        results[img_name] = (tesseract_result, easyocr_result)\n",
        "    \n",
        "    # Visualizar resultados\n",
        "    print(\"\\nVisualizando resultados...\")\n",
        "    demo.visualize_ocr_results(images, results)\n",
        "    \n",
        "    # Analisar performance\n",
        "    print(\"\\nAnalisando performance...\")\n",
        "    metrics = demo.analyze_ocr_performance(results)\n",
        "    \n",
        "    return results, metrics\n",
        "\n",
        "# Executar demonstração\n",
        "ocr_results, ocr_metrics = demonstrate_ocr()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Análise dos Resultados\n",
        "\n",
        "**OCR Observado:**\n",
        "\n",
        "1. **Tesseract**: Mais rápido, boa precisão para texto simples\n",
        "2. **EasyOCR**: Mais lento, melhor precisão para texto complexo\n",
        "3. **Pré-processamento**: Melhora significativamente os resultados\n",
        "4. **Confiança**: EasyOCR fornece métricas de confiança\n",
        "\n",
        "**Insights Importantes:**\n",
        "- **Velocidade**: Tesseract é mais rápido\n",
        "- **Precisão**: EasyOCR é mais preciso\n",
        "- **Robustez**: EasyOCR lida melhor com ruído\n",
        "- **Facilidade**: Tesseract é mais fácil de usar\n",
        "\n",
        "**Referências:**\n",
        "- [Tesseract OCR - Google](https://github.com/tesseract-ocr/tesseract)\n",
        "- [EasyOCR - JaidedAI](https://github.com/JaidedAI/EasyOCR)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6.3 Ferramentas Modernas de OCR",
        "",
        "### Tesseract OCR",
        "",
        "**Características:**",
        "- **Open source**: Desenvolvido pelo Google",
        "- **Multi-idioma**: Suporte a 100+ idiomas",
        "- **Configurável**: Múltiplas opções de configuração",
        "- **Estável**: Ferramenta madura e confiável",
        "",
        "![Tesseract OCR](https://raw.githubusercontent.com/rfapo/visao-computacional/main/images/modulo6/tesseract_ocr.png)",
        "",
        "**Vantagens:**",
        "- **Velocidade**: Processamento rápido",
        "- **Simplicidade**: Fácil de implementar",
        "- **Estabilidade**: Resultados consistentes",
        "- **Documentação**: Bem documentado",
        "",
        "**Desvantagens:**",
        "- **Precisão**: Limitada para texto complexo",
        "- **Ruído**: Sensível a ruído e distorções",
        "- **Configuração**: Requer ajuste fino",
        "- **Limitações**: Não funciona bem com texto rotacionado",
        "",
        "### EasyOCR",
        "",
        "**Características:**",
        "- **Deep Learning**: Baseado em redes neurais",
        "- **Multi-idioma**: Suporte a 80+ idiomas",
        "- **Confiança**: Fornece métricas de confiança",
        "- **Robustez**: Lida bem com texto complexo",
        "",
        "![EasyOCR](https://raw.githubusercontent.com/rfapo/visao-computacional/main/images/modulo6/easyocr.png)",
        "",
        "**Vantagens:**",
        "- **Precisão**: Alta precisão para texto complexo",
        "- **Robustez**: Lida bem com ruído e distorções",
        "- **Confiança**: Métricas de confiança",
        "- **Flexibilidade**: Funciona com diferentes tipos de texto",
        "",
        "**Desvantagens:**",
        "- **Velocidade**: Mais lento que Tesseract",
        "- **Recursos**: Requer mais recursos computacionais",
        "- **Dependências**: Mais dependências",
        "- **Complexidade**: Mais complexo de configurar",
        "",
        "### PaddleOCR",
        "",
        "**Características:**",
        "- **Deep Learning**: Baseado em PaddlePaddle",
        "- **Multi-idioma**: Suporte a 80+ idiomas",
        "- **Precisão**: Alta precisão",
        "- **Velocidade**: Otimizado para velocidade",
        "",
        "![PaddleOCR](https://raw.githubusercontent.com/rfapo/visao-computacional/main/images/modulo6/paddleocr.png)",
        "",
        "**Vantagens:**",
        "- **Precisão**: Alta precisão",
        "- **Velocidade**: Rápido",
        "- **Robustez**: Lida bem com texto complexo",
        "- **Suporte**: Bom suporte da comunidade",
        "",
        "**Desvantagens:**",
        "- **Complexidade**: Mais complexo",
        "- **Dependências**: Muitas dependências",
        "- **Documentação**: Documentação em chinês",
        "- **Suporte**: Suporte limitado em inglês",
        "",
        "**Referências:**",
        "- [Tesseract OCR - Google](https://github.com/tesseract-ocr/tesseract)",
        "- [EasyOCR - JaidedAI](https://github.com/JaidedAI/EasyOCR)",
        "- [PaddleOCR - PaddlePaddle](https://github.com/PaddlePaddle/PaddleOCR)",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6.4 Pré-processamento para OCR",
        "",
        "### Técnicas de Pré-processamento",
        "",
        "**1. Conversão para Escala de Cinza:**",
        "- **Objetivo**: Reduzir dimensionalidade",
        "- **Método**: Média ponderada dos canais RGB",
        "- **Fórmula**: Gray = 0.299×R + 0.587×G + 0.114×B",
        "- **Benefício**: Reduz ruído e melhora processamento",
        "",
        "**2. Binarização:**",
        "- **Objetivo**: Separar texto do fundo",
        "- **Métodos**: Threshold global, adaptativo, Otsu",
        "- **Threshold Global**: Valor fixo para todos os pixels",
        "- **Threshold Adaptativo**: Valor baseado na vizinhança",
        "- **Otsu**: Valor ótimo baseado na distribuição",
        "",
        "![Técnicas de Pré-processamento](https://raw.githubusercontent.com/rfapo/visao-computacional/main/images/modulo6/tecnicas_preprocessamento.png)",
        "",
        "**3. Redução de Ruído:**",
        "- **Filtro Gaussiano**: Suavização com kernel gaussiano",
        "- **Filtro Mediano**: Remove ruído impulsivo",
        "- **Morfologia**: Operações de abertura e fechamento",
        "- **Benefício**: Melhora qualidade da imagem",
        "",
        "**4. Correção de Inclinação:**",
        "- **Detecção**: Análise de projeções horizontais",
        "- **Correção**: Rotação baseada no ângulo detectado",
        "- **Métodos**: Hough transform, análise de linhas",
        "- **Benefício**: Melhora precisão do OCR",
        "",
        "### Demonstração Prática: Pré-processamento",
        "",
        "Vamos implementar e visualizar diferentes técnicas de pré-processamento:",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class PreprocessingDemo:\n",
        "    \"\"\"Demonstração de técnicas de pré-processamento para OCR\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        pass\n",
        "    \n",
        "    def create_challenging_image(self):\n",
        "        \"\"\"Cria uma imagem desafiadora para OCR\"\"\"\n",
        "        \n",
        "        # Criar imagem base\n",
        "        img = np.ones((300, 600, 3), dtype=np.uint8) * 200\n",
        "        \n",
        "        # Adicionar texto\n",
        "        cv2.putText(img, 'Challenging OCR', (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 0, 0), 3)\n",
        "        cv2.putText(img, 'Preprocessing Demo', (50, 150), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 0, 0), 2)\n",
        "        cv2.putText(img, 'Noise + Rotation', (50, 200), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 0, 0), 2)\n",
        "        \n",
        "        # Adicionar ruído\n",
        "        noise = np.random.randint(0, 50, img.shape, dtype=np.uint8)\n",
        "        img = cv2.add(img, noise)\n",
        "        \n",
        "        # Adicionar inclinação\n",
        "        center = (img.shape[1] // 2, img.shape[0] // 2)\n",
        "        rotation_matrix = cv2.getRotationMatrix2D(center, 5, 1.0)\n",
        "        img = cv2.warpAffine(img, rotation_matrix, (img.shape[1], img.shape[0]))\n",
        "        \n",
        "        return img\n",
        "    \n",
        "    def apply_preprocessing_techniques(self, img):\n",
        "        \"\"\"Aplica diferentes técnicas de pré-processamento\"\"\"\n",
        "        \n",
        "        results = {}\n",
        "        \n",
        "        # 1. Imagem original\n",
        "        results['original'] = img\n",
        "        \n",
        "        # 2. Conversão para escala de cinza\n",
        "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "        results['grayscale'] = gray\n",
        "        \n",
        "        # 3. Binarização global\n",
        "        _, binary_global = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)\n",
        "        results['binary_global'] = binary_global\n",
        "        \n",
        "        # 4. Binarização Otsu\n",
        "        _, binary_otsu = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "        results['binary_otsu'] = binary_otsu\n",
        "        \n",
        "        # 5. Binarização adaptativa\n",
        "        binary_adaptive = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)\n",
        "        results['binary_adaptive'] = binary_adaptive\n",
        "        \n",
        "        # 6. Redução de ruído\n",
        "        denoised = cv2.medianBlur(gray, 3)\n",
        "        results['denoised'] = denoised\n",
        "        \n",
        "        # 7. Morfologia\n",
        "        kernel = np.ones((2, 2), np.uint8)\n",
        "        morphed = cv2.morphologyEx(binary_otsu, cv2.MORPH_CLOSE, kernel)\n",
        "        results['morphed'] = morphed\n",
        "        \n",
        "        # 8. Correção de inclinação\n",
        "        # Detectar linhas\n",
        "        edges = cv2.Canny(gray, 50, 150)\n",
        "        lines = cv2.HoughLines(edges, 1, np.pi/180, threshold=100)\n",
        "        \n",
        "        if lines is not None:\n",
        "            # Calcular ângulo médio\n",
        "            angles = []\n",
        "            for line in lines:\n",
        "                rho, theta = line[0]\n",
        "                angle = theta * 180 / np.pi\n",
        "                if 45 < angle < 135:  # Linhas horizontais\n",
        "                    angles.append(angle - 90)\n",
        "            \n",
        "            if angles:\n",
        "                avg_angle = np.mean(angles)\n",
        "                # Corrigir inclinação\n",
        "                center = (img.shape[1] // 2, img.shape[0] // 2)\n",
        "                rotation_matrix = cv2.getRotationMatrix2D(center, -avg_angle, 1.0)\n",
        "                corrected = cv2.warpAffine(gray, rotation_matrix, (img.shape[1], img.shape[0]))\n",
        "                results['corrected'] = corrected\n",
        "            else:\n",
        "                results['corrected'] = gray\n",
        "        else:\n",
        "            results['corrected'] = gray\n",
        "        \n",
        "        return results\n",
        "    \n",
        "    def visualize_preprocessing_results(self, results):\n",
        "        \"\"\"Visualiza resultados do pré-processamento\"\"\"\n",
        "        \n",
        "        fig, axes = plt.subplots(2, 4, figsize=(20, 10))\n",
        "        \n",
        "        # Títulos e descrições\n",
        "        titles = {\n",
        "            'original': 'Imagem Original',\n",
        "            'grayscale': 'Escala de Cinza',\n",
        "            'binary_global': 'Binarização Global',\n",
        "            'binary_otsu': 'Binarização Otsu',\n",
        "            'binary_adaptive': 'Binarização Adaptativa',\n",
        "            'denoised': 'Redução de Ruído',\n",
        "            'morphed': 'Morfologia',\n",
        "            'corrected': 'Correção de Inclinação'\n",
        "        }\n",
        "        \n",
        "        # Plotar resultados\n",
        "        for i, (key, img) in enumerate(results.items()):\n",
        "            row = i // 4\n",
        "            col = i % 4\n",
        "            \n",
        "            if len(img.shape) == 3:\n",
        "                axes[row, col].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "            else:\n",
        "                axes[row, col].imshow(img, cmap='gray')\n",
        "            \n",
        "            axes[row, col].set_title(titles[key])\n",
        "            axes[row, col].axis('off')\n",
        "        \n",
        "        plt.suptitle('Técnicas de Pré-processamento para OCR', fontsize=16)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        \n",
        "        return results\n",
        "    \n",
        "    def analyze_preprocessing_quality(self, results):\n",
        "        \"\"\"Analisa qualidade do pré-processamento\"\"\"\n",
        "        \n",
        "        # Calcular métricas de qualidade\n",
        "        quality_metrics = {}\n",
        "        \n",
        "        for key, img in results.items():\n",
        "            if len(img.shape) == 3:\n",
        "                gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "            else:\n",
        "                gray = img\n",
        "            \n",
        "            # Calcular contraste\n",
        "            contrast = np.std(gray)\n",
        "            \n",
        "            # Calcular nitidez (Laplaciano)\n",
        "            laplacian = cv2.Laplacian(gray, cv2.CV_64F)\n",
        "            sharpness = np.var(laplacian)\n",
        "            \n",
        "            # Calcular uniformidade\n",
        "            uniformity = 1 - np.std(gray) / np.mean(gray)\n",
        "            \n",
        "            quality_metrics[key] = {\n",
        "                'contrast': contrast,\n",
        "                'sharpness': sharpness,\n",
        "                'uniformity': uniformity\n",
        "            }\n",
        "        \n",
        "        # Visualizar métricas\n",
        "        fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
        "        \n",
        "        # Gráfico de contraste\n",
        "        keys = list(quality_metrics.keys())\n",
        "        contrasts = [quality_metrics[key]['contrast'] for key in keys]\n",
        "        \n",
        "        axes[0].bar(keys, contrasts, color='lightblue')\n",
        "        axes[0].set_title('Contraste')\n",
        "        axes[0].set_ylabel('Desvio Padrão')\n",
        "        axes[0].tick_params(axis='x', rotation=45)\n",
        "        \n",
        "        # Gráfico de nitidez\n",
        "        sharpnesses = [quality_metrics[key]['sharpness'] for key in keys]\n",
        "        \n",
        "        axes[1].bar(keys, sharpnesses, color='lightgreen')\n",
        "        axes[1].set_title('Nitidez')\n",
        "        axes[1].set_ylabel('Variância do Laplaciano')\n",
        "        axes[1].tick_params(axis='x', rotation=45)\n",
        "        \n",
        "        # Gráfico de uniformidade\n",
        "        uniformities = [quality_metrics[key]['uniformity'] for key in keys]\n",
        "        \n",
        "        axes[2].bar(keys, uniformities, color='lightcoral')\n",
        "        axes[2].set_title('Uniformidade')\n",
        "        axes[2].set_ylabel('Uniformidade')\n",
        "        axes[2].tick_params(axis='x', rotation=45)\n",
        "        \n",
        "        plt.suptitle('Métricas de Qualidade do Pré-processamento', fontsize=16)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        \n",
        "        # Resumo das métricas\n",
        "        print(f\"\\n=== RESUMO DAS MÉTRICAS ===\")\n",
        "        for key, metrics in quality_metrics.items():\n",
        "            print(f\"{key}: Contraste={metrics['contrast']:.1f}, Nitidez={metrics['sharpness']:.1f}, Uniformidade={metrics['uniformity']:.2f}\")\n",
        "        \n",
        "        return quality_metrics\n",
        "\n",
        "def demonstrate_preprocessing():\n",
        "    \"\"\"Demonstra técnicas de pré-processamento\"\"\"\n",
        "    \n",
        "    print(\"=== Demonstração de Pré-processamento para OCR ===\")\n",
        "    \n",
        "    # Criar instância\n",
        "    demo = PreprocessingDemo()\n",
        "    \n",
        "    # Criar imagem desafiadora\n",
        "    print(\"\\nCriando imagem desafiadora...\")\n",
        "    img = demo.create_challenging_image()\n",
        "    \n",
        "    # Aplicar técnicas de pré-processamento\n",
        "    print(\"\\nAplicando técnicas de pré-processamento...\")\n",
        "    results = demo.apply_preprocessing_techniques(img)\n",
        "    \n",
        "    # Visualizar resultados\n",
        "    print(\"\\nVisualizando resultados...\")\n",
        "    demo.visualize_preprocessing_results(results)\n",
        "    \n",
        "    # Analisar qualidade\n",
        "    print(\"\\nAnalisando qualidade...\")\n",
        "    metrics = demo.analyze_preprocessing_quality(results)\n",
        "    \n",
        "    return results, metrics\n",
        "\n",
        "# Executar demonstração\n",
        "preprocessing_results, preprocessing_metrics = demonstrate_preprocessing()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Análise dos Resultados\n",
        "\n",
        "**Pré-processamento Observado:**\n",
        "\n",
        "1. **Escala de Cinza**: Reduz ruído e melhora processamento\n",
        "2. **Binarização Otsu**: Melhor separação texto/fundo\n",
        "3. **Binarização Adaptativa**: Lida bem com iluminação variável\n",
        "4. **Redução de Ruído**: Melhora qualidade da imagem\n",
        "5. **Morfologia**: Limpa artefatos\n",
        "6. **Correção de Inclinação**: Melhora precisão do OCR\n",
        "\n",
        "**Insights Importantes:**\n",
        "- **Sequência**: Ordem das operações é importante\n",
        "- **Parâmetros**: Ajuste fino necessário\n",
        "- **Qualidade**: Métricas objetivas de qualidade\n",
        "- **Aplicação**: Depende do tipo de imagem\n",
        "\n",
        "**Referências:**\n",
        "- [Optical Character Recognition - An Illustrated Guide to the Frontier - Casey & Lecolinet](https://ieeexplore.ieee.org/document/546110)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6.5 Aplicações Práticas do OCR",
        "",
        "### Casos de Uso Reais",
        "",
        "**1. Digitalização de Documentos:**",
        "- **Contratos**: Extração de informações de contratos",
        "- **Faturas**: Processamento automático de faturas",
        "- **Relatórios**: Digitalização de relatórios impressos",
        "- **Exemplo**: Adobe Acrobat, Google Drive",
        "",
        "**2. Automação de Processos:**",
        "- **Entrada de dados**: Automatização de entrada manual",
        "- **Validação**: Verificação automática de documentos",
        "- **Classificação**: Categorização automática",
        "- **Exemplo**: RPA (Robotic Process Automation)",
        "",
        "**3. Acessibilidade:**",
        "- **Leitores de tela**: Conversão de texto para áudio",
        "- **Tradução**: Tradução automática de texto",
        "- **Navegação**: Ajuda para pessoas com deficiência visual",
        "- **Exemplo**: Google Lens, Microsoft Seeing AI",
        "",
        "**4. Mobile e IoT:**",
        "- **Apps móveis**: Reconhecimento de texto em tempo real",
        "- **Dispositivos IoT**: Processamento de texto em dispositivos",
        "- **Realidade aumentada**: Sobreposição de informações",
        "- **Exemplo**: Google Translate, Apple Live Text",
        "",
        "![Aplicações Práticas OCR](https://raw.githubusercontent.com/rfapo/visao-computacional/main/images/modulo6/aplicacoes_praticas_ocr.png)",
        "",
        "### Desafios e Limitações",
        "",
        "**1. Qualidade da Imagem:**",
        "- **Resolução**: Imagens de baixa resolução",
        "- **Iluminação**: Iluminação inadequada",
        "- **Ruído**: Ruído e artefatos",
        "- **Distorção**: Distorções ópticas",
        "",
        "**2. Tipos de Texto:**",
        "- **Fontes**: Fontes não padrão",
        "- **Tamanho**: Texto muito pequeno",
        "- **Estilo**: Texto manuscrito",
        "- **Idioma**: Idiomas não suportados",
        "",
        "**3. Contexto:**",
        "- **Layout**: Layout complexo",
        "- **Orientação**: Texto rotacionado",
        "- **Sobreposição**: Texto sobreposto",
        "- **Fundo**: Fundo complexo",
        "",
        "![Desafios OCR](https://raw.githubusercontent.com/rfapo/visao-computacional/main/images/modulo6/desafios_ocr.png)",
        "",
        "**Referências:**",
        "- [Optical Character Recognition - An Illustrated Guide to the Frontier - Casey & Lecolinet](https://ieeexplore.ieee.org/document/546110)",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Resumo do Módulo 6\n",
        "\n",
        "### Principais Conceitos Abordados\n",
        "\n",
        "1. **Introdução ao OCR**\n",
        "   - Conceitos fundamentais\n",
        "   - Componentes do sistema\n",
        "   - Histórico e evolução\n",
        "\n",
        "2. **Ferramentas Modernas**\n",
        "   - Tesseract OCR\n",
        "   - EasyOCR\n",
        "   - PaddleOCR\n",
        "   - Comparação de características\n",
        "\n",
        "3. **Pré-processamento**\n",
        "   - Técnicas de melhoria\n",
        "   - Binarização e redução de ruído\n",
        "   - Correção de inclinação\n",
        "   - Métricas de qualidade\n",
        "\n",
        "4. **Aplicações Práticas**\n",
        "   - Casos de uso reais\n",
        "   - Desafios e limitações\n",
        "   - Tendências futuras\n",
        "\n",
        "### Demonstrações Práticas\n",
        "\n",
        "**1. Comparação de Ferramentas:**\n",
        "   - Tesseract vs EasyOCR\n",
        "   - Análise de performance\n",
        "   - Métricas de qualidade\n",
        "\n",
        "**2. Pré-processamento:**\n",
        "   - Técnicas de melhoria\n",
        "   - Visualização de resultados\n",
        "   - Análise de qualidade\n",
        "\n",
        "### Próximos Passos\n",
        "\n",
        "No próximo módulo, exploraremos **GANs e VAEs para Geração Sintética de Imagens**, onde aprenderemos sobre modelos generativos.\n",
        "\n",
        "### Referências Principais\n",
        "\n",
        "- [Optical Character Recognition - An Illustrated Guide to the Frontier - Casey & Lecolinet](https://ieeexplore.ieee.org/document/546110)\n",
        "- [Tesseract OCR - Google](https://github.com/tesseract-ocr/tesseract)\n",
        "- [EasyOCR - JaidedAI](https://github.com/JaidedAI/EasyOCR)\n",
        "\n",
        "---\n",
        "\n",
        "**Próximo Módulo**: GANs e VAEs para Geração Sintética de Imagens\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}