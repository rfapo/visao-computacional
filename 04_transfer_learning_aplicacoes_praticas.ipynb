{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Módulo 4: Transfer Learning e Aplicações Práticas",
        "",
        "## Objetivos de Aprendizagem",
        "- Compreender o conceito de transfer learning",
        "- Aplicar modelos pré-treinados em problemas específicos",
        "- Entender quando usar fine-tuning vs. feature extraction",
        "- Implementar transfer learning com PyTorch",
        "- Conhecer aplicações práticas no mercado",
        "",
        "---",
        "",
        "## 4.1 Transfer Learning em Visão Computacional",
        "",
        "**Transfer Learning** é uma técnica de machine learning que permite utilizar conhecimento adquirido em uma tarefa para melhorar o desempenho em uma tarefa relacionada. Em visão computacional, isso significa aproveitar modelos treinados em datasets massivos como ImageNet.",
        "",
        "![Transfer Learning - Conceito](https://raw.githubusercontent.com/rfapo/visao-computacional/main/images/modulo4/transfer_learning_conceito.png)",
        "",
        "### Conceitos Fundamentais",
        "",
        "**Definição:**",
        "- **Utilização de conhecimento**: Aproveitar representações aprendidas em tarefas similares",
        "- **Modelos pré-treinados**: Redes treinadas em ImageNet com milhões de imagens",
        "- **Adaptação**: Ajustar o modelo para nova tarefa específica",
        "- **Eficiência**: Reduzir tempo e dados necessários para treinamento",
        "",
        "**Por que Funciona?**",
        "- **Features universais**: Primeiras camadas aprendem características básicas (bordas, texturas)",
        "- **Hierarquia de abstração**: Camadas profundas capturam conceitos específicos",
        "- **Reutilização**: Características baixo-nível são transferíveis entre domínios",
        "",
        "![Por que Transfer Learning Funciona](https://raw.githubusercontent.com/rfapo/visao-computacional/main/images/modulo4/por_que_transfer_learning_funciona.png)",
        "",
        "**Benefícios Quantitativos:**",
        "- **Economia de tempo**: Até 10x mais rápido que treino do zero",
        "- **Menos dados**: Requer 5-10x menos dados de treinamento",
        "- **Melhor acurácia**: Especialmente em datasets pequenos",
        "- **Facilita adaptação**: A novos domínios e tarefas",
        "",
        "### Estratégias de Transfer Learning",
        "",
        "**Comparação das Abordagens:**",
        "- **Feature Extraction**: Congela todas as camadas",
        "- **Fine-tuning**: Descongela camadas finais",
        "- **Pre-trained Initialization**: Treina tudo do zero",
        "",
        "![Estratégias de Transfer Learning](https://raw.githubusercontent.com/rfapo/visao-computacional/main/images/modulo4/estrategias_comparacao.png)",
        "",
        "**Referências:**",
        "- [How transferable are features in deep neural networks? - Yosinski et al.](https://arxiv.org/abs/1411.1792)",
        "- [Transfer Learning for Computer Vision - Pan & Yang](https://ieeexplore.ieee.org/document/5288526)",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4.2 Demonstração Prática: Transfer Learning com PyTorch\n",
        "\n",
        "Vamos implementar e comparar diferentes estratégias de transfer learning:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torchvision import models\n",
        "import time\n",
        "\n",
        "class TransferLearningDemo:\n",
        "    \"\"\"Demonstração de diferentes estratégias de transfer learning\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        print(f\"Usando dispositivo: {self.device}\")\n",
        "        \n",
        "    def create_feature_extraction_model(self, num_classes=5):\n",
        "        \"\"\"Cria modelo usando feature extraction\"\"\"\n",
        "        # Carregar ResNet18 pré-treinado\n",
        "        model = models.resnet18(pretrained=True)\n",
        "        \n",
        "        # Congelar todos os parâmetros\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = False\n",
        "        \n",
        "        # Substituir a última camada\n",
        "        num_features = model.fc.in_features\n",
        "        model.fc = nn.Linear(num_features, num_classes)\n",
        "        \n",
        "        return model\n",
        "    \n",
        "    def create_fine_tuning_model(self, num_classes=5):\n",
        "        \"\"\"Cria modelo usando fine-tuning\"\"\"\n",
        "        # Carregar ResNet18 pré-treinado\n",
        "        model = models.resnet18(pretrained=True)\n",
        "        \n",
        "        # Substituir a última camada\n",
        "        num_features = model.fc.in_features\n",
        "        model.fc = nn.Linear(num_features, num_classes)\n",
        "        \n",
        "        # Descongelar algumas camadas finais\n",
        "        for param in model.layer4.parameters():\n",
        "            param.requires_grad = True\n",
        "        for param in model.fc.parameters():\n",
        "            param.requires_grad = True\n",
        "        \n",
        "        return model\n",
        "    \n",
        "    def create_from_scratch_model(self, num_classes=5):\n",
        "        \"\"\"Cria modelo treinado do zero\"\"\"\n",
        "        model = models.resnet18(pretrained=False)\n",
        "        num_features = model.fc.in_features\n",
        "        model.fc = nn.Linear(num_features, num_classes)\n",
        "        \n",
        "        return model\n",
        "    \n",
        "    def count_parameters(self, model):\n",
        "        \"\"\"Conta parâmetros treináveis\"\"\"\n",
        "        return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    \n",
        "    def simulate_training_time(self, model, epochs=10):\n",
        "        \"\"\"Simula tempo de treinamento\"\"\"\n",
        "        # Simular tempo baseado no número de parâmetros\n",
        "        trainable_params = self.count_parameters(model)\n",
        "        \n",
        "        # Tempo simulado (em segundos)\n",
        "        if trainable_params < 100000:  # Feature extraction\n",
        "            time_per_epoch = 2.0\n",
        "        elif trainable_params < 1000000:  # Fine-tuning\n",
        "            time_per_epoch = 5.0\n",
        "        else:  # From scratch\n",
        "            time_per_epoch = 15.0\n",
        "        \n",
        "        return time_per_epoch * epochs\n",
        "    \n",
        "    def simulate_accuracy(self, model_type, dataset_size=1000):\n",
        "        \"\"\"Simula acurácia baseada no tipo de modelo e tamanho do dataset\"\"\"\n",
        "        if model_type == 'feature_extraction':\n",
        "            if dataset_size < 500:\n",
        "                return 0.75\n",
        "            elif dataset_size < 1000:\n",
        "                return 0.82\n",
        "            else:\n",
        "                return 0.85\n",
        "        elif model_type == 'fine_tuning':\n",
        "            if dataset_size < 500:\n",
        "                return 0.88\n",
        "            elif dataset_size < 1000:\n",
        "                return 0.92\n",
        "            else:\n",
        "                return 0.94\n",
        "        else:  # from_scratch\n",
        "            if dataset_size < 500:\n",
        "                return 0.45\n",
        "            elif dataset_size < 1000:\n",
        "                return 0.65\n",
        "            else:\n",
        "                return 0.78\n",
        "    \n",
        "    def compare_strategies(self):\n",
        "        \"\"\"Compara diferentes estratégias de transfer learning\"\"\"\n",
        "        \n",
        "        # Criar modelos\n",
        "        feature_extraction_model = self.create_feature_extraction_model()\n",
        "        fine_tuning_model = self.create_fine_tuning_model()\n",
        "        from_scratch_model = self.create_from_scratch_model()\n",
        "        \n",
        "        # Calcular métricas\n",
        "        strategies = [\n",
        "            ('Feature Extraction', feature_extraction_model),\n",
        "            ('Fine-tuning', fine_tuning_model),\n",
        "            ('From Scratch', from_scratch_model)\n",
        "        ]\n",
        "        \n",
        "        results = {}\n",
        "        for name, model in strategies:\n",
        "            results[name] = {\n",
        "                'parameters': self.count_parameters(model),\n",
        "                'training_time': self.simulate_training_time(model),\n",
        "                'accuracy_small': self.simulate_accuracy(name.lower().replace('-', '_'), 200),\n",
        "                'accuracy_medium': self.simulate_accuracy(name.lower().replace('-', '_'), 1000),\n",
        "                'accuracy_large': self.simulate_accuracy(name.lower().replace('-', '_'), 5000)\n",
        "            }\n",
        "        \n",
        "        return results\n",
        "    \n",
        "    def visualize_comparison(self, results):\n",
        "        \"\"\"Visualiza comparação das estratégias\"\"\"\n",
        "        \n",
        "        fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "        \n",
        "        strategies = list(results.keys())\n",
        "        colors = ['lightblue', 'lightgreen', 'lightcoral']\n",
        "        \n",
        "        # Gráfico de parâmetros\n",
        "        params = [results[s]['parameters'] for s in strategies]\n",
        "        axes[0, 0].bar(strategies, params, color=colors)\n",
        "        axes[0, 0].set_title('Parâmetros Treináveis')\n",
        "        axes[0, 0].set_ylabel('Número de Parâmetros')\n",
        "        axes[0, 0].tick_params(axis='x', rotation=45)\n",
        "        \n",
        "        # Adicionar valores nas barras\n",
        "        for i, v in enumerate(params):\n",
        "            axes[0, 0].text(i, v + max(params) * 0.01, f'{v:,}', \n",
        "                        ha='center', va='bottom', fontsize=10)\n",
        "        \n",
        "        # Gráfico de tempo de treinamento\n",
        "        times = [results[s]['training_time'] for s in strategies]\n",
        "        axes[0, 1].bar(strategies, times, color=colors)\n",
        "        axes[0, 1].set_title('Tempo de Treinamento (10 épocas)')\n",
        "        axes[0, 1].set_ylabel('Tempo (segundos)')\n",
        "        axes[0, 1].tick_params(axis='x', rotation=45)\n",
        "        \n",
        "        # Adicionar valores nas barras\n",
        "        for i, v in enumerate(times):\n",
        "            axes[0, 1].text(i, v + max(times) * 0.01, f'{v:.1f}s', \n",
        "                        ha='center', va='bottom', fontsize=10)\n",
        "        \n",
        "        # Gráfico de acurácia por tamanho de dataset\n",
        "        dataset_sizes = ['Pequeno (200)', 'Médio (1000)', 'Grande (5000)']\n",
        "        accuracy_keys = ['accuracy_small', 'accuracy_medium', 'accuracy_large']\n",
        "        \n",
        "        x = np.arange(len(dataset_sizes))\n",
        "        width = 0.25\n",
        "        \n",
        "        for i, strategy in enumerate(strategies):\n",
        "            accuracies = [results[strategy][key] for key in accuracy_keys]\n",
        "            axes[0, 2].bar(x + i*width, accuracies, width, \n",
        "                          label=strategy, color=colors[i])\n",
        "        \n",
        "        axes[0, 2].set_title('Acurácia por Tamanho do Dataset')\n",
        "        axes[0, 2].set_ylabel('Acurácia')\n",
        "        axes[0, 2].set_xticks(x + width)\n",
        "        axes[0, 2].set_xticklabels(dataset_sizes)\n",
        "        axes[0, 2].legend()\n",
        "        axes[0, 2].set_ylim(0, 1)\n",
        "        \n",
        "        # Informações detalhadas\n",
        "        info_text = \"\"\"\n",
        "        FEATURE EXTRACTION:\n",
        "        • Congela todas as camadas\n",
        "        • Treina apenas classificador\n",
        "        • Mais rápido\n",
        "        • Menos parâmetros\n",
        "        • Boa para datasets pequenos\n",
        "        \n",
        "        FINE-TUNING:\n",
        "        • Descongela camadas finais\n",
        "        • Treina camadas específicas\n",
        "        • Balanceado\n",
        "        • Melhor performance\n",
        "        • Ideal para datasets médios\n",
        "        \n",
        "        FROM SCRATCH:\n",
        "        • Treina tudo do zero\n",
        "        • Mais lento\n",
        "        • Mais parâmetros\n",
        "        • Requer muito dados\n",
        "        • Para domínios muito diferentes\n",
        "        \"\"\"\n",
        "        \n",
        "        axes[1, 0].text(0.05, 0.95, info_text, transform=axes[1, 0].transAxes, \n",
        "                        fontsize=10, verticalalignment='top',\n",
        "                        bbox=dict(boxstyle='round', facecolor='lightgray', alpha=0.8))\n",
        "        axes[1, 0].set_title('Características das Estratégias')\n",
        "        axes[1, 0].axis('off')\n",
        "        \n",
        "        # Quando usar cada estratégia\n",
        "        usage_text = \"\"\"\n",
        "        QUANDO USAR:\n",
        "        \n",
        "        FEATURE EXTRACTION:\n",
        "        ✓ Dataset muito pequeno (< 500)\n",
        "        ✓ Domínio similar ao ImageNet\n",
        "        ✓ Recursos computacionais limitados\n",
        "        ✓ Prototipagem rápida\n",
        "        \n",
        "        FINE-TUNING:\n",
        "        ✓ Dataset médio (500-5000)\n",
        "        ✓ Domínio relacionado\n",
        "        ✓ Balance entre tempo e performance\n",
        "        ✓ Aplicações práticas\n",
        "        \n",
        "        FROM SCRATCH:\n",
        "        ✓ Dataset muito grande (> 5000)\n",
        "        ✓ Domínio muito diferente\n",
        "        ✓ Recursos computacionais abundantes\n",
        "        ✓ Pesquisa e desenvolvimento\n",
        "        \"\"\"\n",
        "        \n",
        "        axes[1, 1].text(0.05, 0.95, usage_text, transform=axes[1, 1].transAxes, \n",
        "                        fontsize=10, verticalalignment='top',\n",
        "                        bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.8))\n",
        "        axes[1, 1].set_title('Quando Usar Cada Estratégia')\n",
        "        axes[1, 1].axis('off')\n",
        "        \n",
        "        # Fluxo de decisão\n",
        "        decision_text = \"\"\"\n",
        "        FLUXO DE DECISÃO:\n",
        "        \n",
        "        1. Tamanho do Dataset?\n",
        "           • Pequeno → Feature Extraction\n",
        "           • Médio → Fine-tuning\n",
        "           • Grande → From Scratch\n",
        "        \n",
        "        2. Similaridade com ImageNet?\n",
        "           • Similar → Feature Extraction\n",
        "           • Relacionado → Fine-tuning\n",
        "           • Diferente → From Scratch\n",
        "        \n",
        "        3. Recursos Disponíveis?\n",
        "           • Limitados → Feature Extraction\n",
        "           • Moderados → Fine-tuning\n",
        "           • Abundantes → From Scratch\n",
        "        \n",
        "        4. Tempo Disponível?\n",
        "           • Pouco → Feature Extraction\n",
        "           • Moderado → Fine-tuning\n",
        "           • Muito → From Scratch\n",
        "        \"\"\"\n",
        "        \n",
        "        axes[1, 2].text(0.05, 0.95, decision_text, transform=axes[1, 2].transAxes, \n",
        "                        fontsize=10, verticalalignment='top',\n",
        "                        bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.8))\n",
        "        axes[1, 2].set_title('Fluxo de Decisão')\n",
        "        axes[1, 2].axis('off')\n",
        "        \n",
        "        plt.suptitle('Comparação de Estratégias de Transfer Learning', fontsize=16)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        \n",
        "        return results\n",
        "\n",
        "# Executar demonstração\n",
        "demo = TransferLearningDemo()\n",
        "results = demo.compare_strategies()\n",
        "demo.visualize_comparison(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Análise dos Resultados\n",
        "\n",
        "**Comparação das Estratégias:**\n",
        "\n",
        "1. **Feature Extraction:**\n",
        "   - **Parâmetros**: ~11K (apenas classificador)\n",
        "   - **Tempo**: ~20s (mais rápido)\n",
        "   - **Acurácia**: Boa para datasets pequenos\n",
        "   - **Uso**: Prototipagem e datasets pequenos\n",
        "\n",
        "2. **Fine-tuning:**\n",
        "   - **Parâmetros**: ~2M (camadas finais)\n",
        "   - **Tempo**: ~50s (balanceado)\n",
        "   - **Acurácia**: Melhor performance geral\n",
        "   - **Uso**: Aplicações práticas\n",
        "\n",
        "3. **From Scratch:**\n",
        "   - **Parâmetros**: ~11M (todos os parâmetros)\n",
        "   - **Tempo**: ~150s (mais lento)\n",
        "   - **Acurácia**: Requer muito dados\n",
        "   - **Uso**: Domínios muito diferentes\n",
        "\n",
        "**Insights Importantes:**\n",
        "- **Eficiência**: Feature extraction é mais eficiente\n",
        "- **Performance**: Fine-tuning oferece melhor balance\n",
        "- **Dados**: From scratch requer datasets grandes\n",
        "- **Escolha**: Depende do contexto e recursos\n",
        "\n",
        "**Referências:**\n",
        "- [How transferable are features in deep neural networks? - Yosinski et al.](https://arxiv.org/abs/1411.1792)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4.3 Estratégias de Transfer Learning",
        "",
        "### Feature Extraction",
        "",
        "**Definição:**",
        "- **Congelamento**: Todas as camadas congeladas",
        "- **Treinamento**: Apenas classificador final",
        "- **Parâmetros**: Mínimos treináveis",
        "- **Velocidade**: Mais rápido",
        "",
        "**Quando Usar:**",
        "- Dataset pequeno (< 500 imagens)",
        "- Domínio similar ao ImageNet",
        "- Recursos computacionais limitados",
        "- Prototipagem rápida",
        "",
        "![Feature Extraction](https://raw.githubusercontent.com/rfapo/visao-computacional/main/images/modulo4/feature_extraction.png)",
        "",
        "### Fine-tuning",
        "",
        "**Definição:**",
        "- **Descongelamento**: Camadas finais treináveis",
        "- **Treinamento**: Camadas específicas + classificador",
        "- **Parâmetros**: Moderados treináveis",
        "- **Velocidade**: Balanceado",
        "",
        "**Quando Usar:**",
        "- Dataset médio (500-5000 imagens)",
        "- Domínio relacionado ao ImageNet",
        "- Balance entre tempo e performance",
        "- Aplicações práticas",
        "",
        "![Fine-tuning](https://raw.githubusercontent.com/rfapo/visao-computacional/main/images/modulo4/fine_tuning.png)",
        "",
        "### Pre-trained Initialization",
        "",
        "**Definição:**",
        "- **Inicialização**: Pesos pré-treinados como ponto de partida",
        "- **Treinamento**: Todas as camadas treináveis",
        "- **Parâmetros**: Todos treináveis",
        "- **Velocidade**: Mais lento",
        "",
        "**Quando Usar:**",
        "- Dataset grande (> 5000 imagens)",
        "- Domínio diferente do ImageNet",
        "- Recursos computacionais abundantes",
        "- Pesquisa e desenvolvimento",
        "",
        "![Pre-trained Initialization](https://raw.githubusercontent.com/rfapo/visao-computacional/main/images/modulo4/pre_trained_initialization.png)",
        "",
        "**Referências:**",
        "- [How transferable are features in deep neural networks? - Yosinski et al.](https://arxiv.org/abs/1411.1792)",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4.4 Demonstração Prática: Implementação Completa\n",
        "\n",
        "Vamos implementar uma solução completa de transfer learning:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import datasets, models\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "class CompleteTransferLearning:\n",
        "    \"\"\"Implementação completa de transfer learning\"\"\"\n",
        "    \n",
        "    def __init__(self, num_classes=5):\n",
        "        self.num_classes = num_classes\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        \n",
        "    def create_data_transforms(self):\n",
        "        \"\"\"Cria transformações de dados\"\"\"\n",
        "        \n",
        "        # Transformações para treinamento\n",
        "        train_transforms = transforms.Compose([\n",
        "            transforms.Resize(256),\n",
        "            transforms.CenterCrop(224),\n",
        "            transforms.RandomHorizontalFlip(p=0.5),\n",
        "            transforms.RandomRotation(degrees=10),\n",
        "            transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
        "                             std=[0.229, 0.224, 0.225])\n",
        "        ])\n",
        "        \n",
        "        # Transformações para validação\n",
        "        val_transforms = transforms.Compose([\n",
        "            transforms.Resize(256),\n",
        "            transforms.CenterCrop(224),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
        "                             std=[0.229, 0.224, 0.225])\n",
        "        ])\n",
        "        \n",
        "        return train_transforms, val_transforms\n",
        "    \n",
        "    def create_model(self, strategy='fine_tuning'):\n",
        "        \"\"\"Cria modelo baseado na estratégia\"\"\"\n",
        "        \n",
        "        # Carregar ResNet18 pré-treinado\n",
        "        model = models.resnet18(pretrained=True)\n",
        "        \n",
        "        # Substituir última camada\n",
        "        num_features = model.fc.in_features\n",
        "        model.fc = nn.Linear(num_features, self.num_classes)\n",
        "        \n",
        "        if strategy == 'feature_extraction':\n",
        "            # Congelar todas as camadas\n",
        "            for param in model.parameters():\n",
        "                param.requires_grad = False\n",
        "            \n",
        "        elif strategy == 'fine_tuning':\n",
        "            # Descongelar camadas finais\n",
        "            for param in model.layer4.parameters():\n",
        "                param.requires_grad = True\n",
        "            for param in model.fc.parameters():\n",
        "                param.requires_grad = True\n",
        "        \n",
        "        # From scratch não precisa de modificações\n",
        "        \n",
        "        return model\n",
        "    \n",
        "    def train_model(self, model, train_loader, val_loader, epochs=5, strategy='fine_tuning'):\n",
        "        \"\"\"Treina o modelo\"\"\"\n",
        "        \n",
        "        model = model.to(self.device)\n",
        "        \n",
        "        # Configurar otimizador\n",
        "        if strategy == 'feature_extraction':\n",
        "            optimizer = optim.Adam(model.fc.parameters(), lr=0.001)\n",
        "        elif strategy == 'fine_tuning':\n",
        "            optimizer = optim.Adam([\n",
        "                {'params': model.layer4.parameters(), 'lr': 0.0001},\n",
        "                {'params': model.fc.parameters(), 'lr': 0.001}\n",
        "            ])\n",
        "        else:  # from_scratch\n",
        "            optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "        \n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.1)\n",
        "        \n",
        "        # Histórico de treinamento\n",
        "        history = {\n",
        "            'train_loss': [],\n",
        "            'train_acc': [],\n",
        "            'val_loss': [],\n",
        "            'val_acc': []\n",
        "        }\n",
        "        \n",
        "        print(f\"Iniciando treinamento ({strategy})...\")\n",
        "        start_time = time.time()\n",
        "        \n",
        "        for epoch in range(epochs):\n",
        "            # Treinamento\n",
        "            model.train()\n",
        "            train_loss = 0.0\n",
        "            train_correct = 0\n",
        "            train_total = 0\n",
        "            \n",
        "            for batch_idx, (data, target) in enumerate(train_loader):\n",
        "                data, target = data.to(self.device), target.to(self.device)\n",
        "                \n",
        "                optimizer.zero_grad()\n",
        "                output = model(data)\n",
        "                loss = criterion(output, target)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                \n",
        "                train_loss += loss.item()\n",
        "                _, predicted = torch.max(output.data, 1)\n",
        "                train_total += target.size(0)\n",
        "                train_correct += (predicted == target).sum().item()\n",
        "            \n",
        "            # Validação\n",
        "            model.eval()\n",
        "            val_loss = 0.0\n",
        "            val_correct = 0\n",
        "            val_total = 0\n",
        "            \n",
        "            with torch.no_grad():\n",
        "                for data, target in val_loader:\n",
        "                    data, target = data.to(self.device), target.to(self.device)\n",
        "                    output = model(data)\n",
        "                    loss = criterion(output, target)\n",
        "                    \n",
        "                    val_loss += loss.item()\n",
        "                    _, predicted = torch.max(output.data, 1)\n",
        "                    val_total += target.size(0)\n",
        "                    val_correct += (predicted == target).sum().item()\n",
        "            \n",
        "            # Calcular métricas\n",
        "            train_loss /= len(train_loader)\n",
        "            train_acc = 100 * train_correct / train_total\n",
        "            val_loss /= len(val_loader)\n",
        "            val_acc = 100 * val_correct / val_total\n",
        "            \n",
        "            # Salvar histórico\n",
        "            history['train_loss'].append(train_loss)\n",
        "            history['train_acc'].append(train_acc)\n",
        "            history['val_loss'].append(val_loss)\n",
        "            history['val_acc'].append(val_acc)\n",
        "            \n",
        "            print(f'Epoch {epoch+1}/{epochs}: '\n",
        "                  f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%, '\n",
        "                  f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%')\n",
        "            \n",
        "            scheduler.step()\n",
        "        \n",
        "        training_time = time.time() - start_time\n",
        "        print(f'Treinamento concluído em {training_time:.2f} segundos')\n",
        "        \n",
        "        return history, training_time\n",
        "    \n",
        "    def plot_training_history(self, histories, strategies):\n",
        "        \"\"\"Plota histórico de treinamento\"\"\"\n",
        "        \n",
        "        fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "        \n",
        "        colors = ['blue', 'green', 'red']\n",
        "        \n",
        "        # Plotar loss\n",
        "        for i, (strategy, history) in enumerate(zip(strategies, histories)):\n",
        "            epochs = range(1, len(history['train_loss']) + 1)\n",
        "            axes[0, 0].plot(epochs, history['train_loss'], \n",
        "                           color=colors[i], label=f'{strategy} (Train)', linestyle='-')\n",
        "            axes[0, 0].plot(epochs, history['val_loss'], \n",
        "                           color=colors[i], label=f'{strategy} (Val)', linestyle='--')\n",
        "        \n",
        "        axes[0, 0].set_title('Training and Validation Loss')\n",
        "        axes[0, 0].set_xlabel('Epoch')\n",
        "        axes[0, 0].set_ylabel('Loss')\n",
        "        axes[0, 0].legend()\n",
        "        axes[0, 0].grid(True, alpha=0.3)\n",
        "        \n",
        "        # Plotar accuracy\n",
        "        for i, (strategy, history) in enumerate(zip(strategies, histories)):\n",
        "            epochs = range(1, len(history['train_acc']) + 1)\n",
        "            axes[0, 1].plot(epochs, history['train_acc'], \n",
        "                           color=colors[i], label=f'{strategy} (Train)', linestyle='-')\n",
        "            axes[0, 1].plot(epochs, history['val_acc'], \n",
        "                           color=colors[i], label=f'{strategy} (Val)', linestyle='--')\n",
        "        \n",
        "        axes[0, 1].set_title('Training and Validation Accuracy')\n",
        "        axes[0, 1].set_xlabel('Epoch')\n",
        "        axes[0, 1].set_ylabel('Accuracy (%)')\n",
        "        axes[0, 1].legend()\n",
        "        axes[0, 1].grid(True, alpha=0.3)\n",
        "        \n",
        "        # Comparação final\n",
        "        final_accuracies = [max(h['val_acc']) for h in histories]\n",
        "        axes[1, 0].bar(strategies, final_accuracies, color=colors)\n",
        "        axes[1, 0].set_title('Final Validation Accuracy')\n",
        "        axes[1, 0].set_ylabel('Accuracy (%)')\n",
        "        axes[1, 0].tick_params(axis='x', rotation=45)\n",
        "        \n",
        "        # Adicionar valores nas barras\n",
        "        for i, v in enumerate(final_accuracies):\n",
        "            axes[1, 0].text(i, v + max(final_accuracies) * 0.01, f'{v:.1f}%', \n",
        "                        ha='center', va='bottom')\n",
        "        \n",
        "        # Resumo das estratégias\n",
        "        summary_text = \"\"\"\n",
        "        RESUMO DAS ESTRATÉGIAS:\n",
        "        \n",
        "        FEATURE EXTRACTION:\n",
        "        • Mais rápido\n",
        "        • Menos parâmetros\n",
        "        • Boa para datasets pequenos\n",
        "        • Menor overfitting\n",
        "        \n",
        "        FINE-TUNING:\n",
        "        • Balanceado\n",
        "        • Boa performance\n",
        "        • Ideal para aplicações\n",
        "        • Flexível\n",
        "        \n",
        "        FROM SCRATCH:\n",
        "        • Mais lento\n",
        "        • Mais parâmetros\n",
        "        • Requer muitos dados\n",
        "        • Para domínios diferentes\n",
        "        \"\"\"\n",
        "        \n",
        "        axes[1, 1].text(0.05, 0.95, summary_text, transform=axes[1, 1].transAxes, \n",
        "                        fontsize=10, verticalalignment='top',\n",
        "                        bbox=dict(boxstyle='round', facecolor='lightgray', alpha=0.8))\n",
        "        axes[1, 1].set_title('Resumo das Estratégias')\n",
        "        axes[1, 1].axis('off')\n",
        "        \n",
        "        plt.suptitle('Comparação de Estratégias de Transfer Learning', fontsize=16)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "def demonstrate_complete_transfer_learning():\n",
        "    \"\"\"Demonstra implementação completa de transfer learning\"\"\"\n",
        "    \n",
        "    print(\"=== Demonstração de Transfer Learning Completa ===\")\n",
        "    print(\"\\nNota: Esta demonstração simula o treinamento com dados sintéticos\")\n",
        "    print(\"para fins educacionais. Em aplicações reais, use datasets reais.\")\n",
        "    \n",
        "    # Criar instância\n",
        "    transfer_learning = CompleteTransferLearning(num_classes=5)\n",
        "    \n",
        "    # Criar transformações\n",
        "    train_transforms, val_transforms = transfer_learning.create_data_transforms()\n",
        "    \n",
        "    # Simular dados (em aplicação real, carregar dataset real)\n",
        "    print(\"\\nSimulando carregamento de dados...\")\n",
        "    \n",
        "    # Criar dados sintéticos para demonstração\n",
        "    train_data = torch.randn(100, 3, 224, 224)\n",
        "    train_labels = torch.randint(0, 5, (100,))\n",
        "    val_data = torch.randn(20, 3, 224, 224)\n",
        "    val_labels = torch.randint(0, 5, (20,))\n",
        "    \n",
        "    # Criar DataLoaders\n",
        "    train_dataset = torch.utils.data.TensorDataset(train_data, train_labels)\n",
        "    val_dataset = torch.utils.data.TensorDataset(val_data, val_labels)\n",
        "    \n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
        "    \n",
        "    # Estratégias para testar\n",
        "    strategies = ['feature_extraction', 'fine_tuning', 'from_scratch']\n",
        "    histories = []\n",
        "    training_times = []\n",
        "    \n",
        "    # Testar cada estratégia\n",
        "    for strategy in strategies:\n",
        "        print(f\"\\n=== Testando {strategy.upper()} ===\")\n",
        "        \n",
        "        # Criar modelo\n",
        "        model = transfer_learning.create_model(strategy)\n",
        "        \n",
        "        # Treinar modelo\n",
        "        history, training_time = transfer_learning.train_model(\n",
        "            model, train_loader, val_loader, epochs=3, strategy=strategy\n",
        "        )\n",
        "        \n",
        "        histories.append(history)\n",
        "        training_times.append(training_time)\n",
        "    \n",
        "    # Plotar resultados\n",
        "    transfer_learning.plot_training_history(histories, strategies)\n",
        "    \n",
        "    # Resumo final\n",
        "    print(\"\\n=== RESUMO FINAL ===\")\n",
        "    for i, strategy in enumerate(strategies):\n",
        "        final_acc = max(histories[i]['val_acc'])\n",
        "        print(f\"{strategy.upper()}: {final_acc:.1f}% accuracy, {training_times[i]:.1f}s\")\n",
        "    \n",
        "    return histories, training_times\n",
        "\n",
        "# Executar demonstração\n",
        "complete_results = demonstrate_complete_transfer_learning()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Análise da Implementação Completa\n",
        "\n",
        "**Resultados Observados:**\n",
        "\n",
        "1. **Feature Extraction:**\n",
        "   - **Convergência**: Rápida e estável\n",
        "   - **Overfitting**: Menor risco\n",
        "   - **Performance**: Boa para datasets pequenos\n",
        "   - **Tempo**: Mais rápido\n",
        "\n",
        "2. **Fine-tuning:**\n",
        "   - **Convergência**: Balanceada\n",
        "   - **Overfitting**: Risco moderado\n",
        "   - **Performance**: Melhor geral\n",
        "   - **Tempo**: Moderado\n",
        "\n",
        "3. **From Scratch:**\n",
        "   - **Convergência**: Mais lenta\n",
        "   - **Overfitting**: Maior risco\n",
        "   - **Performance**: Requer muitos dados\n",
        "   - **Tempo**: Mais lento\n",
        "\n",
        "**Insights Importantes:**\n",
        "- **Escolha**: Depende do contexto\n",
        "- **Dados**: Tamanho é fator crítico\n",
        "- **Recursos**: Computacionais e tempo\n",
        "- **Domínio**: Similaridade com ImageNet\n",
        "\n",
        "**Referências:**\n",
        "- [How transferable are features in deep neural networks? - Yosinski et al.](https://arxiv.org/abs/1411.1792)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4.5 Aplicações Práticas no Mercado",
        "",
        "### Casos de Uso Reais",
        "",
        "**1. Medicina e Saúde:**",
        "- **Diagnóstico por imagem**: Radiologia, dermatologia",
        "- **Detecção de anomalias**: Câncer, fraturas",
        "- **Monitoramento**: Progressão de doenças",
        "- **Exemplo**: Google DeepMind para detecção de retinopatia diabética",
        "",
        "**2. Automotivo:**",
        "- **Veículos autônomos**: Detecção de objetos",
        "- **Segurança**: Detecção de pedestres",
        "- **Qualidade**: Inspeção de peças",
        "- **Exemplo**: Tesla Autopilot",
        "",
        "**3. Varejo e E-commerce:**",
        "- **Recomendações visuais**: Produtos similares",
        "- **Busca por imagem**: Encontrar produtos",
        "- **Controle de estoque**: Reconhecimento automático",
        "- **Exemplo**: Amazon Visual Search",
        "",
        "**4. Agricultura:**",
        "- **Monitoramento de culturas**: Saúde das plantas",
        "- **Detecção de pragas**: Identificação automática",
        "- **Colheita**: Otimização de tempo",
        "- **Exemplo**: John Deere See & Spray",
        "",
        "![Aplicações Práticas](https://raw.githubusercontent.com/rfapo/visao-computacional/main/images/modulo4/aplicacoes_praticas.png)",
        "",
        "### Vantagens Competitivas",
        "",
        "**Eficiência:**",
        "- **Desenvolvimento rápido**: Protótipos em semanas",
        "- **Custo reduzido**: Menos recursos computacionais",
        "- **Time-to-market**: Entrada mais rápida no mercado",
        "",
        "**Qualidade:**",
        "- **Performance superior**: Melhores resultados",
        "- **Robustez**: Modelos mais estáveis",
        "- **Escalabilidade**: Fácil adaptação",
        "",
        "**Acessibilidade:**",
        "- **Democratização**: IA para todos",
        "- **Recursos limitados**: Funciona com poucos dados",
        "- **Expertise**: Menos conhecimento técnico necessário",
        "",
        "![Vantagens Competitivas](https://raw.githubusercontent.com/rfapo/visao-computacional/main/images/modulo4/vantagens_competitivas.png)",
        "",
        "**Referências:**",
        "- [Transfer Learning for Computer Vision - Pan & Yang](https://ieeexplore.ieee.org/document/5288526)",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Resumo do Módulo 4\n",
        "\n",
        "### Principais Conceitos Abordados\n",
        "\n",
        "1. **Transfer Learning em Visão Computacional**\n",
        "   - Conceitos fundamentais\n",
        "   - Por que funciona\n",
        "   - Benefícios quantitativos\n",
        "\n",
        "2. **Estratégias de Transfer Learning**\n",
        "   - Feature Extraction\n",
        "   - Fine-tuning\n",
        "   - Pre-trained Initialization\n",
        "   - Quando usar cada estratégia\n",
        "\n",
        "3. **Aplicações Práticas no Mercado**\n",
        "   - Casos de uso reais\n",
        "   - Vantagens competitivas\n",
        "   - Impacto no mercado\n",
        "\n",
        "### Demonstrações Práticas\n",
        "\n",
        "**1. Comparação de Estratégias:**\n",
        "   - Implementação de diferentes abordagens\n",
        "   - Análise de parâmetros e tempo\n",
        "   - Comparação de performance\n",
        "\n",
        "**2. Implementação Completa:**\n",
        "   - Pipeline completo de transfer learning\n",
        "   - Treinamento e validação\n",
        "   - Análise de resultados\n",
        "\n",
        "### Próximos Passos\n",
        "\n",
        "No próximo módulo, exploraremos **Tarefas Fundamentais em Visão Computacional**, onde aprenderemos sobre classificação, detecção e segmentação.\n",
        "\n",
        "### Referências Principais\n",
        "\n",
        "- [How transferable are features in deep neural networks? - Yosinski et al.](https://arxiv.org/abs/1411.1792)\n",
        "- [Transfer Learning for Computer Vision - Pan & Yang](https://ieeexplore.ieee.org/document/5288526)\n",
        "\n",
        "---\n",
        "\n",
        "**Próximo Módulo**: Tarefas Fundamentais em Visão Computacional\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}